<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Multi-modal Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/fontawesome6-1.2.0/all.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-1.2.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">GEOG 288KC</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">🏠 home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../Syllabus.html"> 
<span class="menu-text">📋 syllabus</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-weekly-sessions" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">💻 weekly sessions</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-weekly-sessions">    
        <li>
    <a class="dropdown-item" href="../../chapters/c01-geospatial-data-foundations.html">
 <span class="dropdown-text">Week 1 - 🚀 Core Tools and Data Access</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../chapters/c02-spatial-temporal-attention-mechanisms.html">
 <span class="dropdown-text">Week 2 - ⚡ Rapid Remote Sensing Preprocessing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../chapters/c03-complete-gfm-architecture.html">
 <span class="dropdown-text">Week 3 - 🤖 Machine Learning on Remote Sensing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../chapters/c04-pretraining-implementation.html">
 <span class="dropdown-text">Week 4 - 🏗️ Foundation Models in Practice</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../chapters/c05-training-loop-optimization.html">
 <span class="dropdown-text">Week 5 - 🔧 Fine-Tuning &amp; Transfer Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../chapters/c06-model-evaluation-analysis.html">
 <span class="dropdown-text">Week 6 - ⏰ Spatiotemporal Modeling &amp; Projects</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-cheatsheets" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">👀 cheatsheets</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-cheatsheets">    
        <li>
    <a class="dropdown-item" href="../../cheatsheets.html">
 <span class="dropdown-text">📋 All Cheatsheets</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">⚡ Quick Starts</li>
        <li>
    <a class="dropdown-item" href="../../extras/cheatsheets/week01_imports.html">
 <span class="dropdown-text">Week 01: Import Guide</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-explainers" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">🧩 explainers</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-explainers">    
        <li class="dropdown-header">1️⃣ Week 1</li>
        <li>
    <a class="dropdown-item" href="../../extras/ai-ml-dl-fm-hierarchy.html">
 <span class="dropdown-text">🤖 AI/ML/DL/FM Hierarchy</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../extras/geospatial-foundation-model-predictions-standalone.html">
 <span class="dropdown-text">🎯 GFM Predictions (Standalone)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../extras/geospatial-prediction-hierarchy.html">
 <span class="dropdown-text">✅ Geospatial Task/Prediction Types</span></a>
  </li>  
        <li class="dropdown-header">2️⃣ Week 2</li>
        <li>
    <a class="dropdown-item" href="../../chapters/c00a-foundation_model_architectures.html">
 <span class="dropdown-text">🏗️ Foundation Model Architectures</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../chapters/c00b-introduction-to-deeplearning-architecture.html">
 <span class="dropdown-text">🎓 Introduction to Deep Learning Architecture</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-extras" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">📖 extras</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-extras">    
        <li class="dropdown-header">🎯 Practical Examples</li>
        <li>
    <a class="dropdown-item" href="../../extras/examples/normalization_comparison.html">
 <span class="dropdown-text">Normalization Comparison</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../extras/examples/resnet.html">
 <span class="dropdown-text">ResNet Implementation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../extras/examples/text_encoder.html">
 <span class="dropdown-text">Text Encoder</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../extras/examples/tiling-and-patches.html">
 <span class="dropdown-text">Tiling and Patches</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../extras/examples/terratorch_workflows.html">
 <span class="dropdown-text">TerraTorch Workflows</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../extras/resources/course_resources.html">
 <span class="dropdown-text">📚 Reference Materials</span></a>
  </li>  
        <li class="dropdown-header">📁 Project Templates</li>
        <li>
    <a class="dropdown-item" href="../../extras/projects/project-proposal-template.html">
 <span class="dropdown-text">Project Proposal Template</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../extras/projects/mvp-template.html">
 <span class="dropdown-text">Project Results Template</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gfms-from-scratch/gfms-from-scratch.github.io" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <div class="quarto-title-block"><div><h1 class="title">Multi-modal Learning</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
            <p class="subtitle lead">Combining different data modalities for enhanced geospatial AI</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-left">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-to-multi-modal-learning" id="toc-introduction-to-multi-modal-learning" class="nav-link active" data-scroll-target="#introduction-to-multi-modal-learning">Introduction to Multi-modal Learning</a></li>
  <li><a href="#types-of-multi-modal-data-in-geospatial-ai" id="toc-types-of-multi-modal-data-in-geospatial-ai" class="nav-link" data-scroll-target="#types-of-multi-modal-data-in-geospatial-ai">Types of Multi-modal Data in Geospatial AI</a>
  <ul class="collapse">
  <li><a href="#common-modality-combinations" id="toc-common-modality-combinations" class="nav-link" data-scroll-target="#common-modality-combinations">Common Modality Combinations</a></li>
  <li><a href="#data-preprocessing-for-multi-modal-learning" id="toc-data-preprocessing-for-multi-modal-learning" class="nav-link" data-scroll-target="#data-preprocessing-for-multi-modal-learning">Data Preprocessing for Multi-modal Learning</a></li>
  </ul></li>
  <li><a href="#multi-modal-architecture-patterns" id="toc-multi-modal-architecture-patterns" class="nav-link" data-scroll-target="#multi-modal-architecture-patterns">Multi-modal Architecture Patterns</a>
  <ul class="collapse">
  <li><a href="#early-fusion-vs-late-fusion" id="toc-early-fusion-vs-late-fusion" class="nav-link" data-scroll-target="#early-fusion-vs-late-fusion">Early Fusion vs Late Fusion</a></li>
  <li><a href="#attention-based-fusion" id="toc-attention-based-fusion" class="nav-link" data-scroll-target="#attention-based-fusion">Attention-based Fusion</a></li>
  </ul></li>
  <li><a href="#contrastive-learning-for-multi-modal-data" id="toc-contrastive-learning-for-multi-modal-data" class="nav-link" data-scroll-target="#contrastive-learning-for-multi-modal-data">Contrastive Learning for Multi-modal Data</a>
  <ul class="collapse">
  <li><a href="#clip-style-contrastive-learning" id="toc-clip-style-contrastive-learning" class="nav-link" data-scroll-target="#clip-style-contrastive-learning">CLIP-style Contrastive Learning</a></li>
  <li><a href="#zero-shot-classification" id="toc-zero-shot-classification" class="nav-link" data-scroll-target="#zero-shot-classification">Zero-Shot Classification</a></li>
  </ul></li>
  <li><a href="#multi-modal-data-augmentation" id="toc-multi-modal-data-augmentation" class="nav-link" data-scroll-target="#multi-modal-data-augmentation">Multi-modal Data Augmentation</a>
  <ul class="collapse">
  <li><a href="#cross-modal-data-augmentation" id="toc-cross-modal-data-augmentation" class="nav-link" data-scroll-target="#cross-modal-data-augmentation">Cross-modal Data Augmentation</a></li>
  </ul></li>
  <li><a href="#performance-evaluation-metrics" id="toc-performance-evaluation-metrics" class="nav-link" data-scroll-target="#performance-evaluation-metrics">Performance Evaluation Metrics</a>
  <ul class="collapse">
  <li><a href="#multi-modal-evaluation" id="toc-multi-modal-evaluation" class="nav-link" data-scroll-target="#multi-modal-evaluation">Multi-modal Evaluation</a></li>
  </ul></li>
  <li><a href="#real-world-applications" id="toc-real-world-applications" class="nav-link" data-scroll-target="#real-world-applications">Real-world Applications</a>
  <ul class="collapse">
  <li><a href="#applications-in-geospatial-ai" id="toc-applications-in-geospatial-ai" class="nav-link" data-scroll-target="#applications-in-geospatial-ai">Applications in Geospatial AI</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-left" id="quarto-document-content">





<section id="introduction-to-multi-modal-learning" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-multi-modal-learning">Introduction to Multi-modal Learning</h2>
<p>Multi-modal learning combines different types of data (imagery, text, time series, etc.) to create more comprehensive and robust AI systems. In geospatial applications, this involves integrating satellite imagery with text descriptions, weather data, and other complementary information.</p>
<div id="f8132206" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> CLIPModel, CLIPProcessor, AutoTokenizer, AutoModel</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"PyTorch version: </span><span class="sc">{</span>torch<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>PyTorch version: 2.7.1</code></pre>
</div>
</div>
</section>
<section id="types-of-multi-modal-data-in-geospatial-ai" class="level2">
<h2 class="anchored" data-anchor-id="types-of-multi-modal-data-in-geospatial-ai">Types of Multi-modal Data in Geospatial AI</h2>
<section id="common-modality-combinations" class="level3">
<h3 class="anchored" data-anchor-id="common-modality-combinations">Common Modality Combinations</h3>
<div id="75d0cd37" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_multimodal_data_types():</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show different types of multi-modal combinations in geospatial AI"""</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    modality_combinations <span class="op">=</span> {</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Image + Text"</span>: {</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example"</span>: <span class="st">"Satellite image + location description"</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"use_cases"</span>: [<span class="st">"Image captioning"</span>, <span class="st">"Location search"</span>, <span class="st">"Content-based retrieval"</span>],</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Semantic gap"</span>, <span class="st">"Text-image alignment"</span>, <span class="st">"Scale differences"</span>]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Multi-spectral + SAR"</span>: {</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example"</span>: <span class="st">"Optical + Radar imagery"</span>, </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>            <span class="st">"use_cases"</span>: [<span class="st">"All-weather monitoring"</span>, <span class="st">"Improved classification"</span>, <span class="st">"Change detection"</span>],</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Registration"</span>, <span class="st">"Resolution differences"</span>, <span class="st">"Fusion strategies"</span>]</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Image + Time Series"</span>: {</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example"</span>: <span class="st">"Satellite imagery + weather/climate data"</span>,</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">"use_cases"</span>: [<span class="st">"Crop yield prediction"</span>, <span class="st">"Disaster monitoring"</span>, <span class="st">"Environmental modeling"</span>],</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Temporal alignment"</span>, <span class="st">"Different sampling rates"</span>, <span class="st">"Multi-scale fusion"</span>]</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Image + Tabular"</span>: {</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example"</span>: <span class="st">"Remote sensing + demographic/economic data"</span>,</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>            <span class="st">"use_cases"</span>: [<span class="st">"Socioeconomic mapping"</span>, <span class="st">"Urban planning"</span>, <span class="st">"Poverty estimation"</span>],</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Spatial alignment"</span>, <span class="st">"Feature engineering"</span>, <span class="st">"Scale mismatch"</span>]</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Multi-resolution"</span>: {</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example"</span>: <span class="st">"High-res + Low-res imagery"</span>,</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>            <span class="st">"use_cases"</span>: [<span class="st">"Super-resolution"</span>, <span class="st">"Multi-scale analysis"</span>, <span class="st">"Data fusion"</span>],</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Resolution alignment"</span>, <span class="st">"Information preservation"</span>, <span class="st">"Computational efficiency"</span>]</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-modal Data Types in Geospatial AI:"</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> modality, details <span class="kw">in</span> modality_combinations.items():</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>modality<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Example: </span><span class="sc">{</span>details[<span class="st">'example'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Use cases: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(details[<span class="st">'use_cases'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Challenges: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(details[<span class="st">'challenges'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> modality_combinations</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>multimodal_types <span class="op">=</span> demonstrate_multimodal_data_types()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Multi-modal Data Types in Geospatial AI:
============================================================

Image + Text:
  Example: Satellite image + location description
  Use cases: Image captioning, Location search, Content-based retrieval
  Challenges: Semantic gap, Text-image alignment, Scale differences

Multi-spectral + SAR:
  Example: Optical + Radar imagery
  Use cases: All-weather monitoring, Improved classification, Change detection
  Challenges: Registration, Resolution differences, Fusion strategies

Image + Time Series:
  Example: Satellite imagery + weather/climate data
  Use cases: Crop yield prediction, Disaster monitoring, Environmental modeling
  Challenges: Temporal alignment, Different sampling rates, Multi-scale fusion

Image + Tabular:
  Example: Remote sensing + demographic/economic data
  Use cases: Socioeconomic mapping, Urban planning, Poverty estimation
  Challenges: Spatial alignment, Feature engineering, Scale mismatch

Multi-resolution:
  Example: High-res + Low-res imagery
  Use cases: Super-resolution, Multi-scale analysis, Data fusion
  Challenges: Resolution alignment, Information preservation, Computational efficiency</code></pre>
</div>
</div>
</section>
<section id="data-preprocessing-for-multi-modal-learning" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing-for-multi-modal-learning">Data Preprocessing for Multi-modal Learning</h3>
<div id="6797f54b" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_multimodal_preprocessing_pipeline():</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Demonstrate preprocessing for multi-modal geospatial data"""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate different data modalities</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    np.random.seed(<span class="dv">42</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Satellite imagery (multispectral)</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    batch_size, channels, height, width <span class="op">=</span> <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    satellite_images <span class="op">=</span> torch.randn(batch_size, channels, height, width)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Text descriptions</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    text_descriptions <span class="op">=</span> [</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Forest area with dense vegetation and high canopy cover"</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Urban residential area with mixed building types"</span>,</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Agricultural land with crop fields and irrigation"</span>,</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Coastal wetland area with water bodies and marsh"</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Tabular metadata</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    metadata <span class="op">=</span> pd.DataFrame({</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">'location_id'</span>: [<span class="ss">f'LOC_</span><span class="sc">{</span>i<span class="sc">:03d}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">'latitude'</span>: [<span class="fl">45.5</span> <span class="op">+</span> i<span class="op">*</span><span class="fl">0.1</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">'longitude'</span>: [<span class="op">-</span><span class="fl">122.5</span> <span class="op">+</span> i<span class="op">*</span><span class="fl">0.1</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">'elevation'</span>: [<span class="dv">100</span> <span class="op">+</span> i<span class="op">*</span><span class="dv">50</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'temperature'</span>: [<span class="fl">15.5</span> <span class="op">+</span> i<span class="op">*</span><span class="dv">2</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'precipitation'</span>: [<span class="dv">800</span> <span class="op">+</span> i<span class="op">*</span><span class="dv">100</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">'season'</span>: [<span class="st">'spring'</span>, <span class="st">'summer'</span>, <span class="st">'autumn'</span>, <span class="st">'winter'</span>]</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Time series data</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    time_steps <span class="op">=</span> <span class="dv">52</span>  <span class="co"># Weekly data for a year</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    time_series <span class="op">=</span> torch.randn(batch_size, time_steps, <span class="dv">3</span>)  <span class="co"># NDVI, temperature, precipitation</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-modal Data Examples:"</span>)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">40</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Satellite images shape: </span><span class="sc">{</span>satellite_images<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text descriptions: </span><span class="sc">{</span><span class="bu">len</span>(text_descriptions)<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Metadata shape: </span><span class="sc">{</span>metadata<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Time series shape: </span><span class="sc">{</span>time_series<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocessing functions</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> preprocess_images(images, target_size<span class="op">=</span>(<span class="dv">224</span>, <span class="dv">224</span>)):</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Preprocess satellite images"""</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize to [0, 1]</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        images <span class="op">=</span> (images <span class="op">-</span> images.<span class="bu">min</span>()) <span class="op">/</span> (images.<span class="bu">max</span>() <span class="op">-</span> images.<span class="bu">min</span>())</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Resize if needed (simplified)</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> images.shape[<span class="op">-</span><span class="dv">2</span>:] <span class="op">!=</span> target_size:</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> F.interpolate(images, size<span class="op">=</span>target_size, mode<span class="op">=</span><span class="st">'bilinear'</span>, align_corners<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> images</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> preprocess_text(texts, max_length<span class="op">=</span><span class="dv">77</span>):</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Preprocess text descriptions (simplified tokenization)"""</span></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># In practice, use proper tokenizers like CLIP or BERT</span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        processed_texts <span class="op">=</span> []</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> text <span class="kw">in</span> texts:</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Simple word tokenization</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>            words <span class="op">=</span> text.lower().split()[:max_length]</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Pad to max_length</span></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>            words <span class="op">+=</span> [<span class="st">'&lt;pad&gt;'</span>] <span class="op">*</span> (max_length <span class="op">-</span> <span class="bu">len</span>(words))</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>            processed_texts.append(words)</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> processed_texts</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> preprocess_tabular(metadata):</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Preprocess tabular metadata"""</span></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>        processed <span class="op">=</span> metadata.copy()</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize numerical features</span></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>        numerical_cols <span class="op">=</span> [<span class="st">'latitude'</span>, <span class="st">'longitude'</span>, <span class="st">'elevation'</span>, <span class="st">'temperature'</span>, <span class="st">'precipitation'</span>]</span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> col <span class="kw">in</span> numerical_cols:</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>            processed[col] <span class="op">=</span> (processed[col] <span class="op">-</span> processed[col].mean()) <span class="op">/</span> processed[col].std()</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode categorical features (simplified)</span></span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>        season_encoding <span class="op">=</span> {<span class="st">'spring'</span>: <span class="dv">0</span>, <span class="st">'summer'</span>: <span class="dv">1</span>, <span class="st">'autumn'</span>: <span class="dv">2</span>, <span class="st">'winter'</span>: <span class="dv">3</span>}</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>        processed[<span class="st">'season_encoded'</span>] <span class="op">=</span> processed[<span class="st">'season'</span>].<span class="bu">map</span>(season_encoding)</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> processed</span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> preprocess_time_series(ts_data, normalize<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Preprocess time series data"""</span></span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> normalize:</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Normalize across time dimension</span></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>            mean <span class="op">=</span> ts_data.mean(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>            std <span class="op">=</span> ts_data.std(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>            ts_data <span class="op">=</span> (ts_data <span class="op">-</span> mean) <span class="op">/</span> (std <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ts_data</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply preprocessing</span></span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a>    processed_images <span class="op">=</span> preprocess_images(satellite_images)</span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>    processed_texts <span class="op">=</span> preprocess_text(text_descriptions)</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>    processed_metadata <span class="op">=</span> preprocess_tabular(metadata)</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>    processed_time_series <span class="op">=</span> preprocess_time_series(time_series)</span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">After Preprocessing:"</span>)</span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Images range: [</span><span class="sc">{</span>processed_images<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>processed_images<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.3f}</span><span class="ss">]"</span>)</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text tokens per sample: </span><span class="sc">{</span><span class="bu">len</span>(processed_texts[<span class="dv">0</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Metadata columns:"</span>, <span class="bu">list</span>(processed_metadata.columns))</span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Time series normalized: mean=</span><span class="sc">{</span>processed_time_series<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">, std=</span><span class="sc">{</span>processed_time_series<span class="sc">.</span>std()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a>        <span class="st">'images'</span>: processed_images,</span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a>        <span class="st">'texts'</span>: processed_texts,</span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a>        <span class="st">'metadata'</span>: processed_metadata,</span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a>        <span class="st">'time_series'</span>: processed_time_series</span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a>preprocessed_data <span class="op">=</span> create_multimodal_preprocessing_pipeline()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Multi-modal Data Examples:
========================================
Satellite images shape: torch.Size([4, 6, 224, 224])
Text descriptions: 4 samples
Metadata shape: (4, 7)
Time series shape: torch.Size([4, 52, 3])

After Preprocessing:
Images range: [0.000, 1.000]
Text tokens per sample: 77
Metadata columns: ['location_id', 'latitude', 'longitude', 'elevation', 'temperature', 'precipitation', 'season', 'season_encoded']
Time series normalized: mean=-0.000, std=0.991</code></pre>
</div>
</div>
</section>
</section>
<section id="multi-modal-architecture-patterns" class="level2">
<h2 class="anchored" data-anchor-id="multi-modal-architecture-patterns">Multi-modal Architecture Patterns</h2>
<section id="early-fusion-vs-late-fusion" class="level3">
<h3 class="anchored" data-anchor-id="early-fusion-vs-late-fusion">Early Fusion vs Late Fusion</h3>
<div id="10237857" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EarlyFusionModel(nn.Module):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Early fusion: combine features at input level"""</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, image_channels<span class="op">=</span><span class="dv">6</span>, text_vocab_size<span class="op">=</span><span class="dv">1000</span>, tabular_features<span class="op">=</span><span class="dv">5</span>, hidden_dim<span class="op">=</span><span class="dv">512</span>, num_classes<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Image encoder</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(image_channels, <span class="dv">64</span>, <span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>),</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool2d((<span class="dv">4</span>, <span class="dv">4</span>)),</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">64</span> <span class="op">*</span> <span class="dv">16</span>, hidden_dim)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text encoder (simplified)</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>            nn.Embedding(text_vocab_size, <span class="dv">256</span>),</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>            nn.LSTM(<span class="dv">256</span>, hidden_dim<span class="op">//</span><span class="dv">2</span>, batch_first<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Tabular encoder</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tabular_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>            nn.Linear(tabular_features, hidden_dim<span class="op">//</span><span class="dv">2</span>),</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim<span class="op">//</span><span class="dv">2</span>, hidden_dim)</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Early fusion: concatenate features</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Image (hidden_dim) + Text (hidden_dim//2) + Tabular (hidden_dim)</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        fusion_input_dim <span class="op">=</span> hidden_dim <span class="op">+</span> hidden_dim<span class="op">//</span><span class="dv">2</span> <span class="op">+</span> hidden_dim</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fusion_layer <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>            nn.Linear(fusion_input_dim, hidden_dim),  <span class="co"># Combined features</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.3</span>),</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, num_classes)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, images, text_tokens, tabular_data):</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode each modality</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>        image_features <span class="op">=</span> <span class="va">self</span>.image_encoder(images)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text encoding (simplified - use last hidden state)</span></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>        text_features, (h_n, c_n) <span class="op">=</span> <span class="va">self</span>.text_encoder(text_tokens)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        text_features <span class="op">=</span> h_n[<span class="op">-</span><span class="dv">1</span>]  <span class="co"># Use last hidden state</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        tabular_features <span class="op">=</span> <span class="va">self</span>.tabular_encoder(tabular_data)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Early fusion: concatenate features</span></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        combined_features <span class="op">=</span> torch.cat([image_features, text_features, tabular_features], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Final prediction</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.fusion_layer(combined_features)</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output, {</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>            <span class="st">'image_features'</span>: image_features,</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>            <span class="st">'text_features'</span>: text_features,</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>            <span class="st">'tabular_features'</span>: tabular_features,</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>            <span class="st">'combined_features'</span>: combined_features</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LateFusionModel(nn.Module):</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Late fusion: combine predictions from separate models"""</span></span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, image_channels<span class="op">=</span><span class="dv">6</span>, text_vocab_size<span class="op">=</span><span class="dv">1000</span>, tabular_features<span class="op">=</span><span class="dv">5</span>, hidden_dim<span class="op">=</span><span class="dv">512</span>, num_classes<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Separate encoders for each modality</span></span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_branch <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(image_channels, <span class="dv">64</span>, <span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>),</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool2d((<span class="dv">4</span>, <span class="dv">4</span>)),</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">64</span> <span class="op">*</span> <span class="dv">16</span>, hidden_dim),</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, num_classes)</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_branch <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>            nn.Embedding(text_vocab_size, <span class="dv">256</span>),</span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a>            nn.LSTM(<span class="dv">256</span>, hidden_dim<span class="op">//</span><span class="dv">2</span>, batch_first<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_classifier <span class="op">=</span> nn.Linear(hidden_dim<span class="op">//</span><span class="dv">2</span>, num_classes)</span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tabular_branch <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a>            nn.Linear(tabular_features, hidden_dim<span class="op">//</span><span class="dv">2</span>),</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim<span class="op">//</span><span class="dv">2</span>, num_classes)</span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fusion weights (learnable)</span></span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fusion_weights <span class="op">=</span> nn.Parameter(torch.ones(<span class="dv">3</span>) <span class="op">/</span> <span class="dv">3</span>)</span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, images, text_tokens, tabular_data):</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get predictions from each branch</span></span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>        image_logits <span class="op">=</span> <span class="va">self</span>.image_branch(images)</span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>        text_features, (h_n, c_n) <span class="op">=</span> <span class="va">self</span>.text_branch(text_tokens)</span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>        text_logits <span class="op">=</span> <span class="va">self</span>.text_classifier(h_n[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a>        tabular_logits <span class="op">=</span> <span class="va">self</span>.tabular_branch(tabular_data)</span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Late fusion: weighted combination of predictions</span></span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a>        fusion_weights <span class="op">=</span> F.softmax(<span class="va">self</span>.fusion_weights, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a>        combined_logits <span class="op">=</span> (fusion_weights[<span class="dv">0</span>] <span class="op">*</span> image_logits <span class="op">+</span> </span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a>                          fusion_weights[<span class="dv">1</span>] <span class="op">*</span> text_logits <span class="op">+</span> </span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a>                          fusion_weights[<span class="dv">2</span>] <span class="op">*</span> tabular_logits)</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> combined_logits, {</span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a>            <span class="st">'image_logits'</span>: image_logits,</span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a>            <span class="st">'text_logits'</span>: text_logits,</span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a>            <span class="st">'tabular_logits'</span>: tabular_logits,</span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a>            <span class="st">'fusion_weights'</span>: fusion_weights</span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare architectures</span></span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compare_fusion_architectures():</span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compare early vs late fusion approaches"""</span></span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create sample data</span></span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> torch.randn(batch_size, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a>    text_tokens <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="dv">1000</span>, (batch_size, <span class="dv">20</span>))</span>
<span id="cb7-124"><a href="#cb7-124" aria-hidden="true" tabindex="-1"></a>    tabular_data <span class="op">=</span> torch.randn(batch_size, <span class="dv">5</span>)</span>
<span id="cb7-125"><a href="#cb7-125" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-126"><a href="#cb7-126" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create models</span></span>
<span id="cb7-127"><a href="#cb7-127" aria-hidden="true" tabindex="-1"></a>    early_fusion <span class="op">=</span> EarlyFusionModel()</span>
<span id="cb7-128"><a href="#cb7-128" aria-hidden="true" tabindex="-1"></a>    late_fusion <span class="op">=</span> LateFusionModel()</span>
<span id="cb7-129"><a href="#cb7-129" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-130"><a href="#cb7-130" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Count parameters</span></span>
<span id="cb7-131"><a href="#cb7-131" aria-hidden="true" tabindex="-1"></a>    early_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> early_fusion.parameters())</span>
<span id="cb7-132"><a href="#cb7-132" aria-hidden="true" tabindex="-1"></a>    late_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> late_fusion.parameters())</span>
<span id="cb7-133"><a href="#cb7-133" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-134"><a href="#cb7-134" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Fusion Architecture Comparison:"</span>)</span>
<span id="cb7-135"><a href="#cb7-135" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb7-136"><a href="#cb7-136" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Early Fusion Parameters: </span><span class="sc">{</span>early_params<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb7-137"><a href="#cb7-137" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Late Fusion Parameters: </span><span class="sc">{</span>late_params<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb7-138"><a href="#cb7-138" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-139"><a href="#cb7-139" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass</span></span>
<span id="cb7-140"><a href="#cb7-140" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb7-141"><a href="#cb7-141" aria-hidden="true" tabindex="-1"></a>        early_output, early_features <span class="op">=</span> early_fusion(images, text_tokens, tabular_data)</span>
<span id="cb7-142"><a href="#cb7-142" aria-hidden="true" tabindex="-1"></a>        late_output, late_features <span class="op">=</span> late_fusion(images, text_tokens, tabular_data)</span>
<span id="cb7-143"><a href="#cb7-143" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-144"><a href="#cb7-144" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Output shapes:"</span>)</span>
<span id="cb7-145"><a href="#cb7-145" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Early Fusion: </span><span class="sc">{</span>early_output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-146"><a href="#cb7-146" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Late Fusion: </span><span class="sc">{</span>late_output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-147"><a href="#cb7-147" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-148"><a href="#cb7-148" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Late Fusion Weights: </span><span class="sc">{</span>late_features[<span class="st">'fusion_weights'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-149"><a href="#cb7-149" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-150"><a href="#cb7-150" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> early_fusion, late_fusion</span>
<span id="cb7-151"><a href="#cb7-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-152"><a href="#cb7-152" aria-hidden="true" tabindex="-1"></a>early_model, late_model <span class="op">=</span> compare_fusion_architectures()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fusion Architecture Comparison:
==================================================
Early Fusion Parameters: 2,120,138
Late Fusion Parameters: 1,337,825

Output shapes:
Early Fusion: torch.Size([4, 10])
Late Fusion: torch.Size([4, 10])

Late Fusion Weights: tensor([0.3333, 0.3333, 0.3333])</code></pre>
</div>
</div>
</section>
<section id="attention-based-fusion" class="level3">
<h3 class="anchored" data-anchor-id="attention-based-fusion">Attention-based Fusion</h3>
<div id="02cc2f38" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CrossModalAttentionFusion(nn.Module):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Cross-modal attention fusion mechanism"""</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, feature_dim<span class="op">=</span><span class="dv">512</span>, num_heads<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.feature_dim <span class="op">=</span> feature_dim</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention layers</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_to_text_attention <span class="op">=</span> nn.MultiheadAttention(feature_dim, num_heads, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_to_image_attention <span class="op">=</span> nn.MultiheadAttention(feature_dim, num_heads, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Self-attention for final fusion</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fusion_attention <span class="op">=</span> nn.MultiheadAttention(feature_dim, num_heads, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Layer normalization</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm1 <span class="op">=</span> nn.LayerNorm(feature_dim)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm2 <span class="op">=</span> nn.LayerNorm(feature_dim)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm3 <span class="op">=</span> nn.LayerNorm(feature_dim)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Final classifier</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Linear(feature_dim <span class="op">*</span> <span class="dv">2</span>, <span class="dv">10</span>)  <span class="co"># 10 classes</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, image_features, text_features):</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="co">        image_features: [batch_size, num_patches, feature_dim]</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a><span class="co">        text_features: [batch_size, seq_len, feature_dim]</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-modal attention: image attending to text</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>        image_attended, image_attention_weights <span class="op">=</span> <span class="va">self</span>.image_to_text_attention(</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>            image_features, text_features, text_features</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>        image_attended <span class="op">=</span> <span class="va">self</span>.norm1(image_features <span class="op">+</span> image_attended)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-modal attention: text attending to image</span></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>        text_attended, text_attention_weights <span class="op">=</span> <span class="va">self</span>.text_to_image_attention(</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>            text_features, image_features, image_features</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>        text_attended <span class="op">=</span> <span class="va">self</span>.norm2(text_features <span class="op">+</span> text_attended)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Global pooling</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>        image_global <span class="op">=</span> image_attended.mean(dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># [batch_size, feature_dim]</span></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>        text_global <span class="op">=</span> text_attended.mean(dim<span class="op">=</span><span class="dv">1</span>)    <span class="co"># [batch_size, feature_dim]</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concatenate and classify</span></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat([image_global, text_global], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.classifier(combined)</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output, {</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">'image_attention_weights'</span>: image_attention_weights,</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>            <span class="st">'text_attention_weights'</span>: text_attention_weights,</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>            <span class="st">'image_global'</span>: image_global,</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>            <span class="st">'text_global'</span>: text_global</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstrate cross-modal attention</span></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_cross_modal_attention():</span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show cross-modal attention mechanism"""</span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>    batch_size, feature_dim <span class="op">=</span> <span class="dv">4</span>, <span class="dv">512</span></span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>    num_image_patches, seq_len <span class="op">=</span> <span class="dv">16</span>, <span class="dv">10</span></span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create sample features</span></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>    image_features <span class="op">=</span> torch.randn(batch_size, num_image_patches, feature_dim)</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>    text_features <span class="op">=</span> torch.randn(batch_size, seq_len, feature_dim)</span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create attention model</span></span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>    attention_fusion <span class="op">=</span> CrossModalAttentionFusion(feature_dim<span class="op">=</span>feature_dim)</span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass</span></span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>        output, attention_info <span class="op">=</span> attention_fusion(image_features, text_features)</span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Cross-modal Attention Results:"</span>)</span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">40</span>)</span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Input shapes:"</span>)</span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Image features: </span><span class="sc">{</span>image_features<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Text features: </span><span class="sc">{</span>text_features<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Output shape: </span><span class="sc">{</span>output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize attention weights</span></span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Image-to-text attention (first sample)</span></span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a>    img_to_text_attn <span class="op">=</span> attention_info[<span class="st">'image_attention_weights'</span>][<span class="dv">0</span>].detach().numpy()</span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>    im1 <span class="op">=</span> axes[<span class="dv">0</span>].imshow(img_to_text_attn, cmap<span class="op">=</span><span class="st">'Blues'</span>, aspect<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_title(<span class="st">'Image-to-Text Attention'</span>)</span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Text Positions'</span>)</span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Image Patches'</span>)</span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(im1, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Text-to-image attention (first sample)</span></span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a>    text_to_img_attn <span class="op">=</span> attention_info[<span class="st">'text_attention_weights'</span>][<span class="dv">0</span>].detach().numpy()</span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>    im2 <span class="op">=</span> axes[<span class="dv">1</span>].imshow(text_to_img_attn, cmap<span class="op">=</span><span class="st">'Reds'</span>, aspect<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_title(<span class="st">'Text-to-Image Attention'</span>)</span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Image Patches'</span>)</span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Text Positions'</span>)</span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(im2, ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> attention_fusion</span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a>attention_model <span class="op">=</span> demonstrate_cross_modal_attention()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cross-modal Attention Results:
========================================
Input shapes:
  Image features: torch.Size([4, 16, 512])
  Text features: torch.Size([4, 10, 512])
Output shape: torch.Size([4, 10])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="multimodal_learning_files/figure-html/cell-6-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="contrastive-learning-for-multi-modal-data" class="level2">
<h2 class="anchored" data-anchor-id="contrastive-learning-for-multi-modal-data">Contrastive Learning for Multi-modal Data</h2>
<section id="clip-style-contrastive-learning" class="level3">
<h3 class="anchored" data-anchor-id="clip-style-contrastive-learning">CLIP-style Contrastive Learning</h3>
<div id="0fff1c89" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ContrastiveLearningModel(nn.Module):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""CLIP-style contrastive learning for image-text pairs"""</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, image_encoder_dim<span class="op">=</span><span class="dv">2048</span>, text_encoder_dim<span class="op">=</span><span class="dv">768</span>, projection_dim<span class="op">=</span><span class="dv">512</span>):</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simplified image encoder</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">6</span>, <span class="dv">64</span>, <span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>),  <span class="co"># 6 channels for multispectral</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">64</span>, <span class="dv">128</span>, <span class="dv">5</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">128</span>, <span class="dv">256</span>, <span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool2d((<span class="dv">1</span>, <span class="dv">1</span>)),</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">256</span>, image_encoder_dim)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simplified text encoder</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>            nn.Embedding(<span class="dv">10000</span>, <span class="dv">256</span>),  <span class="co"># Vocab size 10000</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>            nn.LSTM(<span class="dv">256</span>, text_encoder_dim<span class="op">//</span><span class="dv">2</span>, batch_first<span class="op">=</span><span class="va">True</span>, bidirectional<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Projection heads</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_projection <span class="op">=</span> nn.Sequential(</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>            nn.Linear(image_encoder_dim, projection_dim),</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>            nn.Linear(projection_dim, projection_dim)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_projection <span class="op">=</span> nn.Sequential(</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>            nn.Linear(text_encoder_dim, projection_dim),</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>            nn.Linear(projection_dim, projection_dim)</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Temperature parameter for contrastive loss</span></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.temperature <span class="op">=</span> nn.Parameter(torch.tensor(<span class="fl">0.07</span>))</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, images, text_tokens):</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode images</span></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>        image_features <span class="op">=</span> <span class="va">self</span>.image_encoder(images)</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>        image_embeddings <span class="op">=</span> <span class="va">self</span>.image_projection(image_features)</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode text</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>        text_features, (h_n, c_n) <span class="op">=</span> <span class="va">self</span>.text_encoder(text_tokens)</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use final hidden states from both directions</span></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>        text_features <span class="op">=</span> torch.cat([h_n[<span class="op">-</span><span class="dv">2</span>], h_n[<span class="op">-</span><span class="dv">1</span>]], dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Concatenate bidirectional</span></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>        text_embeddings <span class="op">=</span> <span class="va">self</span>.text_projection(text_features)</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize embeddings</span></span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>        image_embeddings <span class="op">=</span> F.normalize(image_embeddings, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>        text_embeddings <span class="op">=</span> F.normalize(text_embeddings, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> image_embeddings, text_embeddings</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> contrastive_loss(<span class="va">self</span>, image_embeddings, text_embeddings):</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Calculate contrastive loss between image and text embeddings"""</span></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> image_embeddings.shape[<span class="dv">0</span>]</span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate similarity matrix</span></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a>        similarity_matrix <span class="op">=</span> torch.matmul(image_embeddings, text_embeddings.T) <span class="op">/</span> <span class="va">self</span>.temperature</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create labels (diagonal should be positive pairs)</span></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> torch.arange(batch_size, device<span class="op">=</span>image_embeddings.device)</span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Contrastive loss (symmetric)</span></span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a>        loss_img_to_text <span class="op">=</span> F.cross_entropy(similarity_matrix, labels)</span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>        loss_text_to_img <span class="op">=</span> F.cross_entropy(similarity_matrix.T, labels)</span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> (loss_img_to_text <span class="op">+</span> loss_text_to_img) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> total_loss, similarity_matrix</span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_contrastive_learning():</span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Demonstrate contrastive learning training"""</span></span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create model</span></span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a>    contrastive_model <span class="op">=</span> ContrastiveLearningModel()</span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample data</span></span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> torch.randn(batch_size, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a>    text_tokens <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="dv">10000</span>, (batch_size, <span class="dv">20</span>))</span>
<span id="cb11-88"><a href="#cb11-88" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass</span></span>
<span id="cb11-90"><a href="#cb11-90" aria-hidden="true" tabindex="-1"></a>    image_embeddings, text_embeddings <span class="op">=</span> contrastive_model(images, text_tokens)</span>
<span id="cb11-91"><a href="#cb11-91" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-92"><a href="#cb11-92" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate loss</span></span>
<span id="cb11-93"><a href="#cb11-93" aria-hidden="true" tabindex="-1"></a>    loss, similarity_matrix <span class="op">=</span> contrastive_model.contrastive_loss(image_embeddings, text_embeddings)</span>
<span id="cb11-94"><a href="#cb11-94" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-95"><a href="#cb11-95" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Contrastive Learning Results:"</span>)</span>
<span id="cb11-96"><a href="#cb11-96" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">40</span>)</span>
<span id="cb11-97"><a href="#cb11-97" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Image embeddings shape: </span><span class="sc">{</span>image_embeddings<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-98"><a href="#cb11-98" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text embeddings shape: </span><span class="sc">{</span>text_embeddings<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-99"><a href="#cb11-99" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Contrastive loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb11-100"><a href="#cb11-100" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Temperature: </span><span class="sc">{</span>contrastive_model<span class="sc">.</span>temperature<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb11-101"><a href="#cb11-101" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-102"><a href="#cb11-102" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize similarity matrix</span></span>
<span id="cb11-103"><a href="#cb11-103" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb11-104"><a href="#cb11-104" aria-hidden="true" tabindex="-1"></a>    plt.imshow(similarity_matrix.detach().numpy(), cmap<span class="op">=</span><span class="st">'RdBu_r'</span>, aspect<span class="op">=</span><span class="st">'equal'</span>)</span>
<span id="cb11-105"><a href="#cb11-105" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(label<span class="op">=</span><span class="st">'Similarity Score'</span>)</span>
<span id="cb11-106"><a href="#cb11-106" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Image-Text Similarity Matrix'</span>)</span>
<span id="cb11-107"><a href="#cb11-107" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Text Samples'</span>)</span>
<span id="cb11-108"><a href="#cb11-108" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Image Samples'</span>)</span>
<span id="cb11-109"><a href="#cb11-109" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-110"><a href="#cb11-110" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Highlight diagonal (positive pairs)</span></span>
<span id="cb11-111"><a href="#cb11-111" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb11-112"><a href="#cb11-112" aria-hidden="true" tabindex="-1"></a>        plt.scatter(i, i, marker<span class="op">=</span><span class="st">'x'</span>, s<span class="op">=</span><span class="dv">100</span>, color<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-113"><a href="#cb11-113" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-114"><a href="#cb11-114" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb11-115"><a href="#cb11-115" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb11-116"><a href="#cb11-116" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-117"><a href="#cb11-117" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show top-k retrievals</span></span>
<span id="cb11-118"><a href="#cb11-118" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> show_retrievals(similarity_matrix, k<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb11-119"><a href="#cb11-119" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Show top-k text retrievals for each image"""</span></span>
<span id="cb11-120"><a href="#cb11-120" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-121"><a href="#cb11-121" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Top-</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> Text Retrievals for Each Image:"</span>)</span>
<span id="cb11-122"><a href="#cb11-122" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb11-123"><a href="#cb11-123" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-124"><a href="#cb11-124" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> img_idx <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb11-125"><a href="#cb11-125" aria-hidden="true" tabindex="-1"></a>            similarities <span class="op">=</span> similarity_matrix[img_idx]</span>
<span id="cb11-126"><a href="#cb11-126" aria-hidden="true" tabindex="-1"></a>            top_k_indices <span class="op">=</span> similarities.topk(k).indices</span>
<span id="cb11-127"><a href="#cb11-127" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb11-128"><a href="#cb11-128" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Image </span><span class="sc">{</span>img_idx<span class="sc">}</span><span class="ss">: Text indices </span><span class="sc">{</span>top_k_indices<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-129"><a href="#cb11-129" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  Similarities: </span><span class="sc">{</span>similarities[top_k_indices]<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb11-130"><a href="#cb11-130" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-131"><a href="#cb11-131" aria-hidden="true" tabindex="-1"></a>    show_retrievals(similarity_matrix)</span>
<span id="cb11-132"><a href="#cb11-132" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-133"><a href="#cb11-133" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> contrastive_model</span>
<span id="cb11-134"><a href="#cb11-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-135"><a href="#cb11-135" aria-hidden="true" tabindex="-1"></a>contrastive_model <span class="op">=</span> demonstrate_contrastive_learning()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Contrastive Learning Results:
========================================
Image embeddings shape: torch.Size([8, 512])
Text embeddings shape: torch.Size([8, 512])
Contrastive loss: 2.0960
Temperature: 0.0700</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="multimodal_learning_files/figure-html/cell-7-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Top-3 Text Retrievals for Each Image:
----------------------------------------
Image 0: Text indices [5, 4, 1]
  Similarities: [0.06918489187955856, -0.038237396627664566, -0.05621049180626869]
Image 1: Text indices [5, 4, 1]
  Similarities: [0.0625985637307167, -0.04189909249544144, -0.059174180030822754]
Image 2: Text indices [5, 4, 1]
  Similarities: [0.07691492140293121, -0.03728947788476944, -0.05371379479765892]
Image 3: Text indices [5, 4, 1]
  Similarities: [0.07068105041980743, -0.04271123185753822, -0.061762817203998566]
Image 4: Text indices [5, 4, 1]
  Similarities: [0.07277499884366989, -0.041178036481142044, -0.05575103312730789]
Image 5: Text indices [5, 4, 1]
  Similarities: [0.07348140329122543, -0.03945738822221756, -0.056685615330934525]
Image 6: Text indices [5, 4, 1]
  Similarities: [0.06902169436216354, -0.04555588960647583, -0.05787457898259163]
Image 7: Text indices [5, 4, 1]
  Similarities: [0.07388690114021301, -0.03497040271759033, -0.05493520572781563]</code></pre>
</div>
</div>
</section>
<section id="zero-shot-classification" class="level3">
<h3 class="anchored" data-anchor-id="zero-shot-classification">Zero-Shot Classification</h3>
<div id="2d7a2b2a" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_zero_shot_classification():</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show zero-shot classification using learned embeddings"""</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate a trained contrastive model</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> contrastive_model  <span class="co"># Use the model from previous example</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define text prompts for different land cover classes</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    class_descriptions <span class="op">=</span> {</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'forest'</span>: <span class="st">"Dense forest area with trees and vegetation"</span>,</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'urban'</span>: <span class="st">"Urban area with buildings and infrastructure"</span>, </span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'water'</span>: <span class="st">"Water body such as lake or river"</span>,</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'agriculture'</span>: <span class="st">"Agricultural land with crops and farming"</span>,</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'desert'</span>: <span class="st">"Desert area with sand and minimal vegetation"</span>,</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'grassland'</span>: <span class="st">"Grassland area with grass and open space"</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert descriptions to tokens (simplified)</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> simple_tokenize(text, max_length<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Simple tokenization for demonstration"""</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        words <span class="op">=</span> text.lower().split()[:max_length]</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Map words to random token IDs for demo</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        np.random.seed(<span class="bu">hash</span>(text) <span class="op">%</span> <span class="dv">1000</span>)  <span class="co"># Consistent random mapping</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> [np.random.randint(<span class="dv">0</span>, <span class="dv">10000</span>) <span class="cf">for</span> _ <span class="kw">in</span> words]</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pad to max_length</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">+=</span> [<span class="dv">0</span>] <span class="op">*</span> (max_length <span class="op">-</span> <span class="bu">len</span>(tokens))</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.tensor(tokens[:max_length])</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create text embeddings for each class</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>    class_embeddings <span class="op">=</span> {}</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> class_name, description <span class="kw">in</span> class_descriptions.items():</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>            tokens <span class="op">=</span> simple_tokenize(description).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>            _, text_embedding <span class="op">=</span> model(torch.zeros(<span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span>), tokens)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>            class_embeddings[class_name] <span class="op">=</span> text_embedding.squeeze(<span class="dv">0</span>)</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Test images (simulate different land covers)</span></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>    test_images <span class="op">=</span> torch.randn(<span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span>)  <span class="co"># 6 test images</span></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>        test_image_embeddings, _ <span class="op">=</span> model(test_images, torch.zeros(<span class="dv">6</span>, <span class="dv">20</span>, dtype<span class="op">=</span>torch.<span class="bu">long</span>))</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate similarities and classify</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> []</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>    similarities_all <span class="op">=</span> []</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, img_embedding <span class="kw">in</span> <span class="bu">enumerate</span>(test_image_embeddings):</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>        similarities <span class="op">=</span> {}</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> class_name, class_embedding <span class="kw">in</span> class_embeddings.items():</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>            similarity <span class="op">=</span> F.cosine_similarity(img_embedding, class_embedding, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>            similarities[class_name] <span class="op">=</span> similarity.item()</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get predicted class</span></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>        predicted_class <span class="op">=</span> <span class="bu">max</span>(similarities, key<span class="op">=</span>similarities.get)</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>        predictions.append(predicted_class)</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>        similarities_all.append(similarities)</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display results</span></span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Zero-Shot Classification Results:"</span>)</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>    class_names <span class="op">=</span> <span class="bu">list</span>(class_descriptions.keys())</span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a>    similarity_matrix <span class="op">=</span> np.zeros((<span class="bu">len</span>(test_images), <span class="bu">len</span>(class_names)))</span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, similarities <span class="kw">in</span> <span class="bu">enumerate</span>(similarities_all):</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Test Image </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: Predicted as '</span><span class="sc">{</span>predictions[i]<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j, class_name <span class="kw">in</span> <span class="bu">enumerate</span>(class_names):</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a>            similarity_matrix[i, j] <span class="op">=</span> similarities[class_name]</span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>class_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>similarities[class_name]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize similarity heatmap</span></span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a>    plt.imshow(similarity_matrix, cmap<span class="op">=</span><span class="st">'RdYlBu_r'</span>, aspect<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(label<span class="op">=</span><span class="st">'Cosine Similarity'</span>)</span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Classes'</span>)</span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Test Images'</span>)</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(class_names)), class_names, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a>    plt.yticks(<span class="bu">range</span>(<span class="bu">len</span>(test_images)), [<span class="ss">f'Image </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_images))])</span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Zero-Shot Classification Similarities'</span>)</span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add prediction markers</span></span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, pred_class <span class="kw">in</span> <span class="bu">enumerate</span>(predictions):</span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a>        j <span class="op">=</span> class_names.index(pred_class)</span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a>        plt.scatter(j, i, marker<span class="op">=</span><span class="st">'x'</span>, s<span class="op">=</span><span class="dv">200</span>, color<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions, similarities_all</span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a>zeroshot_predictions, zeroshot_similarities <span class="op">=</span> demonstrate_zero_shot_classification()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Zero-Shot Classification Results:
==================================================

Test Image 0: Predicted as 'urban'
  forest: -0.050
  urban: -0.017
  water: -0.062
  agriculture: -0.053
  desert: -0.064
  grassland: -0.032

Test Image 1: Predicted as 'urban'
  forest: -0.050
  urban: -0.017
  water: -0.061
  agriculture: -0.053
  desert: -0.064
  grassland: -0.032

Test Image 2: Predicted as 'urban'
  forest: -0.049
  urban: -0.016
  water: -0.061
  agriculture: -0.053
  desert: -0.064
  grassland: -0.031

Test Image 3: Predicted as 'urban'
  forest: -0.050
  urban: -0.017
  water: -0.061
  agriculture: -0.053
  desert: -0.064
  grassland: -0.032

Test Image 4: Predicted as 'urban'
  forest: -0.050
  urban: -0.017
  water: -0.061
  agriculture: -0.053
  desert: -0.064
  grassland: -0.032

Test Image 5: Predicted as 'urban'
  forest: -0.049
  urban: -0.016
  water: -0.061
  agriculture: -0.053
  desert: -0.064
  grassland: -0.032</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="multimodal_learning_files/figure-html/cell-8-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="multi-modal-data-augmentation" class="level2">
<h2 class="anchored" data-anchor-id="multi-modal-data-augmentation">Multi-modal Data Augmentation</h2>
<section id="cross-modal-data-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="cross-modal-data-augmentation">Cross-modal Data Augmentation</h3>
<div id="8e6eb29a" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_multimodal_augmentation():</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show augmentation techniques for multi-modal data"""</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original data</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    original_images <span class="op">=</span> torch.randn(batch_size, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    original_texts <span class="op">=</span> [</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Forest area with dense canopy"</span>,</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Urban residential district"</span>, </span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Agricultural crop fields"</span>,</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Coastal wetland ecosystem"</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">class</span> MultiModalAugmentation:</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Multi-modal data augmentation techniques"""</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.augmentation_strategies <span class="op">=</span> [</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>                <span class="st">'spatial_crop'</span>,</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>                <span class="st">'spectral_shift'</span>,</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>                <span class="st">'text_synonym'</span>,</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>                <span class="st">'mixup'</span>,</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>                <span class="st">'cutmix'</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> spatial_crop(<span class="va">self</span>, images, texts, crop_ratio<span class="op">=</span><span class="fl">0.8</span>):</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>            <span class="co">"""Spatial cropping with corresponding text modification"""</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>            _, _, h, w <span class="op">=</span> images.shape</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>            crop_h, crop_w <span class="op">=</span> <span class="bu">int</span>(h <span class="op">*</span> crop_ratio), <span class="bu">int</span>(w <span class="op">*</span> crop_ratio)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Random crop position</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>            start_h <span class="op">=</span> torch.randint(<span class="dv">0</span>, h <span class="op">-</span> crop_h <span class="op">+</span> <span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>            start_w <span class="op">=</span> torch.randint(<span class="dv">0</span>, w <span class="op">-</span> crop_w <span class="op">+</span> <span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Crop images</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>            cropped_images <span class="op">=</span> images[:, :, start_h:start_h<span class="op">+</span>crop_h, start_w:start_w<span class="op">+</span>crop_w]</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Resize back to original size</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>            cropped_images <span class="op">=</span> F.interpolate(cropped_images, size<span class="op">=</span>(h, w), mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Modify texts to indicate cropping</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>            modified_texts <span class="op">=</span> [<span class="ss">f"Cropped view of </span><span class="sc">{</span>text<span class="sc">.</span>lower()<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> text <span class="kw">in</span> texts]</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> cropped_images, modified_texts</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> spectral_shift(<span class="va">self</span>, images, texts, shift_factor<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>            <span class="co">"""Spectral band shifting"""</span></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Randomly shift spectral bands</span></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>            shifted_images <span class="op">=</span> images.clone()</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(images.shape[<span class="dv">1</span>]):  <span class="co"># For each spectral band</span></span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>                shift <span class="op">=</span> torch.normal(<span class="dv">0</span>, shift_factor, size<span class="op">=</span>(<span class="dv">1</span>,)).item()</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>                shifted_images[:, i] <span class="op">=</span> images[:, i] <span class="op">+</span> shift</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Clamp to valid range</span></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>            shifted_images <span class="op">=</span> torch.clamp(shifted_images, <span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)  <span class="co"># Assuming normalized data</span></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Modify texts to indicate spectral variation</span></span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>            modified_texts <span class="op">=</span> [<span class="ss">f"</span><span class="sc">{</span>text<span class="sc">}</span><span class="ss"> with spectral variation"</span> <span class="cf">for</span> text <span class="kw">in</span> texts]</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> shifted_images, modified_texts</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> text_synonym_replacement(<span class="va">self</span>, texts, replacement_prob<span class="op">=</span><span class="fl">0.3</span>):</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>            <span class="co">"""Replace words with synonyms"""</span></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Simple synonym dictionary</span></span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>            synonyms <span class="op">=</span> {</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>                <span class="st">'forest'</span>: [<span class="st">'woodland'</span>, <span class="st">'trees'</span>, <span class="st">'vegetation'</span>],</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>                <span class="st">'urban'</span>: [<span class="st">'city'</span>, <span class="st">'metropolitan'</span>, <span class="st">'developed'</span>],</span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a>                <span class="st">'agricultural'</span>: [<span class="st">'farming'</span>, <span class="st">'crop'</span>, <span class="st">'cultivation'</span>],</span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a>                <span class="st">'area'</span>: [<span class="st">'region'</span>, <span class="st">'zone'</span>, <span class="st">'location'</span>],</span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a>                <span class="st">'dense'</span>: [<span class="st">'thick'</span>, <span class="st">'concentrated'</span>, <span class="st">'heavy'</span>]</span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>            modified_texts <span class="op">=</span> []</span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> text <span class="kw">in</span> texts:</span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a>                words <span class="op">=</span> text.split()</span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a>                new_words <span class="op">=</span> []</span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a>                    word_lower <span class="op">=</span> word.lower()</span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> word_lower <span class="kw">in</span> synonyms <span class="kw">and</span> torch.rand(<span class="dv">1</span>).item() <span class="op">&lt;</span> replacement_prob:</span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a>                        synonym <span class="op">=</span> np.random.choice(synonyms[word_lower])</span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a>                        new_words.append(synonym)</span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">else</span>:</span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a>                        new_words.append(word)</span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a>                modified_texts.append(<span class="st">' '</span>.join(new_words))</span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> modified_texts</span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> mixup_multimodal(<span class="va">self</span>, images, texts, alpha<span class="op">=</span><span class="fl">0.4</span>):</span>
<span id="cb16-94"><a href="#cb16-94" aria-hidden="true" tabindex="-1"></a>            <span class="co">"""MixUp augmentation for multi-modal data"""</span></span>
<span id="cb16-95"><a href="#cb16-95" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(images) <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb16-97"><a href="#cb16-97" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> images, texts</span>
<span id="cb16-98"><a href="#cb16-98" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Generate mixing weights</span></span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a>            lam <span class="op">=</span> np.random.beta(alpha, alpha)</span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-102"><a href="#cb16-102" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Shuffle indices for mixing</span></span>
<span id="cb16-103"><a href="#cb16-103" aria-hidden="true" tabindex="-1"></a>            batch_size <span class="op">=</span> images.shape[<span class="dv">0</span>]</span>
<span id="cb16-104"><a href="#cb16-104" aria-hidden="true" tabindex="-1"></a>            indices <span class="op">=</span> torch.randperm(batch_size)</span>
<span id="cb16-105"><a href="#cb16-105" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-106"><a href="#cb16-106" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Mix images</span></span>
<span id="cb16-107"><a href="#cb16-107" aria-hidden="true" tabindex="-1"></a>            mixed_images <span class="op">=</span> lam <span class="op">*</span> images <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> lam) <span class="op">*</span> images[indices]</span>
<span id="cb16-108"><a href="#cb16-108" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-109"><a href="#cb16-109" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Mix texts (concatenate with mixing indicator)</span></span>
<span id="cb16-110"><a href="#cb16-110" aria-hidden="true" tabindex="-1"></a>            mixed_texts <span class="op">=</span> []</span>
<span id="cb16-111"><a href="#cb16-111" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(texts)):</span>
<span id="cb16-112"><a href="#cb16-112" aria-hidden="true" tabindex="-1"></a>                mixed_texts.append(<span class="ss">f"Mixed scene: </span><span class="sc">{</span>lam<span class="sc">:.2f}</span><span class="ss"> * (</span><span class="sc">{</span>texts[i]<span class="sc">}</span><span class="ss">) + </span><span class="sc">{</span><span class="dv">1</span><span class="op">-</span>lam<span class="sc">:.2f}</span><span class="ss"> * (</span><span class="sc">{</span>texts[indices[i]]<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb16-113"><a href="#cb16-113" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-114"><a href="#cb16-114" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> mixed_images, mixed_texts</span>
<span id="cb16-115"><a href="#cb16-115" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-116"><a href="#cb16-116" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> cutmix_multimodal(<span class="va">self</span>, images, texts, alpha<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb16-117"><a href="#cb16-117" aria-hidden="true" tabindex="-1"></a>            <span class="co">"""CutMix augmentation for multi-modal data"""</span></span>
<span id="cb16-118"><a href="#cb16-118" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-119"><a href="#cb16-119" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(images) <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb16-120"><a href="#cb16-120" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> images, texts</span>
<span id="cb16-121"><a href="#cb16-121" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-122"><a href="#cb16-122" aria-hidden="true" tabindex="-1"></a>            lam <span class="op">=</span> np.random.beta(alpha, alpha)</span>
<span id="cb16-123"><a href="#cb16-123" aria-hidden="true" tabindex="-1"></a>            batch_size <span class="op">=</span> images.shape[<span class="dv">0</span>]</span>
<span id="cb16-124"><a href="#cb16-124" aria-hidden="true" tabindex="-1"></a>            indices <span class="op">=</span> torch.randperm(batch_size)</span>
<span id="cb16-125"><a href="#cb16-125" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-126"><a href="#cb16-126" aria-hidden="true" tabindex="-1"></a>            _, _, h, w <span class="op">=</span> images.shape</span>
<span id="cb16-127"><a href="#cb16-127" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-128"><a href="#cb16-128" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Generate random bounding box</span></span>
<span id="cb16-129"><a href="#cb16-129" aria-hidden="true" tabindex="-1"></a>            cut_rat <span class="op">=</span> np.sqrt(<span class="fl">1.</span> <span class="op">-</span> lam)</span>
<span id="cb16-130"><a href="#cb16-130" aria-hidden="true" tabindex="-1"></a>            cut_w <span class="op">=</span> <span class="bu">int</span>(w <span class="op">*</span> cut_rat)</span>
<span id="cb16-131"><a href="#cb16-131" aria-hidden="true" tabindex="-1"></a>            cut_h <span class="op">=</span> <span class="bu">int</span>(h <span class="op">*</span> cut_rat)</span>
<span id="cb16-132"><a href="#cb16-132" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-133"><a href="#cb16-133" aria-hidden="true" tabindex="-1"></a>            cx <span class="op">=</span> np.random.randint(w)</span>
<span id="cb16-134"><a href="#cb16-134" aria-hidden="true" tabindex="-1"></a>            cy <span class="op">=</span> np.random.randint(h)</span>
<span id="cb16-135"><a href="#cb16-135" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-136"><a href="#cb16-136" aria-hidden="true" tabindex="-1"></a>            bbx1 <span class="op">=</span> np.clip(cx <span class="op">-</span> cut_w <span class="op">//</span> <span class="dv">2</span>, <span class="dv">0</span>, w)</span>
<span id="cb16-137"><a href="#cb16-137" aria-hidden="true" tabindex="-1"></a>            bby1 <span class="op">=</span> np.clip(cy <span class="op">-</span> cut_h <span class="op">//</span> <span class="dv">2</span>, <span class="dv">0</span>, h)</span>
<span id="cb16-138"><a href="#cb16-138" aria-hidden="true" tabindex="-1"></a>            bbx2 <span class="op">=</span> np.clip(cx <span class="op">+</span> cut_w <span class="op">//</span> <span class="dv">2</span>, <span class="dv">0</span>, w)</span>
<span id="cb16-139"><a href="#cb16-139" aria-hidden="true" tabindex="-1"></a>            bby2 <span class="op">=</span> np.clip(cy <span class="op">+</span> cut_h <span class="op">//</span> <span class="dv">2</span>, <span class="dv">0</span>, h)</span>
<span id="cb16-140"><a href="#cb16-140" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-141"><a href="#cb16-141" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Apply cutmix</span></span>
<span id="cb16-142"><a href="#cb16-142" aria-hidden="true" tabindex="-1"></a>            mixed_images <span class="op">=</span> images.clone()</span>
<span id="cb16-143"><a href="#cb16-143" aria-hidden="true" tabindex="-1"></a>            mixed_images[:, :, bby1:bby2, bbx1:bbx2] <span class="op">=</span> images[indices, :, bby1:bby2, bbx1:bbx2]</span>
<span id="cb16-144"><a href="#cb16-144" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-145"><a href="#cb16-145" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Mix texts</span></span>
<span id="cb16-146"><a href="#cb16-146" aria-hidden="true" tabindex="-1"></a>            mixed_texts <span class="op">=</span> []</span>
<span id="cb16-147"><a href="#cb16-147" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(texts)):</span>
<span id="cb16-148"><a href="#cb16-148" aria-hidden="true" tabindex="-1"></a>                mixed_texts.append(<span class="ss">f"Scene with cutmix: </span><span class="sc">{</span>texts[i]<span class="sc">}</span><span class="ss"> + patch from </span><span class="sc">{</span>texts[indices[i]]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-149"><a href="#cb16-149" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-150"><a href="#cb16-150" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> mixed_images, mixed_texts</span>
<span id="cb16-151"><a href="#cb16-151" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-152"><a href="#cb16-152" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Demonstrate augmentations</span></span>
<span id="cb16-153"><a href="#cb16-153" aria-hidden="true" tabindex="-1"></a>    augmenter <span class="op">=</span> MultiModalAugmentation()</span>
<span id="cb16-154"><a href="#cb16-154" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-155"><a href="#cb16-155" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-modal Data Augmentation Examples:"</span>)</span>
<span id="cb16-156"><a href="#cb16-156" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb16-157"><a href="#cb16-157" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-158"><a href="#cb16-158" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original</span></span>
<span id="cb16-159"><a href="#cb16-159" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Original texts:"</span>)</span>
<span id="cb16-160"><a href="#cb16-160" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, text <span class="kw">in</span> <span class="bu">enumerate</span>(original_texts):</span>
<span id="cb16-161"><a href="#cb16-161" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-162"><a href="#cb16-162" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-163"><a href="#cb16-163" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Spatial crop</span></span>
<span id="cb16-164"><a href="#cb16-164" aria-hidden="true" tabindex="-1"></a>    cropped_imgs, cropped_texts <span class="op">=</span> augmenter.spatial_crop(original_images, original_texts)</span>
<span id="cb16-165"><a href="#cb16-165" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Spatial Crop:"</span>)</span>
<span id="cb16-166"><a href="#cb16-166" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Image shape change: </span><span class="sc">{</span>original_images<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span>cropped_imgs<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-167"><a href="#cb16-167" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, text <span class="kw">in</span> <span class="bu">enumerate</span>(cropped_texts[:<span class="dv">2</span>]):  <span class="co"># Show first 2</span></span>
<span id="cb16-168"><a href="#cb16-168" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-169"><a href="#cb16-169" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-170"><a href="#cb16-170" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Spectral shift</span></span>
<span id="cb16-171"><a href="#cb16-171" aria-hidden="true" tabindex="-1"></a>    shifted_imgs, shifted_texts <span class="op">=</span> augmenter.spectral_shift(original_images, original_texts)</span>
<span id="cb16-172"><a href="#cb16-172" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Spectral Shift:"</span>)</span>
<span id="cb16-173"><a href="#cb16-173" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Value range change: [</span><span class="sc">{</span>original_images<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>original_images<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.2f}</span><span class="ss">] -&gt; [</span><span class="sc">{</span>shifted_imgs<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>shifted_imgs<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb16-174"><a href="#cb16-174" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-175"><a href="#cb16-175" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Text synonym replacement</span></span>
<span id="cb16-176"><a href="#cb16-176" aria-hidden="true" tabindex="-1"></a>    synonym_texts <span class="op">=</span> augmenter.text_synonym_replacement(original_texts)</span>
<span id="cb16-177"><a href="#cb16-177" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Synonym Replacement:"</span>)</span>
<span id="cb16-178"><a href="#cb16-178" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (orig, syn) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(original_texts[:<span class="dv">2</span>], synonym_texts[:<span class="dv">2</span>])):</span>
<span id="cb16-179"><a href="#cb16-179" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: '</span><span class="sc">{</span>orig<span class="sc">}</span><span class="ss">' -&gt; '</span><span class="sc">{</span>syn<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb16-180"><a href="#cb16-180" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-181"><a href="#cb16-181" aria-hidden="true" tabindex="-1"></a>    <span class="co"># MixUp</span></span>
<span id="cb16-182"><a href="#cb16-182" aria-hidden="true" tabindex="-1"></a>    mixup_imgs, mixup_texts <span class="op">=</span> augmenter.mixup_multimodal(original_images, original_texts)</span>
<span id="cb16-183"><a href="#cb16-183" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">MixUp:"</span>)</span>
<span id="cb16-184"><a href="#cb16-184" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Example: </span><span class="sc">{</span>mixup_texts[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-185"><a href="#cb16-185" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-186"><a href="#cb16-186" aria-hidden="true" tabindex="-1"></a>    <span class="co"># CutMix</span></span>
<span id="cb16-187"><a href="#cb16-187" aria-hidden="true" tabindex="-1"></a>    cutmix_imgs, cutmix_texts <span class="op">=</span> augmenter.cutmix_multimodal(original_images, original_texts)</span>
<span id="cb16-188"><a href="#cb16-188" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">CutMix:"</span>)</span>
<span id="cb16-189"><a href="#cb16-189" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Example: </span><span class="sc">{</span>cutmix_texts[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-190"><a href="#cb16-190" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-191"><a href="#cb16-191" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize augmentation effects</span></span>
<span id="cb16-192"><a href="#cb16-192" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">10</span>))</span>
<span id="cb16-193"><a href="#cb16-193" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-194"><a href="#cb16-194" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> visualize_image(img_tensor, ax, title):</span>
<span id="cb16-195"><a href="#cb16-195" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Visualize first 3 channels as RGB"""</span></span>
<span id="cb16-196"><a href="#cb16-196" aria-hidden="true" tabindex="-1"></a>        img_rgb <span class="op">=</span> img_tensor[<span class="dv">0</span>, :<span class="dv">3</span>].detach().numpy().transpose(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)</span>
<span id="cb16-197"><a href="#cb16-197" aria-hidden="true" tabindex="-1"></a>        img_rgb <span class="op">=</span> (img_rgb <span class="op">-</span> img_rgb.<span class="bu">min</span>()) <span class="op">/</span> (img_rgb.<span class="bu">max</span>() <span class="op">-</span> img_rgb.<span class="bu">min</span>())</span>
<span id="cb16-198"><a href="#cb16-198" aria-hidden="true" tabindex="-1"></a>        ax.imshow(img_rgb)</span>
<span id="cb16-199"><a href="#cb16-199" aria-hidden="true" tabindex="-1"></a>        ax.set_title(title)</span>
<span id="cb16-200"><a href="#cb16-200" aria-hidden="true" tabindex="-1"></a>        ax.axis(<span class="st">'off'</span>)</span>
<span id="cb16-201"><a href="#cb16-201" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-202"><a href="#cb16-202" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original and augmented images</span></span>
<span id="cb16-203"><a href="#cb16-203" aria-hidden="true" tabindex="-1"></a>    augmented_images <span class="op">=</span> [</span>
<span id="cb16-204"><a href="#cb16-204" aria-hidden="true" tabindex="-1"></a>        (original_images, <span class="st">"Original"</span>),</span>
<span id="cb16-205"><a href="#cb16-205" aria-hidden="true" tabindex="-1"></a>        (cropped_imgs, <span class="st">"Spatial Crop"</span>),</span>
<span id="cb16-206"><a href="#cb16-206" aria-hidden="true" tabindex="-1"></a>        (shifted_imgs, <span class="st">"Spectral Shift"</span>),</span>
<span id="cb16-207"><a href="#cb16-207" aria-hidden="true" tabindex="-1"></a>        (mixup_imgs, <span class="st">"MixUp"</span>),</span>
<span id="cb16-208"><a href="#cb16-208" aria-hidden="true" tabindex="-1"></a>        (cutmix_imgs, <span class="st">"CutMix"</span>)</span>
<span id="cb16-209"><a href="#cb16-209" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb16-210"><a href="#cb16-210" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-211"><a href="#cb16-211" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (imgs, title) <span class="kw">in</span> <span class="bu">enumerate</span>(augmented_images[:<span class="dv">6</span>]):</span>
<span id="cb16-212"><a href="#cb16-212" aria-hidden="true" tabindex="-1"></a>        row, col <span class="op">=</span> i <span class="op">//</span> <span class="dv">3</span>, i <span class="op">%</span> <span class="dv">3</span></span>
<span id="cb16-213"><a href="#cb16-213" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> row <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb16-214"><a href="#cb16-214" aria-hidden="true" tabindex="-1"></a>            visualize_image(imgs, axes[row, col], title)</span>
<span id="cb16-215"><a href="#cb16-215" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-216"><a href="#cb16-216" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hide unused subplot</span></span>
<span id="cb16-217"><a href="#cb16-217" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(augmented_images) <span class="op">&lt;</span> <span class="dv">6</span>:</span>
<span id="cb16-218"><a href="#cb16-218" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>, <span class="dv">2</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb16-219"><a href="#cb16-219" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-220"><a href="#cb16-220" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb16-221"><a href="#cb16-221" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb16-222"><a href="#cb16-222" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-223"><a href="#cb16-223" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> augmenter</span>
<span id="cb16-224"><a href="#cb16-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-225"><a href="#cb16-225" aria-hidden="true" tabindex="-1"></a>augmenter <span class="op">=</span> demonstrate_multimodal_augmentation()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Multi-modal Data Augmentation Examples:
============================================================
Original texts:
  0: Forest area with dense canopy
  1: Urban residential district
  2: Agricultural crop fields
  3: Coastal wetland ecosystem

Spatial Crop:
  Image shape change: torch.Size([4, 6, 224, 224]) -&gt; torch.Size([4, 6, 224, 224])
  0: Cropped view of forest area with dense canopy
  1: Cropped view of urban residential district

Spectral Shift:
  Value range change: [-5.53, 4.62] -&gt; [-3.00, 3.00]

Synonym Replacement:
  0: 'Forest area with dense canopy' -&gt; 'trees area with dense canopy'
  1: 'Urban residential district' -&gt; 'Urban residential district'

MixUp:
  Example: Mixed scene: 0.66 * (Forest area with dense canopy) + 0.34 * (Urban residential district)

CutMix:
  Example: Scene with cutmix: Forest area with dense canopy + patch from Agricultural crop fields</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="multimodal_learning_files/figure-html/cell-9-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="performance-evaluation-metrics" class="level2">
<h2 class="anchored" data-anchor-id="performance-evaluation-metrics">Performance Evaluation Metrics</h2>
<section id="multi-modal-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="multi-modal-evaluation">Multi-modal Evaluation</h3>
<div id="d8b64d78" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_multimodal_evaluation():</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Demonstrate evaluation metrics for multi-modal models"""</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate predictions and ground truth</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    np.random.seed(<span class="dv">42</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Classification task</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    num_samples <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ground truth</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> np.random.randint(<span class="dv">0</span>, num_classes, num_samples)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate different model predictions</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    models <span class="op">=</span> {</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Image Only'</span>: np.random.multinomial(<span class="dv">1</span>, [<span class="fl">0.8</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>], num_samples).argmax(axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Text Only'</span>: np.random.multinomial(<span class="dv">1</span>, [<span class="fl">0.1</span>, <span class="fl">0.7</span>, <span class="fl">0.1</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>], num_samples).argmax(axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Early Fusion'</span>: np.random.multinomial(<span class="dv">1</span>, [<span class="fl">0.85</span>, <span class="fl">0.04</span>, <span class="fl">0.04</span>, <span class="fl">0.04</span>, <span class="fl">0.03</span>], num_samples).argmax(axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Late Fusion'</span>: np.random.multinomial(<span class="dv">1</span>, [<span class="fl">0.87</span>, <span class="fl">0.03</span>, <span class="fl">0.03</span>, <span class="fl">0.04</span>, <span class="fl">0.03</span>], num_samples).argmax(axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Attention Fusion'</span>: np.random.multinomial(<span class="dv">1</span>, [<span class="fl">0.9</span>, <span class="fl">0.025</span>, <span class="fl">0.025</span>, <span class="fl">0.025</span>, <span class="fl">0.025</span>], num_samples).argmax(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make predictions more realistic (align with ground truth)</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name <span class="kw">in</span> models:</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add some correlation with ground truth</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> np.random.random(num_samples) <span class="op">&lt;</span> <span class="fl">0.7</span>  <span class="co"># 70% correct</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>        models[model_name][mask] <span class="op">=</span> y_true[mask]</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> calculate_metrics(y_true, y_pred):</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Calculate comprehensive metrics"""</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_recall_fscore_support, confusion_matrix</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(y_true, y_pred)</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        precision, recall, f1, _ <span class="op">=</span> precision_recall_fscore_support(y_true, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        conf_matrix <span class="op">=</span> confusion_matrix(y_true, y_pred)</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>            <span class="st">'accuracy'</span>: accuracy,</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>            <span class="st">'precision'</span>: precision,</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">'recall'</span>: recall,</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">'f1_score'</span>: f1,</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">'confusion_matrix'</span>: conf_matrix</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate metrics for each model</span></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> {}</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name, predictions <span class="kw">in</span> models.items():</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>        results[model_name] <span class="op">=</span> calculate_metrics(y_true, predictions)</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display results</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-modal Model Comparison:"</span>)</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>    metric_names <span class="op">=</span> [<span class="st">'accuracy'</span>, <span class="st">'precision'</span>, <span class="st">'recall'</span>, <span class="st">'f1_score'</span>]</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create comparison table</span></span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>    comparison_data <span class="op">=</span> []</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name, metrics <span class="kw">in</span> results.items():</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>        row <span class="op">=</span> [model_name] <span class="op">+</span> [<span class="ss">f"</span><span class="sc">{</span>metrics[metric]<span class="sc">:.3f}</span><span class="ss">"</span> <span class="cf">for</span> metric <span class="kw">in</span> metric_names]</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>        comparison_data.append(row)</span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print table</span></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>    headers <span class="op">=</span> [<span class="st">'Model'</span>] <span class="op">+</span> [m.replace(<span class="st">'_'</span>, <span class="st">' '</span>).title() <span class="cf">for</span> m <span class="kw">in</span> metric_names]</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simple table formatting</span></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>    col_widths <span class="op">=</span> [<span class="bu">max</span>(<span class="bu">len</span>(<span class="bu">str</span>(row[i])) <span class="cf">for</span> row <span class="kw">in</span> [headers] <span class="op">+</span> comparison_data) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(headers))]</span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> print_row(row):</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">" | "</span>.join(<span class="bu">str</span>(item).ljust(width) <span class="cf">for</span> item, width <span class="kw">in</span> <span class="bu">zip</span>(row, col_widths))</span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(print_row(headers))</span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> (<span class="bu">sum</span>(col_widths) <span class="op">+</span> <span class="bu">len</span>(headers) <span class="op">*</span> <span class="dv">3</span> <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> row <span class="kw">in</span> comparison_data:</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(print_row(row))</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize performance comparison</span></span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>    fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Performance metrics</span></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>    model_names <span class="op">=</span> <span class="bu">list</span>(results.keys())</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a>    metrics_data <span class="op">=</span> {</span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Accuracy'</span>: [results[name][<span class="st">'accuracy'</span>] <span class="cf">for</span> name <span class="kw">in</span> model_names],</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Precision'</span>: [results[name][<span class="st">'precision'</span>] <span class="cf">for</span> name <span class="kw">in</span> model_names],</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Recall'</span>: [results[name][<span class="st">'recall'</span>] <span class="cf">for</span> name <span class="kw">in</span> model_names],</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a>        <span class="st">'F1-Score'</span>: [results[name][<span class="st">'f1_score'</span>] <span class="cf">for</span> name <span class="kw">in</span> model_names]</span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.arange(<span class="bu">len</span>(model_names))</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>    width <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (metric_name, values) <span class="kw">in</span> <span class="bu">enumerate</span>(metrics_data.items()):</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a>        ax1.bar(x <span class="op">+</span> i<span class="op">*</span>width, values, width, label<span class="op">=</span>metric_name, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(<span class="st">'Models'</span>)</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">'Score'</span>)</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(<span class="st">'Multi-modal Model Performance Comparison'</span>)</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticks(x <span class="op">+</span> width <span class="op">*</span> <span class="fl">1.5</span>)</span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticklabels(model_names, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>    ax1.legend()</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>    ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Confusion matrix for best model</span></span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>    best_model <span class="op">=</span> <span class="bu">max</span>(results.keys(), key<span class="op">=</span><span class="kw">lambda</span> x: results[x][<span class="st">'f1_score'</span>])</span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a>    best_conf_matrix <span class="op">=</span> results[best_model][<span class="st">'confusion_matrix'</span>]</span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a>    im <span class="op">=</span> ax2.imshow(best_conf_matrix, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="ss">f'Confusion Matrix - </span><span class="sc">{</span>best_model<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(<span class="st">'Predicted Class'</span>)</span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">'True Class'</span>)</span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add text annotations</span></span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_classes):</span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(num_classes):</span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a>            ax2.text(j, i, <span class="bu">str</span>(best_conf_matrix[i, j]), </span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a>                    ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, color<span class="op">=</span><span class="st">'black'</span> <span class="cf">if</span> best_conf_matrix[i, j] <span class="op">&lt;</span> best_conf_matrix.<span class="bu">max</span>()<span class="op">/</span><span class="dv">2</span> <span class="cf">else</span> <span class="st">'white'</span>)</span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(im, ax<span class="op">=</span>ax2)</span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Cross-modal retrieval metrics</span></span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Best performing model: </span><span class="sc">{</span>best_model<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best F1-score: </span><span class="sc">{</span>results[best_model][<span class="st">'f1_score'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results</span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a>evaluation_results <span class="op">=</span> demonstrate_multimodal_evaluation()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Multi-modal Model Comparison:
==================================================
Model            | Accuracy | Precision | Recall | F1 Score
-------------------------------------------------------------
Image Only       | 0.750    | 0.829     | 0.750  | 0.765   
Text Only        | 0.710    | 0.787     | 0.710  | 0.721   
Early Fusion     | 0.750    | 0.844     | 0.750  | 0.765   
Late Fusion      | 0.710    | 0.844     | 0.710  | 0.735   
Attention Fusion | 0.680    | 0.817     | 0.680  | 0.703   </code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="multimodal_learning_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Best performing model: Image Only
Best F1-score: 0.765</code></pre>
</div>
</div>
</section>
</section>
<section id="real-world-applications" class="level2">
<h2 class="anchored" data-anchor-id="real-world-applications">Real-world Applications</h2>
<section id="applications-in-geospatial-ai" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-geospatial-ai">Applications in Geospatial AI</h3>
<div id="a388f240" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_multimodal_applications():</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show real-world applications of multi-modal geospatial AI"""</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    applications <span class="op">=</span> {</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Disaster Response"</span>: {</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modalities"</span>: [<span class="st">"Satellite imagery"</span>, <span class="st">"Social media text"</span>, <span class="st">"Weather data"</span>],</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"objective"</span>: <span class="st">"Rapid damage assessment and resource allocation"</span>,</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_workflow"</span>: [</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">"1. Analyze pre/post-disaster satellite images"</span>,</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>                <span class="st">"2. Extract text from social media reports"</span>, </span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>                <span class="st">"3. Combine with weather/climate data"</span>,</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>                <span class="st">"4. Generate damage maps and priority areas"</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Real-time processing"</span>, <span class="st">"Data reliability"</span>, <span class="st">"Multi-scale fusion"</span>]</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Urban Planning"</span>: {</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modalities"</span>: [<span class="st">"High-res imagery"</span>, <span class="st">"Demographic data"</span>, <span class="st">"Traffic patterns"</span>],</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">"objective"</span>: <span class="st">"Optimize city development and infrastructure"</span>,</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_workflow"</span>: [</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>                <span class="st">"1. Analyze urban land use from imagery"</span>,</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>                <span class="st">"2. Integrate population and economic data"</span>,</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>                <span class="st">"3. Model traffic and mobility patterns"</span>, </span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>                <span class="st">"4. Generate development recommendations"</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Privacy concerns"</span>, <span class="st">"Data integration"</span>, <span class="st">"Temporal alignment"</span>]</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Agricultural Monitoring"</span>: {</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modalities"</span>: [<span class="st">"Multispectral imagery"</span>, <span class="st">"Weather data"</span>, <span class="st">"Soil information"</span>],</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>            <span class="st">"objective"</span>: <span class="st">"Crop yield prediction and management optimization"</span>,</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_workflow"</span>: [</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>                <span class="st">"1. Monitor crop health via spectral indices"</span>,</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>                <span class="st">"2. Integrate weather and climate data"</span>,</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>                <span class="st">"3. Analyze soil properties and conditions"</span>,</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>                <span class="st">"4. Predict yields and optimize practices"</span></span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Seasonal variations"</span>, <span class="st">"Regional differences"</span>, <span class="st">"Ground truth validation"</span>]</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Environmental Conservation"</span>: {</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modalities"</span>: [<span class="st">"Satellite imagery"</span>, <span class="st">"Species data"</span>, <span class="st">"Climate records"</span>],</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">"objective"</span>: <span class="st">"Biodiversity monitoring and habitat protection"</span>,</span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_workflow"</span>: [</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a>                <span class="st">"1. Map habitat types from imagery"</span>,</span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>                <span class="st">"2. Track species distributions and migrations"</span>,</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>                <span class="st">"3. Monitor climate and environmental changes"</span>,</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>                <span class="st">"4. Identify conservation priorities"</span></span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Species detection"</span>, <span class="st">"Long-term monitoring"</span>, <span class="st">"Scale integration"</span>]</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Climate Change Assessment"</span>: {</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modalities"</span>: [<span class="st">"Time-series imagery"</span>, <span class="st">"Temperature records"</span>, <span class="st">"Precipitation data"</span>],</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a>            <span class="st">"objective"</span>: <span class="st">"Track and predict climate impacts"</span>,</span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_workflow"</span>: [</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>                <span class="st">"1. Analyze land cover changes over time"</span>,</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>                <span class="st">"2. Correlate with temperature trends"</span>,</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>                <span class="st">"3. Integrate precipitation patterns"</span>,</span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>                <span class="st">"4. Model future scenarios"</span></span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Long-term data consistency"</span>, <span class="st">"Attribution"</span>, <span class="st">"Uncertainty quantification"</span>]</span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-modal Applications in Geospatial AI:"</span>)</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> app_name, details <span class="kw">in</span> applications.items():</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>app_name<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Modalities: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(details[<span class="st">'modalities'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Objective: </span><span class="sc">{</span>details[<span class="st">'objective'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Workflow:"</span>)</span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> step <span class="kw">in</span> details[<span class="st">'example_workflow'</span>]:</span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"    </span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Key Challenges: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(details[<span class="st">'challenges'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create application complexity visualization</span></span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>    app_names <span class="op">=</span> <span class="bu">list</span>(applications.keys())</span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>    modality_counts <span class="op">=</span> [<span class="bu">len</span>(app[<span class="st">'modalities'</span>]) <span class="cf">for</span> app <span class="kw">in</span> applications.values()]</span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a>    challenge_counts <span class="op">=</span> [<span class="bu">len</span>(app[<span class="st">'challenges'</span>]) <span class="cf">for</span> app <span class="kw">in</span> applications.values()]</span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a>    fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Modalities per application</span></span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a>    bars1 <span class="op">=</span> ax1.bar(<span class="bu">range</span>(<span class="bu">len</span>(app_names)), modality_counts, color<span class="op">=</span><span class="st">'skyblue'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(<span class="st">'Applications'</span>)</span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">'Number of Modalities'</span>)</span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(<span class="st">'Data Modalities per Application'</span>)</span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticks(<span class="bu">range</span>(<span class="bu">len</span>(app_names)))</span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticklabels(app_names, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add value labels on bars</span></span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bar, count <span class="kw">in</span> <span class="bu">zip</span>(bars1, modality_counts):</span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>        height <span class="op">=</span> bar.get_height()</span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>        ax1.text(bar.get_x() <span class="op">+</span> bar.get_width()<span class="op">/</span><span class="fl">2.</span>, height <span class="op">+</span> <span class="fl">0.05</span>,</span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'</span><span class="sc">{</span>count<span class="sc">}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Challenges per application  </span></span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a>    bars2 <span class="op">=</span> ax2.bar(<span class="bu">range</span>(<span class="bu">len</span>(app_names)), challenge_counts, color<span class="op">=</span><span class="st">'lightcoral'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(<span class="st">'Applications'</span>)</span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">'Number of Key Challenges'</span>)</span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="st">'Implementation Challenges per Application'</span>)</span>
<span id="cb21-104"><a href="#cb21-104" aria-hidden="true" tabindex="-1"></a>    ax2.set_xticks(<span class="bu">range</span>(<span class="bu">len</span>(app_names)))</span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a>    ax2.set_xticklabels(app_names, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add value labels on bars</span></span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bar, count <span class="kw">in</span> <span class="bu">zip</span>(bars2, challenge_counts):</span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a>        height <span class="op">=</span> bar.get_height()</span>
<span id="cb21-110"><a href="#cb21-110" aria-hidden="true" tabindex="-1"></a>        ax2.text(bar.get_x() <span class="op">+</span> bar.get_width()<span class="op">/</span><span class="fl">2.</span>, height <span class="op">+</span> <span class="fl">0.05</span>,</span>
<span id="cb21-111"><a href="#cb21-111" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'</span><span class="sc">{</span>count<span class="sc">}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> applications</span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a>multimodal_apps <span class="op">=</span> demonstrate_multimodal_applications()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Multi-modal Applications in Geospatial AI:
============================================================

Disaster Response:
  Modalities: Satellite imagery, Social media text, Weather data
  Objective: Rapid damage assessment and resource allocation
  Workflow:
    1. Analyze pre/post-disaster satellite images
    2. Extract text from social media reports
    3. Combine with weather/climate data
    4. Generate damage maps and priority areas
  Key Challenges: Real-time processing, Data reliability, Multi-scale fusion

Urban Planning:
  Modalities: High-res imagery, Demographic data, Traffic patterns
  Objective: Optimize city development and infrastructure
  Workflow:
    1. Analyze urban land use from imagery
    2. Integrate population and economic data
    3. Model traffic and mobility patterns
    4. Generate development recommendations
  Key Challenges: Privacy concerns, Data integration, Temporal alignment

Agricultural Monitoring:
  Modalities: Multispectral imagery, Weather data, Soil information
  Objective: Crop yield prediction and management optimization
  Workflow:
    1. Monitor crop health via spectral indices
    2. Integrate weather and climate data
    3. Analyze soil properties and conditions
    4. Predict yields and optimize practices
  Key Challenges: Seasonal variations, Regional differences, Ground truth validation

Environmental Conservation:
  Modalities: Satellite imagery, Species data, Climate records
  Objective: Biodiversity monitoring and habitat protection
  Workflow:
    1. Map habitat types from imagery
    2. Track species distributions and migrations
    3. Monitor climate and environmental changes
    4. Identify conservation priorities
  Key Challenges: Species detection, Long-term monitoring, Scale integration

Climate Change Assessment:
  Modalities: Time-series imagery, Temperature records, Precipitation data
  Objective: Track and predict climate impacts
  Workflow:
    1. Analyze land cover changes over time
    2. Correlate with temperature trends
    3. Integrate precipitation patterns
    4. Model future scenarios
  Key Challenges: Long-term data consistency, Attribution, Uncertainty quantification</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="multimodal_learning_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>Key concepts for multi-modal learning in geospatial AI: - <strong>Data Integration</strong>: Combining imagery, text, time series, and tabular data - <strong>Fusion Strategies</strong>: Early fusion, late fusion, and attention-based approaches<br>
- <strong>Architecture Patterns</strong>: Cross-modal attention, contrastive learning, joint embeddings - <strong>Contrastive Learning</strong>: CLIP-style training for image-text understanding - <strong>Data Augmentation</strong>: Cross-modal augmentation techniques - <strong>Evaluation Metrics</strong>: Multi-modal performance assessment - <strong>Applications</strong>: Disaster response, urban planning, agriculture, conservation - <strong>Challenges</strong>: Data alignment, scale differences, computational complexity</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/kcaylor\.github\.io\/GEOG-288KC-geospatial-foundation-models");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb23" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Multi-modal Learning"</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Combining different data modalities for enhanced geospatial AI"</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> geoai</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: false</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction to Multi-modal Learning</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>Multi-modal learning combines different types of data (imagery, text, time series, etc.) to create more comprehensive and robust AI systems. In geospatial applications, this involves integrating satellite imagery with text descriptions, weather data, and other complementary information.</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> CLIPModel, CLIPProcessor, AutoTokenizer, AutoModel</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"PyTorch version: </span><span class="sc">{</span>torch<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## Types of Multi-modal Data in Geospatial AI</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a><span class="fu">### Common Modality Combinations</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_multimodal_data_types():</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show different types of multi-modal combinations in geospatial AI"""</span></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>    modality_combinations <span class="op">=</span> {</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Image + Text"</span>: {</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example"</span>: <span class="st">"Satellite image + location description"</span>,</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">"use_cases"</span>: [<span class="st">"Image captioning"</span>, <span class="st">"Location search"</span>, <span class="st">"Content-based retrieval"</span>],</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Semantic gap"</span>, <span class="st">"Text-image alignment"</span>, <span class="st">"Scale differences"</span>]</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Multi-spectral + SAR"</span>: {</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example"</span>: <span class="st">"Optical + Radar imagery"</span>, </span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>            <span class="st">"use_cases"</span>: [<span class="st">"All-weather monitoring"</span>, <span class="st">"Improved classification"</span>, <span class="st">"Change detection"</span>],</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Registration"</span>, <span class="st">"Resolution differences"</span>, <span class="st">"Fusion strategies"</span>]</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Image + Time Series"</span>: {</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example"</span>: <span class="st">"Satellite imagery + weather/climate data"</span>,</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">"use_cases"</span>: [<span class="st">"Crop yield prediction"</span>, <span class="st">"Disaster monitoring"</span>, <span class="st">"Environmental modeling"</span>],</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Temporal alignment"</span>, <span class="st">"Different sampling rates"</span>, <span class="st">"Multi-scale fusion"</span>]</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Image + Tabular"</span>: {</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example"</span>: <span class="st">"Remote sensing + demographic/economic data"</span>,</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>            <span class="st">"use_cases"</span>: [<span class="st">"Socioeconomic mapping"</span>, <span class="st">"Urban planning"</span>, <span class="st">"Poverty estimation"</span>],</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Spatial alignment"</span>, <span class="st">"Feature engineering"</span>, <span class="st">"Scale mismatch"</span>]</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Multi-resolution"</span>: {</span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example"</span>: <span class="st">"High-res + Low-res imagery"</span>,</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>            <span class="st">"use_cases"</span>: [<span class="st">"Super-resolution"</span>, <span class="st">"Multi-scale analysis"</span>, <span class="st">"Data fusion"</span>],</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Resolution alignment"</span>, <span class="st">"Information preservation"</span>, <span class="st">"Computational efficiency"</span>]</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-modal Data Types in Geospatial AI:"</span>)</span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> modality, details <span class="kw">in</span> modality_combinations.items():</span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>modality<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Example: </span><span class="sc">{</span>details[<span class="st">'example'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Use cases: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(details[<span class="st">'use_cases'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Challenges: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(details[<span class="st">'challenges'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> modality_combinations</span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>multimodal_types <span class="op">=</span> demonstrate_multimodal_data_types()</span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Preprocessing for Multi-modal Learning</span></span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_multimodal_preprocessing_pipeline():</span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Demonstrate preprocessing for multi-modal geospatial data"""</span></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate different data modalities</span></span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a>    np.random.seed(<span class="dv">42</span>)</span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Satellite imagery (multispectral)</span></span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>    batch_size, channels, height, width <span class="op">=</span> <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span></span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a>    satellite_images <span class="op">=</span> torch.randn(batch_size, channels, height, width)</span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Text descriptions</span></span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a>    text_descriptions <span class="op">=</span> [</span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Forest area with dense vegetation and high canopy cover"</span>,</span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Urban residential area with mixed building types"</span>,</span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Agricultural land with crop fields and irrigation"</span>,</span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Coastal wetland area with water bodies and marsh"</span></span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Tabular metadata</span></span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a>    metadata <span class="op">=</span> pd.DataFrame({</span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a>        <span class="st">'location_id'</span>: [<span class="ss">f'LOC_</span><span class="sc">{</span>i<span class="sc">:03d}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a>        <span class="st">'latitude'</span>: [<span class="fl">45.5</span> <span class="op">+</span> i<span class="op">*</span><span class="fl">0.1</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a>        <span class="st">'longitude'</span>: [<span class="op">-</span><span class="fl">122.5</span> <span class="op">+</span> i<span class="op">*</span><span class="fl">0.1</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a>        <span class="st">'elevation'</span>: [<span class="dv">100</span> <span class="op">+</span> i<span class="op">*</span><span class="dv">50</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a>        <span class="st">'temperature'</span>: [<span class="fl">15.5</span> <span class="op">+</span> i<span class="op">*</span><span class="dv">2</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a>        <span class="st">'precipitation'</span>: [<span class="dv">800</span> <span class="op">+</span> i<span class="op">*</span><span class="dv">100</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size)],</span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a>        <span class="st">'season'</span>: [<span class="st">'spring'</span>, <span class="st">'summer'</span>, <span class="st">'autumn'</span>, <span class="st">'winter'</span>]</span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Time series data</span></span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a>    time_steps <span class="op">=</span> <span class="dv">52</span>  <span class="co"># Weekly data for a year</span></span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a>    time_series <span class="op">=</span> torch.randn(batch_size, time_steps, <span class="dv">3</span>)  <span class="co"># NDVI, temperature, precipitation</span></span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-modal Data Examples:"</span>)</span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">40</span>)</span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Satellite images shape: </span><span class="sc">{</span>satellite_images<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text descriptions: </span><span class="sc">{</span><span class="bu">len</span>(text_descriptions)<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Metadata shape: </span><span class="sc">{</span>metadata<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Time series shape: </span><span class="sc">{</span>time_series<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocessing functions</span></span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> preprocess_images(images, target_size<span class="op">=</span>(<span class="dv">224</span>, <span class="dv">224</span>)):</span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Preprocess satellite images"""</span></span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize to [0, 1]</span></span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a>        images <span class="op">=</span> (images <span class="op">-</span> images.<span class="bu">min</span>()) <span class="op">/</span> (images.<span class="bu">max</span>() <span class="op">-</span> images.<span class="bu">min</span>())</span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Resize if needed (simplified)</span></span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> images.shape[<span class="op">-</span><span class="dv">2</span>:] <span class="op">!=</span> target_size:</span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> F.interpolate(images, size<span class="op">=</span>target_size, mode<span class="op">=</span><span class="st">'bilinear'</span>, align_corners<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> images</span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> preprocess_text(texts, max_length<span class="op">=</span><span class="dv">77</span>):</span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Preprocess text descriptions (simplified tokenization)"""</span></span>
<span id="cb23-138"><a href="#cb23-138" aria-hidden="true" tabindex="-1"></a>        <span class="co"># In practice, use proper tokenizers like CLIP or BERT</span></span>
<span id="cb23-139"><a href="#cb23-139" aria-hidden="true" tabindex="-1"></a>        processed_texts <span class="op">=</span> []</span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> text <span class="kw">in</span> texts:</span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Simple word tokenization</span></span>
<span id="cb23-142"><a href="#cb23-142" aria-hidden="true" tabindex="-1"></a>            words <span class="op">=</span> text.lower().split()[:max_length]</span>
<span id="cb23-143"><a href="#cb23-143" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Pad to max_length</span></span>
<span id="cb23-144"><a href="#cb23-144" aria-hidden="true" tabindex="-1"></a>            words <span class="op">+=</span> [<span class="st">'&lt;pad&gt;'</span>] <span class="op">*</span> (max_length <span class="op">-</span> <span class="bu">len</span>(words))</span>
<span id="cb23-145"><a href="#cb23-145" aria-hidden="true" tabindex="-1"></a>            processed_texts.append(words)</span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> processed_texts</span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> preprocess_tabular(metadata):</span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Preprocess tabular metadata"""</span></span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a>        processed <span class="op">=</span> metadata.copy()</span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize numerical features</span></span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a>        numerical_cols <span class="op">=</span> [<span class="st">'latitude'</span>, <span class="st">'longitude'</span>, <span class="st">'elevation'</span>, <span class="st">'temperature'</span>, <span class="st">'precipitation'</span>]</span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> col <span class="kw">in</span> numerical_cols:</span>
<span id="cb23-156"><a href="#cb23-156" aria-hidden="true" tabindex="-1"></a>            processed[col] <span class="op">=</span> (processed[col] <span class="op">-</span> processed[col].mean()) <span class="op">/</span> processed[col].std()</span>
<span id="cb23-157"><a href="#cb23-157" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode categorical features (simplified)</span></span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a>        season_encoding <span class="op">=</span> {<span class="st">'spring'</span>: <span class="dv">0</span>, <span class="st">'summer'</span>: <span class="dv">1</span>, <span class="st">'autumn'</span>: <span class="dv">2</span>, <span class="st">'winter'</span>: <span class="dv">3</span>}</span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a>        processed[<span class="st">'season_encoded'</span>] <span class="op">=</span> processed[<span class="st">'season'</span>].<span class="bu">map</span>(season_encoding)</span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> processed</span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> preprocess_time_series(ts_data, normalize<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Preprocess time series data"""</span></span>
<span id="cb23-166"><a href="#cb23-166" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> normalize:</span>
<span id="cb23-167"><a href="#cb23-167" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Normalize across time dimension</span></span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a>            mean <span class="op">=</span> ts_data.mean(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a>            std <span class="op">=</span> ts_data.std(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a>            ts_data <span class="op">=</span> (ts_data <span class="op">-</span> mean) <span class="op">/</span> (std <span class="op">+</span> <span class="fl">1e-8</span>)</span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-172"><a href="#cb23-172" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ts_data</span>
<span id="cb23-173"><a href="#cb23-173" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-174"><a href="#cb23-174" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply preprocessing</span></span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a>    processed_images <span class="op">=</span> preprocess_images(satellite_images)</span>
<span id="cb23-176"><a href="#cb23-176" aria-hidden="true" tabindex="-1"></a>    processed_texts <span class="op">=</span> preprocess_text(text_descriptions)</span>
<span id="cb23-177"><a href="#cb23-177" aria-hidden="true" tabindex="-1"></a>    processed_metadata <span class="op">=</span> preprocess_tabular(metadata)</span>
<span id="cb23-178"><a href="#cb23-178" aria-hidden="true" tabindex="-1"></a>    processed_time_series <span class="op">=</span> preprocess_time_series(time_series)</span>
<span id="cb23-179"><a href="#cb23-179" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-180"><a href="#cb23-180" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">After Preprocessing:"</span>)</span>
<span id="cb23-181"><a href="#cb23-181" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Images range: [</span><span class="sc">{</span>processed_images<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>processed_images<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.3f}</span><span class="ss">]"</span>)</span>
<span id="cb23-182"><a href="#cb23-182" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text tokens per sample: </span><span class="sc">{</span><span class="bu">len</span>(processed_texts[<span class="dv">0</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-183"><a href="#cb23-183" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Metadata columns:"</span>, <span class="bu">list</span>(processed_metadata.columns))</span>
<span id="cb23-184"><a href="#cb23-184" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Time series normalized: mean=</span><span class="sc">{</span>processed_time_series<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">, std=</span><span class="sc">{</span>processed_time_series<span class="sc">.</span>std()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-185"><a href="#cb23-185" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-186"><a href="#cb23-186" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb23-187"><a href="#cb23-187" aria-hidden="true" tabindex="-1"></a>        <span class="st">'images'</span>: processed_images,</span>
<span id="cb23-188"><a href="#cb23-188" aria-hidden="true" tabindex="-1"></a>        <span class="st">'texts'</span>: processed_texts,</span>
<span id="cb23-189"><a href="#cb23-189" aria-hidden="true" tabindex="-1"></a>        <span class="st">'metadata'</span>: processed_metadata,</span>
<span id="cb23-190"><a href="#cb23-190" aria-hidden="true" tabindex="-1"></a>        <span class="st">'time_series'</span>: processed_time_series</span>
<span id="cb23-191"><a href="#cb23-191" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb23-192"><a href="#cb23-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-193"><a href="#cb23-193" aria-hidden="true" tabindex="-1"></a>preprocessed_data <span class="op">=</span> create_multimodal_preprocessing_pipeline()</span>
<span id="cb23-194"><a href="#cb23-194" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-195"><a href="#cb23-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-196"><a href="#cb23-196" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multi-modal Architecture Patterns</span></span>
<span id="cb23-197"><a href="#cb23-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-198"><a href="#cb23-198" aria-hidden="true" tabindex="-1"></a><span class="fu">### Early Fusion vs Late Fusion</span></span>
<span id="cb23-201"><a href="#cb23-201" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-202"><a href="#cb23-202" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EarlyFusionModel(nn.Module):</span>
<span id="cb23-203"><a href="#cb23-203" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Early fusion: combine features at input level"""</span></span>
<span id="cb23-204"><a href="#cb23-204" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-205"><a href="#cb23-205" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, image_channels<span class="op">=</span><span class="dv">6</span>, text_vocab_size<span class="op">=</span><span class="dv">1000</span>, tabular_features<span class="op">=</span><span class="dv">5</span>, hidden_dim<span class="op">=</span><span class="dv">512</span>, num_classes<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb23-206"><a href="#cb23-206" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb23-207"><a href="#cb23-207" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-208"><a href="#cb23-208" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Image encoder</span></span>
<span id="cb23-209"><a href="#cb23-209" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-210"><a href="#cb23-210" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(image_channels, <span class="dv">64</span>, <span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>),</span>
<span id="cb23-211"><a href="#cb23-211" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-212"><a href="#cb23-212" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool2d((<span class="dv">4</span>, <span class="dv">4</span>)),</span>
<span id="cb23-213"><a href="#cb23-213" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb23-214"><a href="#cb23-214" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">64</span> <span class="op">*</span> <span class="dv">16</span>, hidden_dim)</span>
<span id="cb23-215"><a href="#cb23-215" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-216"><a href="#cb23-216" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-217"><a href="#cb23-217" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text encoder (simplified)</span></span>
<span id="cb23-218"><a href="#cb23-218" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-219"><a href="#cb23-219" aria-hidden="true" tabindex="-1"></a>            nn.Embedding(text_vocab_size, <span class="dv">256</span>),</span>
<span id="cb23-220"><a href="#cb23-220" aria-hidden="true" tabindex="-1"></a>            nn.LSTM(<span class="dv">256</span>, hidden_dim<span class="op">//</span><span class="dv">2</span>, batch_first<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb23-221"><a href="#cb23-221" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-222"><a href="#cb23-222" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-223"><a href="#cb23-223" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Tabular encoder</span></span>
<span id="cb23-224"><a href="#cb23-224" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tabular_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-225"><a href="#cb23-225" aria-hidden="true" tabindex="-1"></a>            nn.Linear(tabular_features, hidden_dim<span class="op">//</span><span class="dv">2</span>),</span>
<span id="cb23-226"><a href="#cb23-226" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-227"><a href="#cb23-227" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim<span class="op">//</span><span class="dv">2</span>, hidden_dim)</span>
<span id="cb23-228"><a href="#cb23-228" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-229"><a href="#cb23-229" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-230"><a href="#cb23-230" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Early fusion: concatenate features</span></span>
<span id="cb23-231"><a href="#cb23-231" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Image (hidden_dim) + Text (hidden_dim//2) + Tabular (hidden_dim)</span></span>
<span id="cb23-232"><a href="#cb23-232" aria-hidden="true" tabindex="-1"></a>        fusion_input_dim <span class="op">=</span> hidden_dim <span class="op">+</span> hidden_dim<span class="op">//</span><span class="dv">2</span> <span class="op">+</span> hidden_dim</span>
<span id="cb23-233"><a href="#cb23-233" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fusion_layer <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-234"><a href="#cb23-234" aria-hidden="true" tabindex="-1"></a>            nn.Linear(fusion_input_dim, hidden_dim),  <span class="co"># Combined features</span></span>
<span id="cb23-235"><a href="#cb23-235" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-236"><a href="#cb23-236" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.3</span>),</span>
<span id="cb23-237"><a href="#cb23-237" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, num_classes)</span>
<span id="cb23-238"><a href="#cb23-238" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-239"><a href="#cb23-239" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-240"><a href="#cb23-240" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, images, text_tokens, tabular_data):</span>
<span id="cb23-241"><a href="#cb23-241" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode each modality</span></span>
<span id="cb23-242"><a href="#cb23-242" aria-hidden="true" tabindex="-1"></a>        image_features <span class="op">=</span> <span class="va">self</span>.image_encoder(images)</span>
<span id="cb23-243"><a href="#cb23-243" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-244"><a href="#cb23-244" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Text encoding (simplified - use last hidden state)</span></span>
<span id="cb23-245"><a href="#cb23-245" aria-hidden="true" tabindex="-1"></a>        text_features, (h_n, c_n) <span class="op">=</span> <span class="va">self</span>.text_encoder(text_tokens)</span>
<span id="cb23-246"><a href="#cb23-246" aria-hidden="true" tabindex="-1"></a>        text_features <span class="op">=</span> h_n[<span class="op">-</span><span class="dv">1</span>]  <span class="co"># Use last hidden state</span></span>
<span id="cb23-247"><a href="#cb23-247" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-248"><a href="#cb23-248" aria-hidden="true" tabindex="-1"></a>        tabular_features <span class="op">=</span> <span class="va">self</span>.tabular_encoder(tabular_data)</span>
<span id="cb23-249"><a href="#cb23-249" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-250"><a href="#cb23-250" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Early fusion: concatenate features</span></span>
<span id="cb23-251"><a href="#cb23-251" aria-hidden="true" tabindex="-1"></a>        combined_features <span class="op">=</span> torch.cat([image_features, text_features, tabular_features], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-252"><a href="#cb23-252" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-253"><a href="#cb23-253" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Final prediction</span></span>
<span id="cb23-254"><a href="#cb23-254" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.fusion_layer(combined_features)</span>
<span id="cb23-255"><a href="#cb23-255" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-256"><a href="#cb23-256" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output, {</span>
<span id="cb23-257"><a href="#cb23-257" aria-hidden="true" tabindex="-1"></a>            <span class="st">'image_features'</span>: image_features,</span>
<span id="cb23-258"><a href="#cb23-258" aria-hidden="true" tabindex="-1"></a>            <span class="st">'text_features'</span>: text_features,</span>
<span id="cb23-259"><a href="#cb23-259" aria-hidden="true" tabindex="-1"></a>            <span class="st">'tabular_features'</span>: tabular_features,</span>
<span id="cb23-260"><a href="#cb23-260" aria-hidden="true" tabindex="-1"></a>            <span class="st">'combined_features'</span>: combined_features</span>
<span id="cb23-261"><a href="#cb23-261" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb23-262"><a href="#cb23-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-263"><a href="#cb23-263" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LateFusionModel(nn.Module):</span>
<span id="cb23-264"><a href="#cb23-264" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Late fusion: combine predictions from separate models"""</span></span>
<span id="cb23-265"><a href="#cb23-265" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-266"><a href="#cb23-266" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, image_channels<span class="op">=</span><span class="dv">6</span>, text_vocab_size<span class="op">=</span><span class="dv">1000</span>, tabular_features<span class="op">=</span><span class="dv">5</span>, hidden_dim<span class="op">=</span><span class="dv">512</span>, num_classes<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb23-267"><a href="#cb23-267" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb23-268"><a href="#cb23-268" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-269"><a href="#cb23-269" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Separate encoders for each modality</span></span>
<span id="cb23-270"><a href="#cb23-270" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_branch <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-271"><a href="#cb23-271" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(image_channels, <span class="dv">64</span>, <span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>),</span>
<span id="cb23-272"><a href="#cb23-272" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-273"><a href="#cb23-273" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool2d((<span class="dv">4</span>, <span class="dv">4</span>)),</span>
<span id="cb23-274"><a href="#cb23-274" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb23-275"><a href="#cb23-275" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">64</span> <span class="op">*</span> <span class="dv">16</span>, hidden_dim),</span>
<span id="cb23-276"><a href="#cb23-276" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-277"><a href="#cb23-277" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim, num_classes)</span>
<span id="cb23-278"><a href="#cb23-278" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-279"><a href="#cb23-279" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-280"><a href="#cb23-280" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_branch <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-281"><a href="#cb23-281" aria-hidden="true" tabindex="-1"></a>            nn.Embedding(text_vocab_size, <span class="dv">256</span>),</span>
<span id="cb23-282"><a href="#cb23-282" aria-hidden="true" tabindex="-1"></a>            nn.LSTM(<span class="dv">256</span>, hidden_dim<span class="op">//</span><span class="dv">2</span>, batch_first<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb23-283"><a href="#cb23-283" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-284"><a href="#cb23-284" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_classifier <span class="op">=</span> nn.Linear(hidden_dim<span class="op">//</span><span class="dv">2</span>, num_classes)</span>
<span id="cb23-285"><a href="#cb23-285" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-286"><a href="#cb23-286" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tabular_branch <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-287"><a href="#cb23-287" aria-hidden="true" tabindex="-1"></a>            nn.Linear(tabular_features, hidden_dim<span class="op">//</span><span class="dv">2</span>),</span>
<span id="cb23-288"><a href="#cb23-288" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-289"><a href="#cb23-289" aria-hidden="true" tabindex="-1"></a>            nn.Linear(hidden_dim<span class="op">//</span><span class="dv">2</span>, num_classes)</span>
<span id="cb23-290"><a href="#cb23-290" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-291"><a href="#cb23-291" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-292"><a href="#cb23-292" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fusion weights (learnable)</span></span>
<span id="cb23-293"><a href="#cb23-293" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fusion_weights <span class="op">=</span> nn.Parameter(torch.ones(<span class="dv">3</span>) <span class="op">/</span> <span class="dv">3</span>)</span>
<span id="cb23-294"><a href="#cb23-294" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-295"><a href="#cb23-295" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, images, text_tokens, tabular_data):</span>
<span id="cb23-296"><a href="#cb23-296" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get predictions from each branch</span></span>
<span id="cb23-297"><a href="#cb23-297" aria-hidden="true" tabindex="-1"></a>        image_logits <span class="op">=</span> <span class="va">self</span>.image_branch(images)</span>
<span id="cb23-298"><a href="#cb23-298" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-299"><a href="#cb23-299" aria-hidden="true" tabindex="-1"></a>        text_features, (h_n, c_n) <span class="op">=</span> <span class="va">self</span>.text_branch(text_tokens)</span>
<span id="cb23-300"><a href="#cb23-300" aria-hidden="true" tabindex="-1"></a>        text_logits <span class="op">=</span> <span class="va">self</span>.text_classifier(h_n[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb23-301"><a href="#cb23-301" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-302"><a href="#cb23-302" aria-hidden="true" tabindex="-1"></a>        tabular_logits <span class="op">=</span> <span class="va">self</span>.tabular_branch(tabular_data)</span>
<span id="cb23-303"><a href="#cb23-303" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-304"><a href="#cb23-304" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Late fusion: weighted combination of predictions</span></span>
<span id="cb23-305"><a href="#cb23-305" aria-hidden="true" tabindex="-1"></a>        fusion_weights <span class="op">=</span> F.softmax(<span class="va">self</span>.fusion_weights, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-306"><a href="#cb23-306" aria-hidden="true" tabindex="-1"></a>        combined_logits <span class="op">=</span> (fusion_weights[<span class="dv">0</span>] <span class="op">*</span> image_logits <span class="op">+</span> </span>
<span id="cb23-307"><a href="#cb23-307" aria-hidden="true" tabindex="-1"></a>                          fusion_weights[<span class="dv">1</span>] <span class="op">*</span> text_logits <span class="op">+</span> </span>
<span id="cb23-308"><a href="#cb23-308" aria-hidden="true" tabindex="-1"></a>                          fusion_weights[<span class="dv">2</span>] <span class="op">*</span> tabular_logits)</span>
<span id="cb23-309"><a href="#cb23-309" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-310"><a href="#cb23-310" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> combined_logits, {</span>
<span id="cb23-311"><a href="#cb23-311" aria-hidden="true" tabindex="-1"></a>            <span class="st">'image_logits'</span>: image_logits,</span>
<span id="cb23-312"><a href="#cb23-312" aria-hidden="true" tabindex="-1"></a>            <span class="st">'text_logits'</span>: text_logits,</span>
<span id="cb23-313"><a href="#cb23-313" aria-hidden="true" tabindex="-1"></a>            <span class="st">'tabular_logits'</span>: tabular_logits,</span>
<span id="cb23-314"><a href="#cb23-314" aria-hidden="true" tabindex="-1"></a>            <span class="st">'fusion_weights'</span>: fusion_weights</span>
<span id="cb23-315"><a href="#cb23-315" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb23-316"><a href="#cb23-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-317"><a href="#cb23-317" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare architectures</span></span>
<span id="cb23-318"><a href="#cb23-318" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compare_fusion_architectures():</span>
<span id="cb23-319"><a href="#cb23-319" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compare early vs late fusion approaches"""</span></span>
<span id="cb23-320"><a href="#cb23-320" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-321"><a href="#cb23-321" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create sample data</span></span>
<span id="cb23-322"><a href="#cb23-322" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb23-323"><a href="#cb23-323" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> torch.randn(batch_size, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb23-324"><a href="#cb23-324" aria-hidden="true" tabindex="-1"></a>    text_tokens <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="dv">1000</span>, (batch_size, <span class="dv">20</span>))</span>
<span id="cb23-325"><a href="#cb23-325" aria-hidden="true" tabindex="-1"></a>    tabular_data <span class="op">=</span> torch.randn(batch_size, <span class="dv">5</span>)</span>
<span id="cb23-326"><a href="#cb23-326" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-327"><a href="#cb23-327" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create models</span></span>
<span id="cb23-328"><a href="#cb23-328" aria-hidden="true" tabindex="-1"></a>    early_fusion <span class="op">=</span> EarlyFusionModel()</span>
<span id="cb23-329"><a href="#cb23-329" aria-hidden="true" tabindex="-1"></a>    late_fusion <span class="op">=</span> LateFusionModel()</span>
<span id="cb23-330"><a href="#cb23-330" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-331"><a href="#cb23-331" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Count parameters</span></span>
<span id="cb23-332"><a href="#cb23-332" aria-hidden="true" tabindex="-1"></a>    early_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> early_fusion.parameters())</span>
<span id="cb23-333"><a href="#cb23-333" aria-hidden="true" tabindex="-1"></a>    late_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> late_fusion.parameters())</span>
<span id="cb23-334"><a href="#cb23-334" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-335"><a href="#cb23-335" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Fusion Architecture Comparison:"</span>)</span>
<span id="cb23-336"><a href="#cb23-336" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb23-337"><a href="#cb23-337" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Early Fusion Parameters: </span><span class="sc">{</span>early_params<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb23-338"><a href="#cb23-338" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Late Fusion Parameters: </span><span class="sc">{</span>late_params<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb23-339"><a href="#cb23-339" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-340"><a href="#cb23-340" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass</span></span>
<span id="cb23-341"><a href="#cb23-341" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb23-342"><a href="#cb23-342" aria-hidden="true" tabindex="-1"></a>        early_output, early_features <span class="op">=</span> early_fusion(images, text_tokens, tabular_data)</span>
<span id="cb23-343"><a href="#cb23-343" aria-hidden="true" tabindex="-1"></a>        late_output, late_features <span class="op">=</span> late_fusion(images, text_tokens, tabular_data)</span>
<span id="cb23-344"><a href="#cb23-344" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-345"><a href="#cb23-345" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Output shapes:"</span>)</span>
<span id="cb23-346"><a href="#cb23-346" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Early Fusion: </span><span class="sc">{</span>early_output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-347"><a href="#cb23-347" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Late Fusion: </span><span class="sc">{</span>late_output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-348"><a href="#cb23-348" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-349"><a href="#cb23-349" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Late Fusion Weights: </span><span class="sc">{</span>late_features[<span class="st">'fusion_weights'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-350"><a href="#cb23-350" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-351"><a href="#cb23-351" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> early_fusion, late_fusion</span>
<span id="cb23-352"><a href="#cb23-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-353"><a href="#cb23-353" aria-hidden="true" tabindex="-1"></a>early_model, late_model <span class="op">=</span> compare_fusion_architectures()</span>
<span id="cb23-354"><a href="#cb23-354" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-355"><a href="#cb23-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-356"><a href="#cb23-356" aria-hidden="true" tabindex="-1"></a><span class="fu">### Attention-based Fusion</span></span>
<span id="cb23-359"><a href="#cb23-359" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-360"><a href="#cb23-360" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CrossModalAttentionFusion(nn.Module):</span>
<span id="cb23-361"><a href="#cb23-361" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Cross-modal attention fusion mechanism"""</span></span>
<span id="cb23-362"><a href="#cb23-362" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-363"><a href="#cb23-363" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, feature_dim<span class="op">=</span><span class="dv">512</span>, num_heads<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb23-364"><a href="#cb23-364" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb23-365"><a href="#cb23-365" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.feature_dim <span class="op">=</span> feature_dim</span>
<span id="cb23-366"><a href="#cb23-366" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_heads <span class="op">=</span> num_heads</span>
<span id="cb23-367"><a href="#cb23-367" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-368"><a href="#cb23-368" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-attention layers</span></span>
<span id="cb23-369"><a href="#cb23-369" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_to_text_attention <span class="op">=</span> nn.MultiheadAttention(feature_dim, num_heads, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-370"><a href="#cb23-370" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_to_image_attention <span class="op">=</span> nn.MultiheadAttention(feature_dim, num_heads, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-371"><a href="#cb23-371" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-372"><a href="#cb23-372" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Self-attention for final fusion</span></span>
<span id="cb23-373"><a href="#cb23-373" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fusion_attention <span class="op">=</span> nn.MultiheadAttention(feature_dim, num_heads, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-374"><a href="#cb23-374" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-375"><a href="#cb23-375" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Layer normalization</span></span>
<span id="cb23-376"><a href="#cb23-376" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm1 <span class="op">=</span> nn.LayerNorm(feature_dim)</span>
<span id="cb23-377"><a href="#cb23-377" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm2 <span class="op">=</span> nn.LayerNorm(feature_dim)</span>
<span id="cb23-378"><a href="#cb23-378" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm3 <span class="op">=</span> nn.LayerNorm(feature_dim)</span>
<span id="cb23-379"><a href="#cb23-379" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-380"><a href="#cb23-380" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Final classifier</span></span>
<span id="cb23-381"><a href="#cb23-381" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Linear(feature_dim <span class="op">*</span> <span class="dv">2</span>, <span class="dv">10</span>)  <span class="co"># 10 classes</span></span>
<span id="cb23-382"><a href="#cb23-382" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-383"><a href="#cb23-383" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, image_features, text_features):</span>
<span id="cb23-384"><a href="#cb23-384" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb23-385"><a href="#cb23-385" aria-hidden="true" tabindex="-1"></a><span class="co">        image_features: [batch_size, num_patches, feature_dim]</span></span>
<span id="cb23-386"><a href="#cb23-386" aria-hidden="true" tabindex="-1"></a><span class="co">        text_features: [batch_size, seq_len, feature_dim]</span></span>
<span id="cb23-387"><a href="#cb23-387" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb23-388"><a href="#cb23-388" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-389"><a href="#cb23-389" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-modal attention: image attending to text</span></span>
<span id="cb23-390"><a href="#cb23-390" aria-hidden="true" tabindex="-1"></a>        image_attended, image_attention_weights <span class="op">=</span> <span class="va">self</span>.image_to_text_attention(</span>
<span id="cb23-391"><a href="#cb23-391" aria-hidden="true" tabindex="-1"></a>            image_features, text_features, text_features</span>
<span id="cb23-392"><a href="#cb23-392" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-393"><a href="#cb23-393" aria-hidden="true" tabindex="-1"></a>        image_attended <span class="op">=</span> <span class="va">self</span>.norm1(image_features <span class="op">+</span> image_attended)</span>
<span id="cb23-394"><a href="#cb23-394" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-395"><a href="#cb23-395" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cross-modal attention: text attending to image</span></span>
<span id="cb23-396"><a href="#cb23-396" aria-hidden="true" tabindex="-1"></a>        text_attended, text_attention_weights <span class="op">=</span> <span class="va">self</span>.text_to_image_attention(</span>
<span id="cb23-397"><a href="#cb23-397" aria-hidden="true" tabindex="-1"></a>            text_features, image_features, image_features</span>
<span id="cb23-398"><a href="#cb23-398" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-399"><a href="#cb23-399" aria-hidden="true" tabindex="-1"></a>        text_attended <span class="op">=</span> <span class="va">self</span>.norm2(text_features <span class="op">+</span> text_attended)</span>
<span id="cb23-400"><a href="#cb23-400" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-401"><a href="#cb23-401" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Global pooling</span></span>
<span id="cb23-402"><a href="#cb23-402" aria-hidden="true" tabindex="-1"></a>        image_global <span class="op">=</span> image_attended.mean(dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># [batch_size, feature_dim]</span></span>
<span id="cb23-403"><a href="#cb23-403" aria-hidden="true" tabindex="-1"></a>        text_global <span class="op">=</span> text_attended.mean(dim<span class="op">=</span><span class="dv">1</span>)    <span class="co"># [batch_size, feature_dim]</span></span>
<span id="cb23-404"><a href="#cb23-404" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-405"><a href="#cb23-405" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concatenate and classify</span></span>
<span id="cb23-406"><a href="#cb23-406" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat([image_global, text_global], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-407"><a href="#cb23-407" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.classifier(combined)</span>
<span id="cb23-408"><a href="#cb23-408" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-409"><a href="#cb23-409" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output, {</span>
<span id="cb23-410"><a href="#cb23-410" aria-hidden="true" tabindex="-1"></a>            <span class="st">'image_attention_weights'</span>: image_attention_weights,</span>
<span id="cb23-411"><a href="#cb23-411" aria-hidden="true" tabindex="-1"></a>            <span class="st">'text_attention_weights'</span>: text_attention_weights,</span>
<span id="cb23-412"><a href="#cb23-412" aria-hidden="true" tabindex="-1"></a>            <span class="st">'image_global'</span>: image_global,</span>
<span id="cb23-413"><a href="#cb23-413" aria-hidden="true" tabindex="-1"></a>            <span class="st">'text_global'</span>: text_global</span>
<span id="cb23-414"><a href="#cb23-414" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb23-415"><a href="#cb23-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-416"><a href="#cb23-416" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstrate cross-modal attention</span></span>
<span id="cb23-417"><a href="#cb23-417" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_cross_modal_attention():</span>
<span id="cb23-418"><a href="#cb23-418" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show cross-modal attention mechanism"""</span></span>
<span id="cb23-419"><a href="#cb23-419" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-420"><a href="#cb23-420" aria-hidden="true" tabindex="-1"></a>    batch_size, feature_dim <span class="op">=</span> <span class="dv">4</span>, <span class="dv">512</span></span>
<span id="cb23-421"><a href="#cb23-421" aria-hidden="true" tabindex="-1"></a>    num_image_patches, seq_len <span class="op">=</span> <span class="dv">16</span>, <span class="dv">10</span></span>
<span id="cb23-422"><a href="#cb23-422" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-423"><a href="#cb23-423" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create sample features</span></span>
<span id="cb23-424"><a href="#cb23-424" aria-hidden="true" tabindex="-1"></a>    image_features <span class="op">=</span> torch.randn(batch_size, num_image_patches, feature_dim)</span>
<span id="cb23-425"><a href="#cb23-425" aria-hidden="true" tabindex="-1"></a>    text_features <span class="op">=</span> torch.randn(batch_size, seq_len, feature_dim)</span>
<span id="cb23-426"><a href="#cb23-426" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-427"><a href="#cb23-427" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create attention model</span></span>
<span id="cb23-428"><a href="#cb23-428" aria-hidden="true" tabindex="-1"></a>    attention_fusion <span class="op">=</span> CrossModalAttentionFusion(feature_dim<span class="op">=</span>feature_dim)</span>
<span id="cb23-429"><a href="#cb23-429" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-430"><a href="#cb23-430" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass</span></span>
<span id="cb23-431"><a href="#cb23-431" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb23-432"><a href="#cb23-432" aria-hidden="true" tabindex="-1"></a>        output, attention_info <span class="op">=</span> attention_fusion(image_features, text_features)</span>
<span id="cb23-433"><a href="#cb23-433" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-434"><a href="#cb23-434" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Cross-modal Attention Results:"</span>)</span>
<span id="cb23-435"><a href="#cb23-435" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">40</span>)</span>
<span id="cb23-436"><a href="#cb23-436" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Input shapes:"</span>)</span>
<span id="cb23-437"><a href="#cb23-437" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Image features: </span><span class="sc">{</span>image_features<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-438"><a href="#cb23-438" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Text features: </span><span class="sc">{</span>text_features<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-439"><a href="#cb23-439" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Output shape: </span><span class="sc">{</span>output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-440"><a href="#cb23-440" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-441"><a href="#cb23-441" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize attention weights</span></span>
<span id="cb23-442"><a href="#cb23-442" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb23-443"><a href="#cb23-443" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-444"><a href="#cb23-444" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Image-to-text attention (first sample)</span></span>
<span id="cb23-445"><a href="#cb23-445" aria-hidden="true" tabindex="-1"></a>    img_to_text_attn <span class="op">=</span> attention_info[<span class="st">'image_attention_weights'</span>][<span class="dv">0</span>].detach().numpy()</span>
<span id="cb23-446"><a href="#cb23-446" aria-hidden="true" tabindex="-1"></a>    im1 <span class="op">=</span> axes[<span class="dv">0</span>].imshow(img_to_text_attn, cmap<span class="op">=</span><span class="st">'Blues'</span>, aspect<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb23-447"><a href="#cb23-447" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_title(<span class="st">'Image-to-Text Attention'</span>)</span>
<span id="cb23-448"><a href="#cb23-448" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Text Positions'</span>)</span>
<span id="cb23-449"><a href="#cb23-449" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Image Patches'</span>)</span>
<span id="cb23-450"><a href="#cb23-450" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(im1, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb23-451"><a href="#cb23-451" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-452"><a href="#cb23-452" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Text-to-image attention (first sample)</span></span>
<span id="cb23-453"><a href="#cb23-453" aria-hidden="true" tabindex="-1"></a>    text_to_img_attn <span class="op">=</span> attention_info[<span class="st">'text_attention_weights'</span>][<span class="dv">0</span>].detach().numpy()</span>
<span id="cb23-454"><a href="#cb23-454" aria-hidden="true" tabindex="-1"></a>    im2 <span class="op">=</span> axes[<span class="dv">1</span>].imshow(text_to_img_attn, cmap<span class="op">=</span><span class="st">'Reds'</span>, aspect<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb23-455"><a href="#cb23-455" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_title(<span class="st">'Text-to-Image Attention'</span>)</span>
<span id="cb23-456"><a href="#cb23-456" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Image Patches'</span>)</span>
<span id="cb23-457"><a href="#cb23-457" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Text Positions'</span>)</span>
<span id="cb23-458"><a href="#cb23-458" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(im2, ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb23-459"><a href="#cb23-459" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-460"><a href="#cb23-460" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb23-461"><a href="#cb23-461" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-462"><a href="#cb23-462" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-463"><a href="#cb23-463" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> attention_fusion</span>
<span id="cb23-464"><a href="#cb23-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-465"><a href="#cb23-465" aria-hidden="true" tabindex="-1"></a>attention_model <span class="op">=</span> demonstrate_cross_modal_attention()</span>
<span id="cb23-466"><a href="#cb23-466" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-467"><a href="#cb23-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-468"><a href="#cb23-468" aria-hidden="true" tabindex="-1"></a><span class="fu">## Contrastive Learning for Multi-modal Data</span></span>
<span id="cb23-469"><a href="#cb23-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-470"><a href="#cb23-470" aria-hidden="true" tabindex="-1"></a><span class="fu">### CLIP-style Contrastive Learning</span></span>
<span id="cb23-473"><a href="#cb23-473" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-474"><a href="#cb23-474" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ContrastiveLearningModel(nn.Module):</span>
<span id="cb23-475"><a href="#cb23-475" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""CLIP-style contrastive learning for image-text pairs"""</span></span>
<span id="cb23-476"><a href="#cb23-476" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-477"><a href="#cb23-477" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, image_encoder_dim<span class="op">=</span><span class="dv">2048</span>, text_encoder_dim<span class="op">=</span><span class="dv">768</span>, projection_dim<span class="op">=</span><span class="dv">512</span>):</span>
<span id="cb23-478"><a href="#cb23-478" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb23-479"><a href="#cb23-479" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-480"><a href="#cb23-480" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simplified image encoder</span></span>
<span id="cb23-481"><a href="#cb23-481" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-482"><a href="#cb23-482" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">6</span>, <span class="dv">64</span>, <span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>),  <span class="co"># 6 channels for multispectral</span></span>
<span id="cb23-483"><a href="#cb23-483" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-484"><a href="#cb23-484" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">64</span>, <span class="dv">128</span>, <span class="dv">5</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb23-485"><a href="#cb23-485" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-486"><a href="#cb23-486" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">128</span>, <span class="dv">256</span>, <span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb23-487"><a href="#cb23-487" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-488"><a href="#cb23-488" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool2d((<span class="dv">1</span>, <span class="dv">1</span>)),</span>
<span id="cb23-489"><a href="#cb23-489" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb23-490"><a href="#cb23-490" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">256</span>, image_encoder_dim)</span>
<span id="cb23-491"><a href="#cb23-491" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-492"><a href="#cb23-492" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-493"><a href="#cb23-493" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simplified text encoder</span></span>
<span id="cb23-494"><a href="#cb23-494" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-495"><a href="#cb23-495" aria-hidden="true" tabindex="-1"></a>            nn.Embedding(<span class="dv">10000</span>, <span class="dv">256</span>),  <span class="co"># Vocab size 10000</span></span>
<span id="cb23-496"><a href="#cb23-496" aria-hidden="true" tabindex="-1"></a>            nn.LSTM(<span class="dv">256</span>, text_encoder_dim<span class="op">//</span><span class="dv">2</span>, batch_first<span class="op">=</span><span class="va">True</span>, bidirectional<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb23-497"><a href="#cb23-497" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-498"><a href="#cb23-498" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-499"><a href="#cb23-499" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Projection heads</span></span>
<span id="cb23-500"><a href="#cb23-500" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.image_projection <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-501"><a href="#cb23-501" aria-hidden="true" tabindex="-1"></a>            nn.Linear(image_encoder_dim, projection_dim),</span>
<span id="cb23-502"><a href="#cb23-502" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-503"><a href="#cb23-503" aria-hidden="true" tabindex="-1"></a>            nn.Linear(projection_dim, projection_dim)</span>
<span id="cb23-504"><a href="#cb23-504" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-505"><a href="#cb23-505" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-506"><a href="#cb23-506" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.text_projection <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-507"><a href="#cb23-507" aria-hidden="true" tabindex="-1"></a>            nn.Linear(text_encoder_dim, projection_dim),</span>
<span id="cb23-508"><a href="#cb23-508" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb23-509"><a href="#cb23-509" aria-hidden="true" tabindex="-1"></a>            nn.Linear(projection_dim, projection_dim)</span>
<span id="cb23-510"><a href="#cb23-510" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb23-511"><a href="#cb23-511" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-512"><a href="#cb23-512" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Temperature parameter for contrastive loss</span></span>
<span id="cb23-513"><a href="#cb23-513" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.temperature <span class="op">=</span> nn.Parameter(torch.tensor(<span class="fl">0.07</span>))</span>
<span id="cb23-514"><a href="#cb23-514" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-515"><a href="#cb23-515" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, images, text_tokens):</span>
<span id="cb23-516"><a href="#cb23-516" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode images</span></span>
<span id="cb23-517"><a href="#cb23-517" aria-hidden="true" tabindex="-1"></a>        image_features <span class="op">=</span> <span class="va">self</span>.image_encoder(images)</span>
<span id="cb23-518"><a href="#cb23-518" aria-hidden="true" tabindex="-1"></a>        image_embeddings <span class="op">=</span> <span class="va">self</span>.image_projection(image_features)</span>
<span id="cb23-519"><a href="#cb23-519" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-520"><a href="#cb23-520" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Encode text</span></span>
<span id="cb23-521"><a href="#cb23-521" aria-hidden="true" tabindex="-1"></a>        text_features, (h_n, c_n) <span class="op">=</span> <span class="va">self</span>.text_encoder(text_tokens)</span>
<span id="cb23-522"><a href="#cb23-522" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use final hidden states from both directions</span></span>
<span id="cb23-523"><a href="#cb23-523" aria-hidden="true" tabindex="-1"></a>        text_features <span class="op">=</span> torch.cat([h_n[<span class="op">-</span><span class="dv">2</span>], h_n[<span class="op">-</span><span class="dv">1</span>]], dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># Concatenate bidirectional</span></span>
<span id="cb23-524"><a href="#cb23-524" aria-hidden="true" tabindex="-1"></a>        text_embeddings <span class="op">=</span> <span class="va">self</span>.text_projection(text_features)</span>
<span id="cb23-525"><a href="#cb23-525" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-526"><a href="#cb23-526" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Normalize embeddings</span></span>
<span id="cb23-527"><a href="#cb23-527" aria-hidden="true" tabindex="-1"></a>        image_embeddings <span class="op">=</span> F.normalize(image_embeddings, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-528"><a href="#cb23-528" aria-hidden="true" tabindex="-1"></a>        text_embeddings <span class="op">=</span> F.normalize(text_embeddings, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-529"><a href="#cb23-529" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-530"><a href="#cb23-530" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> image_embeddings, text_embeddings</span>
<span id="cb23-531"><a href="#cb23-531" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-532"><a href="#cb23-532" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> contrastive_loss(<span class="va">self</span>, image_embeddings, text_embeddings):</span>
<span id="cb23-533"><a href="#cb23-533" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Calculate contrastive loss between image and text embeddings"""</span></span>
<span id="cb23-534"><a href="#cb23-534" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-535"><a href="#cb23-535" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> image_embeddings.shape[<span class="dv">0</span>]</span>
<span id="cb23-536"><a href="#cb23-536" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-537"><a href="#cb23-537" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate similarity matrix</span></span>
<span id="cb23-538"><a href="#cb23-538" aria-hidden="true" tabindex="-1"></a>        similarity_matrix <span class="op">=</span> torch.matmul(image_embeddings, text_embeddings.T) <span class="op">/</span> <span class="va">self</span>.temperature</span>
<span id="cb23-539"><a href="#cb23-539" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-540"><a href="#cb23-540" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create labels (diagonal should be positive pairs)</span></span>
<span id="cb23-541"><a href="#cb23-541" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> torch.arange(batch_size, device<span class="op">=</span>image_embeddings.device)</span>
<span id="cb23-542"><a href="#cb23-542" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-543"><a href="#cb23-543" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Contrastive loss (symmetric)</span></span>
<span id="cb23-544"><a href="#cb23-544" aria-hidden="true" tabindex="-1"></a>        loss_img_to_text <span class="op">=</span> F.cross_entropy(similarity_matrix, labels)</span>
<span id="cb23-545"><a href="#cb23-545" aria-hidden="true" tabindex="-1"></a>        loss_text_to_img <span class="op">=</span> F.cross_entropy(similarity_matrix.T, labels)</span>
<span id="cb23-546"><a href="#cb23-546" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-547"><a href="#cb23-547" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> (loss_img_to_text <span class="op">+</span> loss_text_to_img) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb23-548"><a href="#cb23-548" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-549"><a href="#cb23-549" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> total_loss, similarity_matrix</span>
<span id="cb23-550"><a href="#cb23-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-551"><a href="#cb23-551" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_contrastive_learning():</span>
<span id="cb23-552"><a href="#cb23-552" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Demonstrate contrastive learning training"""</span></span>
<span id="cb23-553"><a href="#cb23-553" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-554"><a href="#cb23-554" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create model</span></span>
<span id="cb23-555"><a href="#cb23-555" aria-hidden="true" tabindex="-1"></a>    contrastive_model <span class="op">=</span> ContrastiveLearningModel()</span>
<span id="cb23-556"><a href="#cb23-556" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-557"><a href="#cb23-557" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample data</span></span>
<span id="cb23-558"><a href="#cb23-558" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb23-559"><a href="#cb23-559" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> torch.randn(batch_size, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb23-560"><a href="#cb23-560" aria-hidden="true" tabindex="-1"></a>    text_tokens <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="dv">10000</span>, (batch_size, <span class="dv">20</span>))</span>
<span id="cb23-561"><a href="#cb23-561" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-562"><a href="#cb23-562" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass</span></span>
<span id="cb23-563"><a href="#cb23-563" aria-hidden="true" tabindex="-1"></a>    image_embeddings, text_embeddings <span class="op">=</span> contrastive_model(images, text_tokens)</span>
<span id="cb23-564"><a href="#cb23-564" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-565"><a href="#cb23-565" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate loss</span></span>
<span id="cb23-566"><a href="#cb23-566" aria-hidden="true" tabindex="-1"></a>    loss, similarity_matrix <span class="op">=</span> contrastive_model.contrastive_loss(image_embeddings, text_embeddings)</span>
<span id="cb23-567"><a href="#cb23-567" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-568"><a href="#cb23-568" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Contrastive Learning Results:"</span>)</span>
<span id="cb23-569"><a href="#cb23-569" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">40</span>)</span>
<span id="cb23-570"><a href="#cb23-570" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Image embeddings shape: </span><span class="sc">{</span>image_embeddings<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-571"><a href="#cb23-571" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text embeddings shape: </span><span class="sc">{</span>text_embeddings<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-572"><a href="#cb23-572" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Contrastive loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb23-573"><a href="#cb23-573" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Temperature: </span><span class="sc">{</span>contrastive_model<span class="sc">.</span>temperature<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb23-574"><a href="#cb23-574" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-575"><a href="#cb23-575" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize similarity matrix</span></span>
<span id="cb23-576"><a href="#cb23-576" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb23-577"><a href="#cb23-577" aria-hidden="true" tabindex="-1"></a>    plt.imshow(similarity_matrix.detach().numpy(), cmap<span class="op">=</span><span class="st">'RdBu_r'</span>, aspect<span class="op">=</span><span class="st">'equal'</span>)</span>
<span id="cb23-578"><a href="#cb23-578" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(label<span class="op">=</span><span class="st">'Similarity Score'</span>)</span>
<span id="cb23-579"><a href="#cb23-579" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Image-Text Similarity Matrix'</span>)</span>
<span id="cb23-580"><a href="#cb23-580" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Text Samples'</span>)</span>
<span id="cb23-581"><a href="#cb23-581" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Image Samples'</span>)</span>
<span id="cb23-582"><a href="#cb23-582" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-583"><a href="#cb23-583" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Highlight diagonal (positive pairs)</span></span>
<span id="cb23-584"><a href="#cb23-584" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb23-585"><a href="#cb23-585" aria-hidden="true" tabindex="-1"></a>        plt.scatter(i, i, marker<span class="op">=</span><span class="st">'x'</span>, s<span class="op">=</span><span class="dv">100</span>, color<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb23-586"><a href="#cb23-586" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-587"><a href="#cb23-587" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb23-588"><a href="#cb23-588" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-589"><a href="#cb23-589" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-590"><a href="#cb23-590" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show top-k retrievals</span></span>
<span id="cb23-591"><a href="#cb23-591" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> show_retrievals(similarity_matrix, k<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb23-592"><a href="#cb23-592" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Show top-k text retrievals for each image"""</span></span>
<span id="cb23-593"><a href="#cb23-593" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-594"><a href="#cb23-594" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Top-</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> Text Retrievals for Each Image:"</span>)</span>
<span id="cb23-595"><a href="#cb23-595" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb23-596"><a href="#cb23-596" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-597"><a href="#cb23-597" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> img_idx <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb23-598"><a href="#cb23-598" aria-hidden="true" tabindex="-1"></a>            similarities <span class="op">=</span> similarity_matrix[img_idx]</span>
<span id="cb23-599"><a href="#cb23-599" aria-hidden="true" tabindex="-1"></a>            top_k_indices <span class="op">=</span> similarities.topk(k).indices</span>
<span id="cb23-600"><a href="#cb23-600" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-601"><a href="#cb23-601" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Image </span><span class="sc">{</span>img_idx<span class="sc">}</span><span class="ss">: Text indices </span><span class="sc">{</span>top_k_indices<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-602"><a href="#cb23-602" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  Similarities: </span><span class="sc">{</span>similarities[top_k_indices]<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-603"><a href="#cb23-603" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-604"><a href="#cb23-604" aria-hidden="true" tabindex="-1"></a>    show_retrievals(similarity_matrix)</span>
<span id="cb23-605"><a href="#cb23-605" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-606"><a href="#cb23-606" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> contrastive_model</span>
<span id="cb23-607"><a href="#cb23-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-608"><a href="#cb23-608" aria-hidden="true" tabindex="-1"></a>contrastive_model <span class="op">=</span> demonstrate_contrastive_learning()</span>
<span id="cb23-609"><a href="#cb23-609" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-610"><a href="#cb23-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-611"><a href="#cb23-611" aria-hidden="true" tabindex="-1"></a><span class="fu">### Zero-Shot Classification</span></span>
<span id="cb23-614"><a href="#cb23-614" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-615"><a href="#cb23-615" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_zero_shot_classification():</span>
<span id="cb23-616"><a href="#cb23-616" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show zero-shot classification using learned embeddings"""</span></span>
<span id="cb23-617"><a href="#cb23-617" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-618"><a href="#cb23-618" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate a trained contrastive model</span></span>
<span id="cb23-619"><a href="#cb23-619" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> contrastive_model  <span class="co"># Use the model from previous example</span></span>
<span id="cb23-620"><a href="#cb23-620" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb23-621"><a href="#cb23-621" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-622"><a href="#cb23-622" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define text prompts for different land cover classes</span></span>
<span id="cb23-623"><a href="#cb23-623" aria-hidden="true" tabindex="-1"></a>    class_descriptions <span class="op">=</span> {</span>
<span id="cb23-624"><a href="#cb23-624" aria-hidden="true" tabindex="-1"></a>        <span class="st">'forest'</span>: <span class="st">"Dense forest area with trees and vegetation"</span>,</span>
<span id="cb23-625"><a href="#cb23-625" aria-hidden="true" tabindex="-1"></a>        <span class="st">'urban'</span>: <span class="st">"Urban area with buildings and infrastructure"</span>, </span>
<span id="cb23-626"><a href="#cb23-626" aria-hidden="true" tabindex="-1"></a>        <span class="st">'water'</span>: <span class="st">"Water body such as lake or river"</span>,</span>
<span id="cb23-627"><a href="#cb23-627" aria-hidden="true" tabindex="-1"></a>        <span class="st">'agriculture'</span>: <span class="st">"Agricultural land with crops and farming"</span>,</span>
<span id="cb23-628"><a href="#cb23-628" aria-hidden="true" tabindex="-1"></a>        <span class="st">'desert'</span>: <span class="st">"Desert area with sand and minimal vegetation"</span>,</span>
<span id="cb23-629"><a href="#cb23-629" aria-hidden="true" tabindex="-1"></a>        <span class="st">'grassland'</span>: <span class="st">"Grassland area with grass and open space"</span></span>
<span id="cb23-630"><a href="#cb23-630" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb23-631"><a href="#cb23-631" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-632"><a href="#cb23-632" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert descriptions to tokens (simplified)</span></span>
<span id="cb23-633"><a href="#cb23-633" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> simple_tokenize(text, max_length<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb23-634"><a href="#cb23-634" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Simple tokenization for demonstration"""</span></span>
<span id="cb23-635"><a href="#cb23-635" aria-hidden="true" tabindex="-1"></a>        words <span class="op">=</span> text.lower().split()[:max_length]</span>
<span id="cb23-636"><a href="#cb23-636" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Map words to random token IDs for demo</span></span>
<span id="cb23-637"><a href="#cb23-637" aria-hidden="true" tabindex="-1"></a>        np.random.seed(<span class="bu">hash</span>(text) <span class="op">%</span> <span class="dv">1000</span>)  <span class="co"># Consistent random mapping</span></span>
<span id="cb23-638"><a href="#cb23-638" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> [np.random.randint(<span class="dv">0</span>, <span class="dv">10000</span>) <span class="cf">for</span> _ <span class="kw">in</span> words]</span>
<span id="cb23-639"><a href="#cb23-639" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pad to max_length</span></span>
<span id="cb23-640"><a href="#cb23-640" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">+=</span> [<span class="dv">0</span>] <span class="op">*</span> (max_length <span class="op">-</span> <span class="bu">len</span>(tokens))</span>
<span id="cb23-641"><a href="#cb23-641" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.tensor(tokens[:max_length])</span>
<span id="cb23-642"><a href="#cb23-642" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-643"><a href="#cb23-643" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create text embeddings for each class</span></span>
<span id="cb23-644"><a href="#cb23-644" aria-hidden="true" tabindex="-1"></a>    class_embeddings <span class="op">=</span> {}</span>
<span id="cb23-645"><a href="#cb23-645" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb23-646"><a href="#cb23-646" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> class_name, description <span class="kw">in</span> class_descriptions.items():</span>
<span id="cb23-647"><a href="#cb23-647" aria-hidden="true" tabindex="-1"></a>            tokens <span class="op">=</span> simple_tokenize(description).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb23-648"><a href="#cb23-648" aria-hidden="true" tabindex="-1"></a>            _, text_embedding <span class="op">=</span> model(torch.zeros(<span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span>), tokens)</span>
<span id="cb23-649"><a href="#cb23-649" aria-hidden="true" tabindex="-1"></a>            class_embeddings[class_name] <span class="op">=</span> text_embedding.squeeze(<span class="dv">0</span>)</span>
<span id="cb23-650"><a href="#cb23-650" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-651"><a href="#cb23-651" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Test images (simulate different land covers)</span></span>
<span id="cb23-652"><a href="#cb23-652" aria-hidden="true" tabindex="-1"></a>    test_images <span class="op">=</span> torch.randn(<span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span>)  <span class="co"># 6 test images</span></span>
<span id="cb23-653"><a href="#cb23-653" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-654"><a href="#cb23-654" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb23-655"><a href="#cb23-655" aria-hidden="true" tabindex="-1"></a>        test_image_embeddings, _ <span class="op">=</span> model(test_images, torch.zeros(<span class="dv">6</span>, <span class="dv">20</span>, dtype<span class="op">=</span>torch.<span class="bu">long</span>))</span>
<span id="cb23-656"><a href="#cb23-656" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-657"><a href="#cb23-657" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate similarities and classify</span></span>
<span id="cb23-658"><a href="#cb23-658" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> []</span>
<span id="cb23-659"><a href="#cb23-659" aria-hidden="true" tabindex="-1"></a>    similarities_all <span class="op">=</span> []</span>
<span id="cb23-660"><a href="#cb23-660" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-661"><a href="#cb23-661" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, img_embedding <span class="kw">in</span> <span class="bu">enumerate</span>(test_image_embeddings):</span>
<span id="cb23-662"><a href="#cb23-662" aria-hidden="true" tabindex="-1"></a>        similarities <span class="op">=</span> {}</span>
<span id="cb23-663"><a href="#cb23-663" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> class_name, class_embedding <span class="kw">in</span> class_embeddings.items():</span>
<span id="cb23-664"><a href="#cb23-664" aria-hidden="true" tabindex="-1"></a>            similarity <span class="op">=</span> F.cosine_similarity(img_embedding, class_embedding, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb23-665"><a href="#cb23-665" aria-hidden="true" tabindex="-1"></a>            similarities[class_name] <span class="op">=</span> similarity.item()</span>
<span id="cb23-666"><a href="#cb23-666" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-667"><a href="#cb23-667" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get predicted class</span></span>
<span id="cb23-668"><a href="#cb23-668" aria-hidden="true" tabindex="-1"></a>        predicted_class <span class="op">=</span> <span class="bu">max</span>(similarities, key<span class="op">=</span>similarities.get)</span>
<span id="cb23-669"><a href="#cb23-669" aria-hidden="true" tabindex="-1"></a>        predictions.append(predicted_class)</span>
<span id="cb23-670"><a href="#cb23-670" aria-hidden="true" tabindex="-1"></a>        similarities_all.append(similarities)</span>
<span id="cb23-671"><a href="#cb23-671" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-672"><a href="#cb23-672" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display results</span></span>
<span id="cb23-673"><a href="#cb23-673" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Zero-Shot Classification Results:"</span>)</span>
<span id="cb23-674"><a href="#cb23-674" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb23-675"><a href="#cb23-675" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-676"><a href="#cb23-676" aria-hidden="true" tabindex="-1"></a>    class_names <span class="op">=</span> <span class="bu">list</span>(class_descriptions.keys())</span>
<span id="cb23-677"><a href="#cb23-677" aria-hidden="true" tabindex="-1"></a>    similarity_matrix <span class="op">=</span> np.zeros((<span class="bu">len</span>(test_images), <span class="bu">len</span>(class_names)))</span>
<span id="cb23-678"><a href="#cb23-678" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-679"><a href="#cb23-679" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, similarities <span class="kw">in</span> <span class="bu">enumerate</span>(similarities_all):</span>
<span id="cb23-680"><a href="#cb23-680" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Test Image </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: Predicted as '</span><span class="sc">{</span>predictions[i]<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb23-681"><a href="#cb23-681" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j, class_name <span class="kw">in</span> <span class="bu">enumerate</span>(class_names):</span>
<span id="cb23-682"><a href="#cb23-682" aria-hidden="true" tabindex="-1"></a>            similarity_matrix[i, j] <span class="op">=</span> similarities[class_name]</span>
<span id="cb23-683"><a href="#cb23-683" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>class_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>similarities[class_name]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-684"><a href="#cb23-684" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-685"><a href="#cb23-685" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize similarity heatmap</span></span>
<span id="cb23-686"><a href="#cb23-686" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb23-687"><a href="#cb23-687" aria-hidden="true" tabindex="-1"></a>    plt.imshow(similarity_matrix, cmap<span class="op">=</span><span class="st">'RdYlBu_r'</span>, aspect<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb23-688"><a href="#cb23-688" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(label<span class="op">=</span><span class="st">'Cosine Similarity'</span>)</span>
<span id="cb23-689"><a href="#cb23-689" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Classes'</span>)</span>
<span id="cb23-690"><a href="#cb23-690" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Test Images'</span>)</span>
<span id="cb23-691"><a href="#cb23-691" aria-hidden="true" tabindex="-1"></a>    plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(class_names)), class_names, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb23-692"><a href="#cb23-692" aria-hidden="true" tabindex="-1"></a>    plt.yticks(<span class="bu">range</span>(<span class="bu">len</span>(test_images)), [<span class="ss">f'Image </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_images))])</span>
<span id="cb23-693"><a href="#cb23-693" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Zero-Shot Classification Similarities'</span>)</span>
<span id="cb23-694"><a href="#cb23-694" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-695"><a href="#cb23-695" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add prediction markers</span></span>
<span id="cb23-696"><a href="#cb23-696" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, pred_class <span class="kw">in</span> <span class="bu">enumerate</span>(predictions):</span>
<span id="cb23-697"><a href="#cb23-697" aria-hidden="true" tabindex="-1"></a>        j <span class="op">=</span> class_names.index(pred_class)</span>
<span id="cb23-698"><a href="#cb23-698" aria-hidden="true" tabindex="-1"></a>        plt.scatter(j, i, marker<span class="op">=</span><span class="st">'x'</span>, s<span class="op">=</span><span class="dv">200</span>, color<span class="op">=</span><span class="st">'white'</span>, linewidth<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb23-699"><a href="#cb23-699" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-700"><a href="#cb23-700" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb23-701"><a href="#cb23-701" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-702"><a href="#cb23-702" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-703"><a href="#cb23-703" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions, similarities_all</span>
<span id="cb23-704"><a href="#cb23-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-705"><a href="#cb23-705" aria-hidden="true" tabindex="-1"></a>zeroshot_predictions, zeroshot_similarities <span class="op">=</span> demonstrate_zero_shot_classification()</span>
<span id="cb23-706"><a href="#cb23-706" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-707"><a href="#cb23-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-708"><a href="#cb23-708" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multi-modal Data Augmentation</span></span>
<span id="cb23-709"><a href="#cb23-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-710"><a href="#cb23-710" aria-hidden="true" tabindex="-1"></a><span class="fu">### Cross-modal Data Augmentation</span></span>
<span id="cb23-713"><a href="#cb23-713" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-714"><a href="#cb23-714" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_multimodal_augmentation():</span>
<span id="cb23-715"><a href="#cb23-715" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show augmentation techniques for multi-modal data"""</span></span>
<span id="cb23-716"><a href="#cb23-716" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-717"><a href="#cb23-717" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original data</span></span>
<span id="cb23-718"><a href="#cb23-718" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb23-719"><a href="#cb23-719" aria-hidden="true" tabindex="-1"></a>    original_images <span class="op">=</span> torch.randn(batch_size, <span class="dv">6</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb23-720"><a href="#cb23-720" aria-hidden="true" tabindex="-1"></a>    original_texts <span class="op">=</span> [</span>
<span id="cb23-721"><a href="#cb23-721" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Forest area with dense canopy"</span>,</span>
<span id="cb23-722"><a href="#cb23-722" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Urban residential district"</span>, </span>
<span id="cb23-723"><a href="#cb23-723" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Agricultural crop fields"</span>,</span>
<span id="cb23-724"><a href="#cb23-724" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Coastal wetland ecosystem"</span></span>
<span id="cb23-725"><a href="#cb23-725" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb23-726"><a href="#cb23-726" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-727"><a href="#cb23-727" aria-hidden="true" tabindex="-1"></a>    <span class="kw">class</span> MultiModalAugmentation:</span>
<span id="cb23-728"><a href="#cb23-728" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Multi-modal data augmentation techniques"""</span></span>
<span id="cb23-729"><a href="#cb23-729" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-730"><a href="#cb23-730" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb23-731"><a href="#cb23-731" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.augmentation_strategies <span class="op">=</span> [</span>
<span id="cb23-732"><a href="#cb23-732" aria-hidden="true" tabindex="-1"></a>                <span class="st">'spatial_crop'</span>,</span>
<span id="cb23-733"><a href="#cb23-733" aria-hidden="true" tabindex="-1"></a>                <span class="st">'spectral_shift'</span>,</span>
<span id="cb23-734"><a href="#cb23-734" aria-hidden="true" tabindex="-1"></a>                <span class="st">'text_synonym'</span>,</span>
<span id="cb23-735"><a href="#cb23-735" aria-hidden="true" tabindex="-1"></a>                <span class="st">'mixup'</span>,</span>
<span id="cb23-736"><a href="#cb23-736" aria-hidden="true" tabindex="-1"></a>                <span class="st">'cutmix'</span></span>
<span id="cb23-737"><a href="#cb23-737" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb23-738"><a href="#cb23-738" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-739"><a href="#cb23-739" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> spatial_crop(<span class="va">self</span>, images, texts, crop_ratio<span class="op">=</span><span class="fl">0.8</span>):</span>
<span id="cb23-740"><a href="#cb23-740" aria-hidden="true" tabindex="-1"></a>            <span class="co">"""Spatial cropping with corresponding text modification"""</span></span>
<span id="cb23-741"><a href="#cb23-741" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-742"><a href="#cb23-742" aria-hidden="true" tabindex="-1"></a>            _, _, h, w <span class="op">=</span> images.shape</span>
<span id="cb23-743"><a href="#cb23-743" aria-hidden="true" tabindex="-1"></a>            crop_h, crop_w <span class="op">=</span> <span class="bu">int</span>(h <span class="op">*</span> crop_ratio), <span class="bu">int</span>(w <span class="op">*</span> crop_ratio)</span>
<span id="cb23-744"><a href="#cb23-744" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-745"><a href="#cb23-745" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Random crop position</span></span>
<span id="cb23-746"><a href="#cb23-746" aria-hidden="true" tabindex="-1"></a>            start_h <span class="op">=</span> torch.randint(<span class="dv">0</span>, h <span class="op">-</span> crop_h <span class="op">+</span> <span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb23-747"><a href="#cb23-747" aria-hidden="true" tabindex="-1"></a>            start_w <span class="op">=</span> torch.randint(<span class="dv">0</span>, w <span class="op">-</span> crop_w <span class="op">+</span> <span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb23-748"><a href="#cb23-748" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-749"><a href="#cb23-749" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Crop images</span></span>
<span id="cb23-750"><a href="#cb23-750" aria-hidden="true" tabindex="-1"></a>            cropped_images <span class="op">=</span> images[:, :, start_h:start_h<span class="op">+</span>crop_h, start_w:start_w<span class="op">+</span>crop_w]</span>
<span id="cb23-751"><a href="#cb23-751" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-752"><a href="#cb23-752" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Resize back to original size</span></span>
<span id="cb23-753"><a href="#cb23-753" aria-hidden="true" tabindex="-1"></a>            cropped_images <span class="op">=</span> F.interpolate(cropped_images, size<span class="op">=</span>(h, w), mode<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb23-754"><a href="#cb23-754" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-755"><a href="#cb23-755" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Modify texts to indicate cropping</span></span>
<span id="cb23-756"><a href="#cb23-756" aria-hidden="true" tabindex="-1"></a>            modified_texts <span class="op">=</span> [<span class="ss">f"Cropped view of </span><span class="sc">{</span>text<span class="sc">.</span>lower()<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> text <span class="kw">in</span> texts]</span>
<span id="cb23-757"><a href="#cb23-757" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-758"><a href="#cb23-758" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> cropped_images, modified_texts</span>
<span id="cb23-759"><a href="#cb23-759" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-760"><a href="#cb23-760" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> spectral_shift(<span class="va">self</span>, images, texts, shift_factor<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb23-761"><a href="#cb23-761" aria-hidden="true" tabindex="-1"></a>            <span class="co">"""Spectral band shifting"""</span></span>
<span id="cb23-762"><a href="#cb23-762" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-763"><a href="#cb23-763" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Randomly shift spectral bands</span></span>
<span id="cb23-764"><a href="#cb23-764" aria-hidden="true" tabindex="-1"></a>            shifted_images <span class="op">=</span> images.clone()</span>
<span id="cb23-765"><a href="#cb23-765" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(images.shape[<span class="dv">1</span>]):  <span class="co"># For each spectral band</span></span>
<span id="cb23-766"><a href="#cb23-766" aria-hidden="true" tabindex="-1"></a>                shift <span class="op">=</span> torch.normal(<span class="dv">0</span>, shift_factor, size<span class="op">=</span>(<span class="dv">1</span>,)).item()</span>
<span id="cb23-767"><a href="#cb23-767" aria-hidden="true" tabindex="-1"></a>                shifted_images[:, i] <span class="op">=</span> images[:, i] <span class="op">+</span> shift</span>
<span id="cb23-768"><a href="#cb23-768" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-769"><a href="#cb23-769" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Clamp to valid range</span></span>
<span id="cb23-770"><a href="#cb23-770" aria-hidden="true" tabindex="-1"></a>            shifted_images <span class="op">=</span> torch.clamp(shifted_images, <span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)  <span class="co"># Assuming normalized data</span></span>
<span id="cb23-771"><a href="#cb23-771" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-772"><a href="#cb23-772" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Modify texts to indicate spectral variation</span></span>
<span id="cb23-773"><a href="#cb23-773" aria-hidden="true" tabindex="-1"></a>            modified_texts <span class="op">=</span> [<span class="ss">f"</span><span class="sc">{</span>text<span class="sc">}</span><span class="ss"> with spectral variation"</span> <span class="cf">for</span> text <span class="kw">in</span> texts]</span>
<span id="cb23-774"><a href="#cb23-774" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-775"><a href="#cb23-775" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> shifted_images, modified_texts</span>
<span id="cb23-776"><a href="#cb23-776" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-777"><a href="#cb23-777" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> text_synonym_replacement(<span class="va">self</span>, texts, replacement_prob<span class="op">=</span><span class="fl">0.3</span>):</span>
<span id="cb23-778"><a href="#cb23-778" aria-hidden="true" tabindex="-1"></a>            <span class="co">"""Replace words with synonyms"""</span></span>
<span id="cb23-779"><a href="#cb23-779" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-780"><a href="#cb23-780" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Simple synonym dictionary</span></span>
<span id="cb23-781"><a href="#cb23-781" aria-hidden="true" tabindex="-1"></a>            synonyms <span class="op">=</span> {</span>
<span id="cb23-782"><a href="#cb23-782" aria-hidden="true" tabindex="-1"></a>                <span class="st">'forest'</span>: [<span class="st">'woodland'</span>, <span class="st">'trees'</span>, <span class="st">'vegetation'</span>],</span>
<span id="cb23-783"><a href="#cb23-783" aria-hidden="true" tabindex="-1"></a>                <span class="st">'urban'</span>: [<span class="st">'city'</span>, <span class="st">'metropolitan'</span>, <span class="st">'developed'</span>],</span>
<span id="cb23-784"><a href="#cb23-784" aria-hidden="true" tabindex="-1"></a>                <span class="st">'agricultural'</span>: [<span class="st">'farming'</span>, <span class="st">'crop'</span>, <span class="st">'cultivation'</span>],</span>
<span id="cb23-785"><a href="#cb23-785" aria-hidden="true" tabindex="-1"></a>                <span class="st">'area'</span>: [<span class="st">'region'</span>, <span class="st">'zone'</span>, <span class="st">'location'</span>],</span>
<span id="cb23-786"><a href="#cb23-786" aria-hidden="true" tabindex="-1"></a>                <span class="st">'dense'</span>: [<span class="st">'thick'</span>, <span class="st">'concentrated'</span>, <span class="st">'heavy'</span>]</span>
<span id="cb23-787"><a href="#cb23-787" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb23-788"><a href="#cb23-788" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-789"><a href="#cb23-789" aria-hidden="true" tabindex="-1"></a>            modified_texts <span class="op">=</span> []</span>
<span id="cb23-790"><a href="#cb23-790" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> text <span class="kw">in</span> texts:</span>
<span id="cb23-791"><a href="#cb23-791" aria-hidden="true" tabindex="-1"></a>                words <span class="op">=</span> text.split()</span>
<span id="cb23-792"><a href="#cb23-792" aria-hidden="true" tabindex="-1"></a>                new_words <span class="op">=</span> []</span>
<span id="cb23-793"><a href="#cb23-793" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb23-794"><a href="#cb23-794" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb23-795"><a href="#cb23-795" aria-hidden="true" tabindex="-1"></a>                    word_lower <span class="op">=</span> word.lower()</span>
<span id="cb23-796"><a href="#cb23-796" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> word_lower <span class="kw">in</span> synonyms <span class="kw">and</span> torch.rand(<span class="dv">1</span>).item() <span class="op">&lt;</span> replacement_prob:</span>
<span id="cb23-797"><a href="#cb23-797" aria-hidden="true" tabindex="-1"></a>                        synonym <span class="op">=</span> np.random.choice(synonyms[word_lower])</span>
<span id="cb23-798"><a href="#cb23-798" aria-hidden="true" tabindex="-1"></a>                        new_words.append(synonym)</span>
<span id="cb23-799"><a href="#cb23-799" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">else</span>:</span>
<span id="cb23-800"><a href="#cb23-800" aria-hidden="true" tabindex="-1"></a>                        new_words.append(word)</span>
<span id="cb23-801"><a href="#cb23-801" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb23-802"><a href="#cb23-802" aria-hidden="true" tabindex="-1"></a>                modified_texts.append(<span class="st">' '</span>.join(new_words))</span>
<span id="cb23-803"><a href="#cb23-803" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-804"><a href="#cb23-804" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> modified_texts</span>
<span id="cb23-805"><a href="#cb23-805" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-806"><a href="#cb23-806" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> mixup_multimodal(<span class="va">self</span>, images, texts, alpha<span class="op">=</span><span class="fl">0.4</span>):</span>
<span id="cb23-807"><a href="#cb23-807" aria-hidden="true" tabindex="-1"></a>            <span class="co">"""MixUp augmentation for multi-modal data"""</span></span>
<span id="cb23-808"><a href="#cb23-808" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-809"><a href="#cb23-809" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(images) <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb23-810"><a href="#cb23-810" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> images, texts</span>
<span id="cb23-811"><a href="#cb23-811" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-812"><a href="#cb23-812" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Generate mixing weights</span></span>
<span id="cb23-813"><a href="#cb23-813" aria-hidden="true" tabindex="-1"></a>            lam <span class="op">=</span> np.random.beta(alpha, alpha)</span>
<span id="cb23-814"><a href="#cb23-814" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-815"><a href="#cb23-815" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Shuffle indices for mixing</span></span>
<span id="cb23-816"><a href="#cb23-816" aria-hidden="true" tabindex="-1"></a>            batch_size <span class="op">=</span> images.shape[<span class="dv">0</span>]</span>
<span id="cb23-817"><a href="#cb23-817" aria-hidden="true" tabindex="-1"></a>            indices <span class="op">=</span> torch.randperm(batch_size)</span>
<span id="cb23-818"><a href="#cb23-818" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-819"><a href="#cb23-819" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Mix images</span></span>
<span id="cb23-820"><a href="#cb23-820" aria-hidden="true" tabindex="-1"></a>            mixed_images <span class="op">=</span> lam <span class="op">*</span> images <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> lam) <span class="op">*</span> images[indices]</span>
<span id="cb23-821"><a href="#cb23-821" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-822"><a href="#cb23-822" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Mix texts (concatenate with mixing indicator)</span></span>
<span id="cb23-823"><a href="#cb23-823" aria-hidden="true" tabindex="-1"></a>            mixed_texts <span class="op">=</span> []</span>
<span id="cb23-824"><a href="#cb23-824" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(texts)):</span>
<span id="cb23-825"><a href="#cb23-825" aria-hidden="true" tabindex="-1"></a>                mixed_texts.append(<span class="ss">f"Mixed scene: </span><span class="sc">{</span>lam<span class="sc">:.2f}</span><span class="ss"> * (</span><span class="sc">{</span>texts[i]<span class="sc">}</span><span class="ss">) + </span><span class="sc">{</span><span class="dv">1</span><span class="op">-</span>lam<span class="sc">:.2f}</span><span class="ss"> * (</span><span class="sc">{</span>texts[indices[i]]<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb23-826"><a href="#cb23-826" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-827"><a href="#cb23-827" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> mixed_images, mixed_texts</span>
<span id="cb23-828"><a href="#cb23-828" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-829"><a href="#cb23-829" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> cutmix_multimodal(<span class="va">self</span>, images, texts, alpha<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb23-830"><a href="#cb23-830" aria-hidden="true" tabindex="-1"></a>            <span class="co">"""CutMix augmentation for multi-modal data"""</span></span>
<span id="cb23-831"><a href="#cb23-831" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-832"><a href="#cb23-832" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(images) <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb23-833"><a href="#cb23-833" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> images, texts</span>
<span id="cb23-834"><a href="#cb23-834" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-835"><a href="#cb23-835" aria-hidden="true" tabindex="-1"></a>            lam <span class="op">=</span> np.random.beta(alpha, alpha)</span>
<span id="cb23-836"><a href="#cb23-836" aria-hidden="true" tabindex="-1"></a>            batch_size <span class="op">=</span> images.shape[<span class="dv">0</span>]</span>
<span id="cb23-837"><a href="#cb23-837" aria-hidden="true" tabindex="-1"></a>            indices <span class="op">=</span> torch.randperm(batch_size)</span>
<span id="cb23-838"><a href="#cb23-838" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-839"><a href="#cb23-839" aria-hidden="true" tabindex="-1"></a>            _, _, h, w <span class="op">=</span> images.shape</span>
<span id="cb23-840"><a href="#cb23-840" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-841"><a href="#cb23-841" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Generate random bounding box</span></span>
<span id="cb23-842"><a href="#cb23-842" aria-hidden="true" tabindex="-1"></a>            cut_rat <span class="op">=</span> np.sqrt(<span class="fl">1.</span> <span class="op">-</span> lam)</span>
<span id="cb23-843"><a href="#cb23-843" aria-hidden="true" tabindex="-1"></a>            cut_w <span class="op">=</span> <span class="bu">int</span>(w <span class="op">*</span> cut_rat)</span>
<span id="cb23-844"><a href="#cb23-844" aria-hidden="true" tabindex="-1"></a>            cut_h <span class="op">=</span> <span class="bu">int</span>(h <span class="op">*</span> cut_rat)</span>
<span id="cb23-845"><a href="#cb23-845" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-846"><a href="#cb23-846" aria-hidden="true" tabindex="-1"></a>            cx <span class="op">=</span> np.random.randint(w)</span>
<span id="cb23-847"><a href="#cb23-847" aria-hidden="true" tabindex="-1"></a>            cy <span class="op">=</span> np.random.randint(h)</span>
<span id="cb23-848"><a href="#cb23-848" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-849"><a href="#cb23-849" aria-hidden="true" tabindex="-1"></a>            bbx1 <span class="op">=</span> np.clip(cx <span class="op">-</span> cut_w <span class="op">//</span> <span class="dv">2</span>, <span class="dv">0</span>, w)</span>
<span id="cb23-850"><a href="#cb23-850" aria-hidden="true" tabindex="-1"></a>            bby1 <span class="op">=</span> np.clip(cy <span class="op">-</span> cut_h <span class="op">//</span> <span class="dv">2</span>, <span class="dv">0</span>, h)</span>
<span id="cb23-851"><a href="#cb23-851" aria-hidden="true" tabindex="-1"></a>            bbx2 <span class="op">=</span> np.clip(cx <span class="op">+</span> cut_w <span class="op">//</span> <span class="dv">2</span>, <span class="dv">0</span>, w)</span>
<span id="cb23-852"><a href="#cb23-852" aria-hidden="true" tabindex="-1"></a>            bby2 <span class="op">=</span> np.clip(cy <span class="op">+</span> cut_h <span class="op">//</span> <span class="dv">2</span>, <span class="dv">0</span>, h)</span>
<span id="cb23-853"><a href="#cb23-853" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-854"><a href="#cb23-854" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Apply cutmix</span></span>
<span id="cb23-855"><a href="#cb23-855" aria-hidden="true" tabindex="-1"></a>            mixed_images <span class="op">=</span> images.clone()</span>
<span id="cb23-856"><a href="#cb23-856" aria-hidden="true" tabindex="-1"></a>            mixed_images[:, :, bby1:bby2, bbx1:bbx2] <span class="op">=</span> images[indices, :, bby1:bby2, bbx1:bbx2]</span>
<span id="cb23-857"><a href="#cb23-857" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-858"><a href="#cb23-858" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Mix texts</span></span>
<span id="cb23-859"><a href="#cb23-859" aria-hidden="true" tabindex="-1"></a>            mixed_texts <span class="op">=</span> []</span>
<span id="cb23-860"><a href="#cb23-860" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(texts)):</span>
<span id="cb23-861"><a href="#cb23-861" aria-hidden="true" tabindex="-1"></a>                mixed_texts.append(<span class="ss">f"Scene with cutmix: </span><span class="sc">{</span>texts[i]<span class="sc">}</span><span class="ss"> + patch from </span><span class="sc">{</span>texts[indices[i]]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-862"><a href="#cb23-862" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb23-863"><a href="#cb23-863" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> mixed_images, mixed_texts</span>
<span id="cb23-864"><a href="#cb23-864" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-865"><a href="#cb23-865" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Demonstrate augmentations</span></span>
<span id="cb23-866"><a href="#cb23-866" aria-hidden="true" tabindex="-1"></a>    augmenter <span class="op">=</span> MultiModalAugmentation()</span>
<span id="cb23-867"><a href="#cb23-867" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-868"><a href="#cb23-868" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-modal Data Augmentation Examples:"</span>)</span>
<span id="cb23-869"><a href="#cb23-869" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb23-870"><a href="#cb23-870" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-871"><a href="#cb23-871" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original</span></span>
<span id="cb23-872"><a href="#cb23-872" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Original texts:"</span>)</span>
<span id="cb23-873"><a href="#cb23-873" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, text <span class="kw">in</span> <span class="bu">enumerate</span>(original_texts):</span>
<span id="cb23-874"><a href="#cb23-874" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-875"><a href="#cb23-875" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-876"><a href="#cb23-876" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Spatial crop</span></span>
<span id="cb23-877"><a href="#cb23-877" aria-hidden="true" tabindex="-1"></a>    cropped_imgs, cropped_texts <span class="op">=</span> augmenter.spatial_crop(original_images, original_texts)</span>
<span id="cb23-878"><a href="#cb23-878" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Spatial Crop:"</span>)</span>
<span id="cb23-879"><a href="#cb23-879" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Image shape change: </span><span class="sc">{</span>original_images<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> -&gt; </span><span class="sc">{</span>cropped_imgs<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-880"><a href="#cb23-880" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, text <span class="kw">in</span> <span class="bu">enumerate</span>(cropped_texts[:<span class="dv">2</span>]):  <span class="co"># Show first 2</span></span>
<span id="cb23-881"><a href="#cb23-881" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-882"><a href="#cb23-882" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-883"><a href="#cb23-883" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Spectral shift</span></span>
<span id="cb23-884"><a href="#cb23-884" aria-hidden="true" tabindex="-1"></a>    shifted_imgs, shifted_texts <span class="op">=</span> augmenter.spectral_shift(original_images, original_texts)</span>
<span id="cb23-885"><a href="#cb23-885" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Spectral Shift:"</span>)</span>
<span id="cb23-886"><a href="#cb23-886" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Value range change: [</span><span class="sc">{</span>original_images<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>original_images<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.2f}</span><span class="ss">] -&gt; [</span><span class="sc">{</span>shifted_imgs<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.2f}</span><span class="ss">, </span><span class="sc">{</span>shifted_imgs<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb23-887"><a href="#cb23-887" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-888"><a href="#cb23-888" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Text synonym replacement</span></span>
<span id="cb23-889"><a href="#cb23-889" aria-hidden="true" tabindex="-1"></a>    synonym_texts <span class="op">=</span> augmenter.text_synonym_replacement(original_texts)</span>
<span id="cb23-890"><a href="#cb23-890" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Synonym Replacement:"</span>)</span>
<span id="cb23-891"><a href="#cb23-891" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (orig, syn) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(original_texts[:<span class="dv">2</span>], synonym_texts[:<span class="dv">2</span>])):</span>
<span id="cb23-892"><a href="#cb23-892" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: '</span><span class="sc">{</span>orig<span class="sc">}</span><span class="ss">' -&gt; '</span><span class="sc">{</span>syn<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb23-893"><a href="#cb23-893" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-894"><a href="#cb23-894" aria-hidden="true" tabindex="-1"></a>    <span class="co"># MixUp</span></span>
<span id="cb23-895"><a href="#cb23-895" aria-hidden="true" tabindex="-1"></a>    mixup_imgs, mixup_texts <span class="op">=</span> augmenter.mixup_multimodal(original_images, original_texts)</span>
<span id="cb23-896"><a href="#cb23-896" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">MixUp:"</span>)</span>
<span id="cb23-897"><a href="#cb23-897" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Example: </span><span class="sc">{</span>mixup_texts[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-898"><a href="#cb23-898" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-899"><a href="#cb23-899" aria-hidden="true" tabindex="-1"></a>    <span class="co"># CutMix</span></span>
<span id="cb23-900"><a href="#cb23-900" aria-hidden="true" tabindex="-1"></a>    cutmix_imgs, cutmix_texts <span class="op">=</span> augmenter.cutmix_multimodal(original_images, original_texts)</span>
<span id="cb23-901"><a href="#cb23-901" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">CutMix:"</span>)</span>
<span id="cb23-902"><a href="#cb23-902" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Example: </span><span class="sc">{</span>cutmix_texts[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-903"><a href="#cb23-903" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-904"><a href="#cb23-904" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize augmentation effects</span></span>
<span id="cb23-905"><a href="#cb23-905" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">10</span>))</span>
<span id="cb23-906"><a href="#cb23-906" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-907"><a href="#cb23-907" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> visualize_image(img_tensor, ax, title):</span>
<span id="cb23-908"><a href="#cb23-908" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Visualize first 3 channels as RGB"""</span></span>
<span id="cb23-909"><a href="#cb23-909" aria-hidden="true" tabindex="-1"></a>        img_rgb <span class="op">=</span> img_tensor[<span class="dv">0</span>, :<span class="dv">3</span>].detach().numpy().transpose(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)</span>
<span id="cb23-910"><a href="#cb23-910" aria-hidden="true" tabindex="-1"></a>        img_rgb <span class="op">=</span> (img_rgb <span class="op">-</span> img_rgb.<span class="bu">min</span>()) <span class="op">/</span> (img_rgb.<span class="bu">max</span>() <span class="op">-</span> img_rgb.<span class="bu">min</span>())</span>
<span id="cb23-911"><a href="#cb23-911" aria-hidden="true" tabindex="-1"></a>        ax.imshow(img_rgb)</span>
<span id="cb23-912"><a href="#cb23-912" aria-hidden="true" tabindex="-1"></a>        ax.set_title(title)</span>
<span id="cb23-913"><a href="#cb23-913" aria-hidden="true" tabindex="-1"></a>        ax.axis(<span class="st">'off'</span>)</span>
<span id="cb23-914"><a href="#cb23-914" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-915"><a href="#cb23-915" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Original and augmented images</span></span>
<span id="cb23-916"><a href="#cb23-916" aria-hidden="true" tabindex="-1"></a>    augmented_images <span class="op">=</span> [</span>
<span id="cb23-917"><a href="#cb23-917" aria-hidden="true" tabindex="-1"></a>        (original_images, <span class="st">"Original"</span>),</span>
<span id="cb23-918"><a href="#cb23-918" aria-hidden="true" tabindex="-1"></a>        (cropped_imgs, <span class="st">"Spatial Crop"</span>),</span>
<span id="cb23-919"><a href="#cb23-919" aria-hidden="true" tabindex="-1"></a>        (shifted_imgs, <span class="st">"Spectral Shift"</span>),</span>
<span id="cb23-920"><a href="#cb23-920" aria-hidden="true" tabindex="-1"></a>        (mixup_imgs, <span class="st">"MixUp"</span>),</span>
<span id="cb23-921"><a href="#cb23-921" aria-hidden="true" tabindex="-1"></a>        (cutmix_imgs, <span class="st">"CutMix"</span>)</span>
<span id="cb23-922"><a href="#cb23-922" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb23-923"><a href="#cb23-923" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-924"><a href="#cb23-924" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (imgs, title) <span class="kw">in</span> <span class="bu">enumerate</span>(augmented_images[:<span class="dv">6</span>]):</span>
<span id="cb23-925"><a href="#cb23-925" aria-hidden="true" tabindex="-1"></a>        row, col <span class="op">=</span> i <span class="op">//</span> <span class="dv">3</span>, i <span class="op">%</span> <span class="dv">3</span></span>
<span id="cb23-926"><a href="#cb23-926" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> row <span class="op">&lt;</span> <span class="dv">2</span>:</span>
<span id="cb23-927"><a href="#cb23-927" aria-hidden="true" tabindex="-1"></a>            visualize_image(imgs, axes[row, col], title)</span>
<span id="cb23-928"><a href="#cb23-928" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-929"><a href="#cb23-929" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Hide unused subplot</span></span>
<span id="cb23-930"><a href="#cb23-930" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(augmented_images) <span class="op">&lt;</span> <span class="dv">6</span>:</span>
<span id="cb23-931"><a href="#cb23-931" aria-hidden="true" tabindex="-1"></a>        axes[<span class="dv">1</span>, <span class="dv">2</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb23-932"><a href="#cb23-932" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-933"><a href="#cb23-933" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb23-934"><a href="#cb23-934" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-935"><a href="#cb23-935" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-936"><a href="#cb23-936" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> augmenter</span>
<span id="cb23-937"><a href="#cb23-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-938"><a href="#cb23-938" aria-hidden="true" tabindex="-1"></a>augmenter <span class="op">=</span> demonstrate_multimodal_augmentation()</span>
<span id="cb23-939"><a href="#cb23-939" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-940"><a href="#cb23-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-941"><a href="#cb23-941" aria-hidden="true" tabindex="-1"></a><span class="fu">## Performance Evaluation Metrics</span></span>
<span id="cb23-942"><a href="#cb23-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-943"><a href="#cb23-943" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multi-modal Evaluation</span></span>
<span id="cb23-946"><a href="#cb23-946" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-947"><a href="#cb23-947" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_multimodal_evaluation():</span>
<span id="cb23-948"><a href="#cb23-948" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Demonstrate evaluation metrics for multi-modal models"""</span></span>
<span id="cb23-949"><a href="#cb23-949" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-950"><a href="#cb23-950" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate predictions and ground truth</span></span>
<span id="cb23-951"><a href="#cb23-951" aria-hidden="true" tabindex="-1"></a>    np.random.seed(<span class="dv">42</span>)</span>
<span id="cb23-952"><a href="#cb23-952" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-953"><a href="#cb23-953" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Classification task</span></span>
<span id="cb23-954"><a href="#cb23-954" aria-hidden="true" tabindex="-1"></a>    num_samples <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb23-955"><a href="#cb23-955" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb23-956"><a href="#cb23-956" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-957"><a href="#cb23-957" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ground truth</span></span>
<span id="cb23-958"><a href="#cb23-958" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> np.random.randint(<span class="dv">0</span>, num_classes, num_samples)</span>
<span id="cb23-959"><a href="#cb23-959" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-960"><a href="#cb23-960" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simulate different model predictions</span></span>
<span id="cb23-961"><a href="#cb23-961" aria-hidden="true" tabindex="-1"></a>    models <span class="op">=</span> {</span>
<span id="cb23-962"><a href="#cb23-962" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Image Only'</span>: np.random.multinomial(<span class="dv">1</span>, [<span class="fl">0.8</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>], num_samples).argmax(axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb23-963"><a href="#cb23-963" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Text Only'</span>: np.random.multinomial(<span class="dv">1</span>, [<span class="fl">0.1</span>, <span class="fl">0.7</span>, <span class="fl">0.1</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>], num_samples).argmax(axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb23-964"><a href="#cb23-964" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Early Fusion'</span>: np.random.multinomial(<span class="dv">1</span>, [<span class="fl">0.85</span>, <span class="fl">0.04</span>, <span class="fl">0.04</span>, <span class="fl">0.04</span>, <span class="fl">0.03</span>], num_samples).argmax(axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb23-965"><a href="#cb23-965" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Late Fusion'</span>: np.random.multinomial(<span class="dv">1</span>, [<span class="fl">0.87</span>, <span class="fl">0.03</span>, <span class="fl">0.03</span>, <span class="fl">0.04</span>, <span class="fl">0.03</span>], num_samples).argmax(axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb23-966"><a href="#cb23-966" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Attention Fusion'</span>: np.random.multinomial(<span class="dv">1</span>, [<span class="fl">0.9</span>, <span class="fl">0.025</span>, <span class="fl">0.025</span>, <span class="fl">0.025</span>, <span class="fl">0.025</span>], num_samples).argmax(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-967"><a href="#cb23-967" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb23-968"><a href="#cb23-968" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-969"><a href="#cb23-969" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make predictions more realistic (align with ground truth)</span></span>
<span id="cb23-970"><a href="#cb23-970" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name <span class="kw">in</span> models:</span>
<span id="cb23-971"><a href="#cb23-971" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add some correlation with ground truth</span></span>
<span id="cb23-972"><a href="#cb23-972" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> np.random.random(num_samples) <span class="op">&lt;</span> <span class="fl">0.7</span>  <span class="co"># 70% correct</span></span>
<span id="cb23-973"><a href="#cb23-973" aria-hidden="true" tabindex="-1"></a>        models[model_name][mask] <span class="op">=</span> y_true[mask]</span>
<span id="cb23-974"><a href="#cb23-974" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-975"><a href="#cb23-975" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> calculate_metrics(y_true, y_pred):</span>
<span id="cb23-976"><a href="#cb23-976" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Calculate comprehensive metrics"""</span></span>
<span id="cb23-977"><a href="#cb23-977" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_recall_fscore_support, confusion_matrix</span>
<span id="cb23-978"><a href="#cb23-978" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-979"><a href="#cb23-979" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> accuracy_score(y_true, y_pred)</span>
<span id="cb23-980"><a href="#cb23-980" aria-hidden="true" tabindex="-1"></a>        precision, recall, f1, _ <span class="op">=</span> precision_recall_fscore_support(y_true, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb23-981"><a href="#cb23-981" aria-hidden="true" tabindex="-1"></a>        conf_matrix <span class="op">=</span> confusion_matrix(y_true, y_pred)</span>
<span id="cb23-982"><a href="#cb23-982" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-983"><a href="#cb23-983" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb23-984"><a href="#cb23-984" aria-hidden="true" tabindex="-1"></a>            <span class="st">'accuracy'</span>: accuracy,</span>
<span id="cb23-985"><a href="#cb23-985" aria-hidden="true" tabindex="-1"></a>            <span class="st">'precision'</span>: precision,</span>
<span id="cb23-986"><a href="#cb23-986" aria-hidden="true" tabindex="-1"></a>            <span class="st">'recall'</span>: recall,</span>
<span id="cb23-987"><a href="#cb23-987" aria-hidden="true" tabindex="-1"></a>            <span class="st">'f1_score'</span>: f1,</span>
<span id="cb23-988"><a href="#cb23-988" aria-hidden="true" tabindex="-1"></a>            <span class="st">'confusion_matrix'</span>: conf_matrix</span>
<span id="cb23-989"><a href="#cb23-989" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb23-990"><a href="#cb23-990" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-991"><a href="#cb23-991" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate metrics for each model</span></span>
<span id="cb23-992"><a href="#cb23-992" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> {}</span>
<span id="cb23-993"><a href="#cb23-993" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name, predictions <span class="kw">in</span> models.items():</span>
<span id="cb23-994"><a href="#cb23-994" aria-hidden="true" tabindex="-1"></a>        results[model_name] <span class="op">=</span> calculate_metrics(y_true, predictions)</span>
<span id="cb23-995"><a href="#cb23-995" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-996"><a href="#cb23-996" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display results</span></span>
<span id="cb23-997"><a href="#cb23-997" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-modal Model Comparison:"</span>)</span>
<span id="cb23-998"><a href="#cb23-998" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb23-999"><a href="#cb23-999" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1000"><a href="#cb23-1000" aria-hidden="true" tabindex="-1"></a>    metric_names <span class="op">=</span> [<span class="st">'accuracy'</span>, <span class="st">'precision'</span>, <span class="st">'recall'</span>, <span class="st">'f1_score'</span>]</span>
<span id="cb23-1001"><a href="#cb23-1001" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1002"><a href="#cb23-1002" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create comparison table</span></span>
<span id="cb23-1003"><a href="#cb23-1003" aria-hidden="true" tabindex="-1"></a>    comparison_data <span class="op">=</span> []</span>
<span id="cb23-1004"><a href="#cb23-1004" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name, metrics <span class="kw">in</span> results.items():</span>
<span id="cb23-1005"><a href="#cb23-1005" aria-hidden="true" tabindex="-1"></a>        row <span class="op">=</span> [model_name] <span class="op">+</span> [<span class="ss">f"</span><span class="sc">{</span>metrics[metric]<span class="sc">:.3f}</span><span class="ss">"</span> <span class="cf">for</span> metric <span class="kw">in</span> metric_names]</span>
<span id="cb23-1006"><a href="#cb23-1006" aria-hidden="true" tabindex="-1"></a>        comparison_data.append(row)</span>
<span id="cb23-1007"><a href="#cb23-1007" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1008"><a href="#cb23-1008" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print table</span></span>
<span id="cb23-1009"><a href="#cb23-1009" aria-hidden="true" tabindex="-1"></a>    headers <span class="op">=</span> [<span class="st">'Model'</span>] <span class="op">+</span> [m.replace(<span class="st">'_'</span>, <span class="st">' '</span>).title() <span class="cf">for</span> m <span class="kw">in</span> metric_names]</span>
<span id="cb23-1010"><a href="#cb23-1010" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1011"><a href="#cb23-1011" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Simple table formatting</span></span>
<span id="cb23-1012"><a href="#cb23-1012" aria-hidden="true" tabindex="-1"></a>    col_widths <span class="op">=</span> [<span class="bu">max</span>(<span class="bu">len</span>(<span class="bu">str</span>(row[i])) <span class="cf">for</span> row <span class="kw">in</span> [headers] <span class="op">+</span> comparison_data) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(headers))]</span>
<span id="cb23-1013"><a href="#cb23-1013" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1014"><a href="#cb23-1014" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> print_row(row):</span>
<span id="cb23-1015"><a href="#cb23-1015" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">" | "</span>.join(<span class="bu">str</span>(item).ljust(width) <span class="cf">for</span> item, width <span class="kw">in</span> <span class="bu">zip</span>(row, col_widths))</span>
<span id="cb23-1016"><a href="#cb23-1016" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1017"><a href="#cb23-1017" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(print_row(headers))</span>
<span id="cb23-1018"><a href="#cb23-1018" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> (<span class="bu">sum</span>(col_widths) <span class="op">+</span> <span class="bu">len</span>(headers) <span class="op">*</span> <span class="dv">3</span> <span class="op">-</span> <span class="dv">1</span>))</span>
<span id="cb23-1019"><a href="#cb23-1019" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> row <span class="kw">in</span> comparison_data:</span>
<span id="cb23-1020"><a href="#cb23-1020" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(print_row(row))</span>
<span id="cb23-1021"><a href="#cb23-1021" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1022"><a href="#cb23-1022" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Visualize performance comparison</span></span>
<span id="cb23-1023"><a href="#cb23-1023" aria-hidden="true" tabindex="-1"></a>    fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb23-1024"><a href="#cb23-1024" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1025"><a href="#cb23-1025" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Performance metrics</span></span>
<span id="cb23-1026"><a href="#cb23-1026" aria-hidden="true" tabindex="-1"></a>    model_names <span class="op">=</span> <span class="bu">list</span>(results.keys())</span>
<span id="cb23-1027"><a href="#cb23-1027" aria-hidden="true" tabindex="-1"></a>    metrics_data <span class="op">=</span> {</span>
<span id="cb23-1028"><a href="#cb23-1028" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Accuracy'</span>: [results[name][<span class="st">'accuracy'</span>] <span class="cf">for</span> name <span class="kw">in</span> model_names],</span>
<span id="cb23-1029"><a href="#cb23-1029" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Precision'</span>: [results[name][<span class="st">'precision'</span>] <span class="cf">for</span> name <span class="kw">in</span> model_names],</span>
<span id="cb23-1030"><a href="#cb23-1030" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Recall'</span>: [results[name][<span class="st">'recall'</span>] <span class="cf">for</span> name <span class="kw">in</span> model_names],</span>
<span id="cb23-1031"><a href="#cb23-1031" aria-hidden="true" tabindex="-1"></a>        <span class="st">'F1-Score'</span>: [results[name][<span class="st">'f1_score'</span>] <span class="cf">for</span> name <span class="kw">in</span> model_names]</span>
<span id="cb23-1032"><a href="#cb23-1032" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb23-1033"><a href="#cb23-1033" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1034"><a href="#cb23-1034" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.arange(<span class="bu">len</span>(model_names))</span>
<span id="cb23-1035"><a href="#cb23-1035" aria-hidden="true" tabindex="-1"></a>    width <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb23-1036"><a href="#cb23-1036" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1037"><a href="#cb23-1037" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (metric_name, values) <span class="kw">in</span> <span class="bu">enumerate</span>(metrics_data.items()):</span>
<span id="cb23-1038"><a href="#cb23-1038" aria-hidden="true" tabindex="-1"></a>        ax1.bar(x <span class="op">+</span> i<span class="op">*</span>width, values, width, label<span class="op">=</span>metric_name, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb23-1039"><a href="#cb23-1039" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1040"><a href="#cb23-1040" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(<span class="st">'Models'</span>)</span>
<span id="cb23-1041"><a href="#cb23-1041" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">'Score'</span>)</span>
<span id="cb23-1042"><a href="#cb23-1042" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(<span class="st">'Multi-modal Model Performance Comparison'</span>)</span>
<span id="cb23-1043"><a href="#cb23-1043" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticks(x <span class="op">+</span> width <span class="op">*</span> <span class="fl">1.5</span>)</span>
<span id="cb23-1044"><a href="#cb23-1044" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticklabels(model_names, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb23-1045"><a href="#cb23-1045" aria-hidden="true" tabindex="-1"></a>    ax1.legend()</span>
<span id="cb23-1046"><a href="#cb23-1046" aria-hidden="true" tabindex="-1"></a>    ax1.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb23-1047"><a href="#cb23-1047" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb23-1048"><a href="#cb23-1048" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1049"><a href="#cb23-1049" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Confusion matrix for best model</span></span>
<span id="cb23-1050"><a href="#cb23-1050" aria-hidden="true" tabindex="-1"></a>    best_model <span class="op">=</span> <span class="bu">max</span>(results.keys(), key<span class="op">=</span><span class="kw">lambda</span> x: results[x][<span class="st">'f1_score'</span>])</span>
<span id="cb23-1051"><a href="#cb23-1051" aria-hidden="true" tabindex="-1"></a>    best_conf_matrix <span class="op">=</span> results[best_model][<span class="st">'confusion_matrix'</span>]</span>
<span id="cb23-1052"><a href="#cb23-1052" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1053"><a href="#cb23-1053" aria-hidden="true" tabindex="-1"></a>    im <span class="op">=</span> ax2.imshow(best_conf_matrix, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb23-1054"><a href="#cb23-1054" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="ss">f'Confusion Matrix - </span><span class="sc">{</span>best_model<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb23-1055"><a href="#cb23-1055" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(<span class="st">'Predicted Class'</span>)</span>
<span id="cb23-1056"><a href="#cb23-1056" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">'True Class'</span>)</span>
<span id="cb23-1057"><a href="#cb23-1057" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1058"><a href="#cb23-1058" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add text annotations</span></span>
<span id="cb23-1059"><a href="#cb23-1059" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_classes):</span>
<span id="cb23-1060"><a href="#cb23-1060" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(num_classes):</span>
<span id="cb23-1061"><a href="#cb23-1061" aria-hidden="true" tabindex="-1"></a>            ax2.text(j, i, <span class="bu">str</span>(best_conf_matrix[i, j]), </span>
<span id="cb23-1062"><a href="#cb23-1062" aria-hidden="true" tabindex="-1"></a>                    ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, color<span class="op">=</span><span class="st">'black'</span> <span class="cf">if</span> best_conf_matrix[i, j] <span class="op">&lt;</span> best_conf_matrix.<span class="bu">max</span>()<span class="op">/</span><span class="dv">2</span> <span class="cf">else</span> <span class="st">'white'</span>)</span>
<span id="cb23-1063"><a href="#cb23-1063" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1064"><a href="#cb23-1064" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(im, ax<span class="op">=</span>ax2)</span>
<span id="cb23-1065"><a href="#cb23-1065" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb23-1066"><a href="#cb23-1066" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-1067"><a href="#cb23-1067" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1068"><a href="#cb23-1068" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Cross-modal retrieval metrics</span></span>
<span id="cb23-1069"><a href="#cb23-1069" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Best performing model: </span><span class="sc">{</span>best_model<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-1070"><a href="#cb23-1070" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Best F1-score: </span><span class="sc">{</span>results[best_model][<span class="st">'f1_score'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb23-1071"><a href="#cb23-1071" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1072"><a href="#cb23-1072" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> results</span>
<span id="cb23-1073"><a href="#cb23-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1074"><a href="#cb23-1074" aria-hidden="true" tabindex="-1"></a>evaluation_results <span class="op">=</span> demonstrate_multimodal_evaluation()</span>
<span id="cb23-1075"><a href="#cb23-1075" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-1076"><a href="#cb23-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1077"><a href="#cb23-1077" aria-hidden="true" tabindex="-1"></a><span class="fu">## Real-world Applications</span></span>
<span id="cb23-1078"><a href="#cb23-1078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1079"><a href="#cb23-1079" aria-hidden="true" tabindex="-1"></a><span class="fu">### Applications in Geospatial AI</span></span>
<span id="cb23-1082"><a href="#cb23-1082" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb23-1083"><a href="#cb23-1083" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_multimodal_applications():</span>
<span id="cb23-1084"><a href="#cb23-1084" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show real-world applications of multi-modal geospatial AI"""</span></span>
<span id="cb23-1085"><a href="#cb23-1085" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1086"><a href="#cb23-1086" aria-hidden="true" tabindex="-1"></a>    applications <span class="op">=</span> {</span>
<span id="cb23-1087"><a href="#cb23-1087" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Disaster Response"</span>: {</span>
<span id="cb23-1088"><a href="#cb23-1088" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modalities"</span>: [<span class="st">"Satellite imagery"</span>, <span class="st">"Social media text"</span>, <span class="st">"Weather data"</span>],</span>
<span id="cb23-1089"><a href="#cb23-1089" aria-hidden="true" tabindex="-1"></a>            <span class="st">"objective"</span>: <span class="st">"Rapid damage assessment and resource allocation"</span>,</span>
<span id="cb23-1090"><a href="#cb23-1090" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_workflow"</span>: [</span>
<span id="cb23-1091"><a href="#cb23-1091" aria-hidden="true" tabindex="-1"></a>                <span class="st">"1. Analyze pre/post-disaster satellite images"</span>,</span>
<span id="cb23-1092"><a href="#cb23-1092" aria-hidden="true" tabindex="-1"></a>                <span class="st">"2. Extract text from social media reports"</span>, </span>
<span id="cb23-1093"><a href="#cb23-1093" aria-hidden="true" tabindex="-1"></a>                <span class="st">"3. Combine with weather/climate data"</span>,</span>
<span id="cb23-1094"><a href="#cb23-1094" aria-hidden="true" tabindex="-1"></a>                <span class="st">"4. Generate damage maps and priority areas"</span></span>
<span id="cb23-1095"><a href="#cb23-1095" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb23-1096"><a href="#cb23-1096" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Real-time processing"</span>, <span class="st">"Data reliability"</span>, <span class="st">"Multi-scale fusion"</span>]</span>
<span id="cb23-1097"><a href="#cb23-1097" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb23-1098"><a href="#cb23-1098" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-1099"><a href="#cb23-1099" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Urban Planning"</span>: {</span>
<span id="cb23-1100"><a href="#cb23-1100" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modalities"</span>: [<span class="st">"High-res imagery"</span>, <span class="st">"Demographic data"</span>, <span class="st">"Traffic patterns"</span>],</span>
<span id="cb23-1101"><a href="#cb23-1101" aria-hidden="true" tabindex="-1"></a>            <span class="st">"objective"</span>: <span class="st">"Optimize city development and infrastructure"</span>,</span>
<span id="cb23-1102"><a href="#cb23-1102" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_workflow"</span>: [</span>
<span id="cb23-1103"><a href="#cb23-1103" aria-hidden="true" tabindex="-1"></a>                <span class="st">"1. Analyze urban land use from imagery"</span>,</span>
<span id="cb23-1104"><a href="#cb23-1104" aria-hidden="true" tabindex="-1"></a>                <span class="st">"2. Integrate population and economic data"</span>,</span>
<span id="cb23-1105"><a href="#cb23-1105" aria-hidden="true" tabindex="-1"></a>                <span class="st">"3. Model traffic and mobility patterns"</span>, </span>
<span id="cb23-1106"><a href="#cb23-1106" aria-hidden="true" tabindex="-1"></a>                <span class="st">"4. Generate development recommendations"</span></span>
<span id="cb23-1107"><a href="#cb23-1107" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb23-1108"><a href="#cb23-1108" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Privacy concerns"</span>, <span class="st">"Data integration"</span>, <span class="st">"Temporal alignment"</span>]</span>
<span id="cb23-1109"><a href="#cb23-1109" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb23-1110"><a href="#cb23-1110" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-1111"><a href="#cb23-1111" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Agricultural Monitoring"</span>: {</span>
<span id="cb23-1112"><a href="#cb23-1112" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modalities"</span>: [<span class="st">"Multispectral imagery"</span>, <span class="st">"Weather data"</span>, <span class="st">"Soil information"</span>],</span>
<span id="cb23-1113"><a href="#cb23-1113" aria-hidden="true" tabindex="-1"></a>            <span class="st">"objective"</span>: <span class="st">"Crop yield prediction and management optimization"</span>,</span>
<span id="cb23-1114"><a href="#cb23-1114" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_workflow"</span>: [</span>
<span id="cb23-1115"><a href="#cb23-1115" aria-hidden="true" tabindex="-1"></a>                <span class="st">"1. Monitor crop health via spectral indices"</span>,</span>
<span id="cb23-1116"><a href="#cb23-1116" aria-hidden="true" tabindex="-1"></a>                <span class="st">"2. Integrate weather and climate data"</span>,</span>
<span id="cb23-1117"><a href="#cb23-1117" aria-hidden="true" tabindex="-1"></a>                <span class="st">"3. Analyze soil properties and conditions"</span>,</span>
<span id="cb23-1118"><a href="#cb23-1118" aria-hidden="true" tabindex="-1"></a>                <span class="st">"4. Predict yields and optimize practices"</span></span>
<span id="cb23-1119"><a href="#cb23-1119" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb23-1120"><a href="#cb23-1120" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Seasonal variations"</span>, <span class="st">"Regional differences"</span>, <span class="st">"Ground truth validation"</span>]</span>
<span id="cb23-1121"><a href="#cb23-1121" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb23-1122"><a href="#cb23-1122" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-1123"><a href="#cb23-1123" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Environmental Conservation"</span>: {</span>
<span id="cb23-1124"><a href="#cb23-1124" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modalities"</span>: [<span class="st">"Satellite imagery"</span>, <span class="st">"Species data"</span>, <span class="st">"Climate records"</span>],</span>
<span id="cb23-1125"><a href="#cb23-1125" aria-hidden="true" tabindex="-1"></a>            <span class="st">"objective"</span>: <span class="st">"Biodiversity monitoring and habitat protection"</span>,</span>
<span id="cb23-1126"><a href="#cb23-1126" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_workflow"</span>: [</span>
<span id="cb23-1127"><a href="#cb23-1127" aria-hidden="true" tabindex="-1"></a>                <span class="st">"1. Map habitat types from imagery"</span>,</span>
<span id="cb23-1128"><a href="#cb23-1128" aria-hidden="true" tabindex="-1"></a>                <span class="st">"2. Track species distributions and migrations"</span>,</span>
<span id="cb23-1129"><a href="#cb23-1129" aria-hidden="true" tabindex="-1"></a>                <span class="st">"3. Monitor climate and environmental changes"</span>,</span>
<span id="cb23-1130"><a href="#cb23-1130" aria-hidden="true" tabindex="-1"></a>                <span class="st">"4. Identify conservation priorities"</span></span>
<span id="cb23-1131"><a href="#cb23-1131" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb23-1132"><a href="#cb23-1132" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Species detection"</span>, <span class="st">"Long-term monitoring"</span>, <span class="st">"Scale integration"</span>]</span>
<span id="cb23-1133"><a href="#cb23-1133" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb23-1134"><a href="#cb23-1134" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-1135"><a href="#cb23-1135" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Climate Change Assessment"</span>: {</span>
<span id="cb23-1136"><a href="#cb23-1136" aria-hidden="true" tabindex="-1"></a>            <span class="st">"modalities"</span>: [<span class="st">"Time-series imagery"</span>, <span class="st">"Temperature records"</span>, <span class="st">"Precipitation data"</span>],</span>
<span id="cb23-1137"><a href="#cb23-1137" aria-hidden="true" tabindex="-1"></a>            <span class="st">"objective"</span>: <span class="st">"Track and predict climate impacts"</span>,</span>
<span id="cb23-1138"><a href="#cb23-1138" aria-hidden="true" tabindex="-1"></a>            <span class="st">"example_workflow"</span>: [</span>
<span id="cb23-1139"><a href="#cb23-1139" aria-hidden="true" tabindex="-1"></a>                <span class="st">"1. Analyze land cover changes over time"</span>,</span>
<span id="cb23-1140"><a href="#cb23-1140" aria-hidden="true" tabindex="-1"></a>                <span class="st">"2. Correlate with temperature trends"</span>,</span>
<span id="cb23-1141"><a href="#cb23-1141" aria-hidden="true" tabindex="-1"></a>                <span class="st">"3. Integrate precipitation patterns"</span>,</span>
<span id="cb23-1142"><a href="#cb23-1142" aria-hidden="true" tabindex="-1"></a>                <span class="st">"4. Model future scenarios"</span></span>
<span id="cb23-1143"><a href="#cb23-1143" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb23-1144"><a href="#cb23-1144" aria-hidden="true" tabindex="-1"></a>            <span class="st">"challenges"</span>: [<span class="st">"Long-term data consistency"</span>, <span class="st">"Attribution"</span>, <span class="st">"Uncertainty quantification"</span>]</span>
<span id="cb23-1145"><a href="#cb23-1145" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb23-1146"><a href="#cb23-1146" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb23-1147"><a href="#cb23-1147" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1148"><a href="#cb23-1148" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Multi-modal Applications in Geospatial AI:"</span>)</span>
<span id="cb23-1149"><a href="#cb23-1149" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb23-1150"><a href="#cb23-1150" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1151"><a href="#cb23-1151" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> app_name, details <span class="kw">in</span> applications.items():</span>
<span id="cb23-1152"><a href="#cb23-1152" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>app_name<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb23-1153"><a href="#cb23-1153" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Modalities: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(details[<span class="st">'modalities'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-1154"><a href="#cb23-1154" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Objective: </span><span class="sc">{</span>details[<span class="st">'objective'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-1155"><a href="#cb23-1155" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Workflow:"</span>)</span>
<span id="cb23-1156"><a href="#cb23-1156" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> step <span class="kw">in</span> details[<span class="st">'example_workflow'</span>]:</span>
<span id="cb23-1157"><a href="#cb23-1157" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"    </span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-1158"><a href="#cb23-1158" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Key Challenges: </span><span class="sc">{</span><span class="st">', '</span><span class="sc">.</span>join(details[<span class="st">'challenges'</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-1159"><a href="#cb23-1159" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1160"><a href="#cb23-1160" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create application complexity visualization</span></span>
<span id="cb23-1161"><a href="#cb23-1161" aria-hidden="true" tabindex="-1"></a>    app_names <span class="op">=</span> <span class="bu">list</span>(applications.keys())</span>
<span id="cb23-1162"><a href="#cb23-1162" aria-hidden="true" tabindex="-1"></a>    modality_counts <span class="op">=</span> [<span class="bu">len</span>(app[<span class="st">'modalities'</span>]) <span class="cf">for</span> app <span class="kw">in</span> applications.values()]</span>
<span id="cb23-1163"><a href="#cb23-1163" aria-hidden="true" tabindex="-1"></a>    challenge_counts <span class="op">=</span> [<span class="bu">len</span>(app[<span class="st">'challenges'</span>]) <span class="cf">for</span> app <span class="kw">in</span> applications.values()]</span>
<span id="cb23-1164"><a href="#cb23-1164" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1165"><a href="#cb23-1165" aria-hidden="true" tabindex="-1"></a>    fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb23-1166"><a href="#cb23-1166" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1167"><a href="#cb23-1167" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Modalities per application</span></span>
<span id="cb23-1168"><a href="#cb23-1168" aria-hidden="true" tabindex="-1"></a>    bars1 <span class="op">=</span> ax1.bar(<span class="bu">range</span>(<span class="bu">len</span>(app_names)), modality_counts, color<span class="op">=</span><span class="st">'skyblue'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb23-1169"><a href="#cb23-1169" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(<span class="st">'Applications'</span>)</span>
<span id="cb23-1170"><a href="#cb23-1170" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">'Number of Modalities'</span>)</span>
<span id="cb23-1171"><a href="#cb23-1171" aria-hidden="true" tabindex="-1"></a>    ax1.set_title(<span class="st">'Data Modalities per Application'</span>)</span>
<span id="cb23-1172"><a href="#cb23-1172" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticks(<span class="bu">range</span>(<span class="bu">len</span>(app_names)))</span>
<span id="cb23-1173"><a href="#cb23-1173" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticklabels(app_names, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb23-1174"><a href="#cb23-1174" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1175"><a href="#cb23-1175" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add value labels on bars</span></span>
<span id="cb23-1176"><a href="#cb23-1176" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bar, count <span class="kw">in</span> <span class="bu">zip</span>(bars1, modality_counts):</span>
<span id="cb23-1177"><a href="#cb23-1177" aria-hidden="true" tabindex="-1"></a>        height <span class="op">=</span> bar.get_height()</span>
<span id="cb23-1178"><a href="#cb23-1178" aria-hidden="true" tabindex="-1"></a>        ax1.text(bar.get_x() <span class="op">+</span> bar.get_width()<span class="op">/</span><span class="fl">2.</span>, height <span class="op">+</span> <span class="fl">0.05</span>,</span>
<span id="cb23-1179"><a href="#cb23-1179" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'</span><span class="sc">{</span>count<span class="sc">}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb23-1180"><a href="#cb23-1180" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1181"><a href="#cb23-1181" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Challenges per application  </span></span>
<span id="cb23-1182"><a href="#cb23-1182" aria-hidden="true" tabindex="-1"></a>    bars2 <span class="op">=</span> ax2.bar(<span class="bu">range</span>(<span class="bu">len</span>(app_names)), challenge_counts, color<span class="op">=</span><span class="st">'lightcoral'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb23-1183"><a href="#cb23-1183" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(<span class="st">'Applications'</span>)</span>
<span id="cb23-1184"><a href="#cb23-1184" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">'Number of Key Challenges'</span>)</span>
<span id="cb23-1185"><a href="#cb23-1185" aria-hidden="true" tabindex="-1"></a>    ax2.set_title(<span class="st">'Implementation Challenges per Application'</span>)</span>
<span id="cb23-1186"><a href="#cb23-1186" aria-hidden="true" tabindex="-1"></a>    ax2.set_xticks(<span class="bu">range</span>(<span class="bu">len</span>(app_names)))</span>
<span id="cb23-1187"><a href="#cb23-1187" aria-hidden="true" tabindex="-1"></a>    ax2.set_xticklabels(app_names, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb23-1188"><a href="#cb23-1188" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1189"><a href="#cb23-1189" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add value labels on bars</span></span>
<span id="cb23-1190"><a href="#cb23-1190" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bar, count <span class="kw">in</span> <span class="bu">zip</span>(bars2, challenge_counts):</span>
<span id="cb23-1191"><a href="#cb23-1191" aria-hidden="true" tabindex="-1"></a>        height <span class="op">=</span> bar.get_height()</span>
<span id="cb23-1192"><a href="#cb23-1192" aria-hidden="true" tabindex="-1"></a>        ax2.text(bar.get_x() <span class="op">+</span> bar.get_width()<span class="op">/</span><span class="fl">2.</span>, height <span class="op">+</span> <span class="fl">0.05</span>,</span>
<span id="cb23-1193"><a href="#cb23-1193" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'</span><span class="sc">{</span>count<span class="sc">}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb23-1194"><a href="#cb23-1194" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1195"><a href="#cb23-1195" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb23-1196"><a href="#cb23-1196" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb23-1197"><a href="#cb23-1197" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-1198"><a href="#cb23-1198" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> applications</span>
<span id="cb23-1199"><a href="#cb23-1199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1200"><a href="#cb23-1200" aria-hidden="true" tabindex="-1"></a>multimodal_apps <span class="op">=</span> demonstrate_multimodal_applications()</span>
<span id="cb23-1201"><a href="#cb23-1201" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-1202"><a href="#cb23-1202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1203"><a href="#cb23-1203" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb23-1204"><a href="#cb23-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-1205"><a href="#cb23-1205" aria-hidden="true" tabindex="-1"></a>Key concepts for multi-modal learning in geospatial AI:</span>
<span id="cb23-1206"><a href="#cb23-1206" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Data Integration**: Combining imagery, text, time series, and tabular data</span>
<span id="cb23-1207"><a href="#cb23-1207" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Fusion Strategies**: Early fusion, late fusion, and attention-based approaches  </span>
<span id="cb23-1208"><a href="#cb23-1208" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Architecture Patterns**: Cross-modal attention, contrastive learning, joint embeddings</span>
<span id="cb23-1209"><a href="#cb23-1209" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Contrastive Learning**: CLIP-style training for image-text understanding</span>
<span id="cb23-1210"><a href="#cb23-1210" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Data Augmentation**: Cross-modal augmentation techniques</span>
<span id="cb23-1211"><a href="#cb23-1211" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Evaluation Metrics**: Multi-modal performance assessment</span>
<span id="cb23-1212"><a href="#cb23-1212" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Applications**: Disaster response, urban planning, agriculture, conservation</span>
<span id="cb23-1213"><a href="#cb23-1213" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Challenges**: Data alignment, scale differences, computational complexity</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/geog-logo.png" class="img-fluid figure-img" width="250"></p>
<figcaption>Department of Geography logo</figcaption>
</figure>
</div>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This website is built with <a href="https://github.com/kcaylor/GEOG-288KC-geospatial-foundation-models"><i class="fa-brands fa-github" title="the github octocat logo" aria-label="github"></i></a> and <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>