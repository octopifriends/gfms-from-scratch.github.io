---
title: "Week 2: Geospatial Data Preprocessing"
subtitle: "Building efficient pipelines for Sentinel-2 preprocessing"
jupyter: geoai
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: false
---

## Introduction

This week we'll build production-ready preprocessing pipelines that can handle multiple Sentinel-2 scenes efficiently. You'll learn to process entire datasets, not just single scenes, with cloud masking, reprojection, and mosaicking.

## Prerequisites

Before starting this session, ensure you have:

- Completed Week 1: Geospatial Data Foundations
- Activated the `geoAI` conda environment
- Access to UCSB AI Sandbox or local environment with 8GB+ RAM
- Basic familiarity with xarray and rasterio from Week 1

:::{.callout-note}
## Optional NetCDF4 Installation
For optimal performance saving data cubes, install netCDF4:
```bash
conda install netcdf4
# or
mamba install netcdf4
```
If netCDF4 is unavailable, the code will automatically fallback to scipy or zarr formats.
:::

:::{.callout-warning}
## Computational Requirements
Processing multiple Sentinel-2 scenes requires significant memory and storage. Each scene can be 100MB+ when loaded. Use the provided chunking parameters or reduce the number of scenes if running locally with limited resources.
:::

:::{.callout-tip}
## Learning Goals
By the end of this session, you will:

- Build reproducible preprocessing pipelines for multiple scenes
- Handle cloud masking using Sentinel-2's Scene Classification Layer
- Reproject and mosaic multiple satellite scenes
- Create analysis-ready data cubes with xarray
- Optimize workflows with dask for large datasets
:::

## Session Overview

Today's hands-on workflow:

| Step | Activity | Tools | Output |
|------|----------|-------|--------|
| 1 | Multi-scene data discovery | pystac-client | Scene inventory |
| 2 | Cloud masking pipeline | rasterio, numpy | Clean pixels only |
| 3 | Reprojection & mosaicking | rasterio, rioxarray | Unified grid |
| 4 | Analysis-ready data cubes | xarray, dask | Time series ready data |
| 5 | Batch processing workflow | pathlib, concurrent.futures | Scalable pipeline |

---

## Step 1: Multi-Scene Data Discovery

Let's scale up from Week 1's single scene approach to handle multiple scenes across time and space.

### Define Study Area and Time Range

```{python}
# Import functions from our geogfm module
from geogfm.c01 import (
    verify_environment,
    setup_planetary_computer_auth,
    search_sentinel2_scenes,
    load_sentinel2_bands
)

# Core libraries
import warnings
import numpy as np
import pandas as pd
import xarray as xr
import rasterio
from rasterio.warp import calculate_default_transform, reproject, Resampling
from rasterio.merge import merge
import rioxarray
from pathlib import Path
from datetime import datetime, timedelta
from pystac_client import Client
import folium
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor
from functools import partial
import dask
from dask.distributed import Client as DaskClient
from typing import Dict, List, Tuple, Optional, Union

warnings.filterwarnings('ignore')

# Verify environment using our standardized function
required_packages = [
    'numpy', 'pandas', 'xarray', 'rasterio', 'rioxarray',
    'pystac_client', 'folium', 'matplotlib', 'dask'
]
env_status = verify_environment(required_packages)

# Set up study area - Central Valley, California (agriculture focus)
central_valley_bbox = [-121.5, 36.5, -120.0, 38.0]  # [west, south, east, north]

# Define longer time range for trend analysis
start_date = "2024-06-01"
end_date = "2024-09-01"
max_cloud_cover = 15  # More restrictive for cleaner mosaics

print(f"üó∫Ô∏è Study Area: Central Valley, California")
print(f"üìÖ Time Range: {start_date} to {end_date}")
print(f"‚òÅÔ∏è Max Cloud Cover: {max_cloud_cover}%")
```

### Search for Multiple Scenes

```{python}
# Set up authentication using our standardized function
auth_status = setup_planetary_computer_auth()

# Search for scenes using our enhanced search function
print("üîç Searching for multiple Sentinel-2 scenes...")
items = search_sentinel2_scenes(
    bbox=central_valley_bbox,
    date_range=f"{start_date}/{end_date}",
    cloud_cover_max=max_cloud_cover,
    limit=50
)

print(f"üì∏ Found {len(items)} scenes")

# Organize scenes by date and tile
scene_info = []
for item in items:
    props = item.properties
    date = props['datetime'].split('T')[0]
    tile_id = item.id.split('_')[5]  # Extract tile ID from scene name
    cloud_cover = props.get('eo:cloud_cover', 0)

    scene_info.append({
        'id': item.id,
        'date': date,
        'tile': tile_id,
        'cloud_cover': cloud_cover,
        'item': item
    })

# Convert to DataFrame for easier analysis
scenes_df = pd.DataFrame(scene_info)
print(f"\nüìä Scene Distribution:")
print(f"   Unique dates: {scenes_df['date'].nunique()}")
print(f"   Unique tiles: {scenes_df['tile'].nunique()}")
print(f"   Date range: {scenes_df['date'].min()} to {scenes_df['date'].max()}")

# Show scenes by tile
print(f"\nüóÇÔ∏è Scenes by Tile:")
tile_counts = scenes_df.groupby('tile').size().sort_values(ascending=False)
for tile, count in tile_counts.head().items():
    avg_cloud = scenes_df[scenes_df['tile'] == tile]['cloud_cover'].mean()
    print(f"   {tile}: {count} scenes (avg cloud: {avg_cloud:.1f}%)")
```

### Visualize Scene Coverage

```{python}
# Create map showing all scene footprints
m = folium.Map(
    location=[37.25, -120.75],  # Center of Central Valley
    zoom_start=8,
    tiles='OpenStreetMap'
)

# Add study area boundary
folium.Rectangle(
    bounds=[[central_valley_bbox[1], central_valley_bbox[0]],
            [central_valley_bbox[3], central_valley_bbox[2]]],
    color='red',
    fill=False,
    weight=3,
    popup="Study Area: Central Valley"
).add_to(m)

# Add scene footprints colored by date
colors = ['blue', 'green', 'orange', 'purple', 'red']
unique_dates = sorted(scenes_df['date'].unique())

for i, date in enumerate(unique_dates[:5]):  # Show first 5 dates
    date_scenes = scenes_df[scenes_df['date'] == date]
    color = colors[i % len(colors)]

    for _, scene in date_scenes.iterrows():
        item = scene['item']
        geom = item.geometry

        # Add scene footprint
        folium.GeoJson(
            geom,
            style_function=lambda x, color=color: {
                'fillColor': color,
                'color': color,
                'weight': 2,
                'fillOpacity': 0.3
            },
            popup=f"Date: {date}<br>Tile: {scene['tile']}<br>Cloud: {scene['cloud_cover']:.1f}%"
        ).add_to(m)

folium.LayerControl().add_to(m)
print("üó∫Ô∏è Scene coverage map created")
m
```

---

## Step 2: Cloud Masking Pipeline

Sentinel-2 Level 2A includes a Scene Classification Layer (SCL) that identifies clouds, cloud shadows, and other features.

### Understanding Scene Classification Layer

```{python}
# SCL class definitions (Sentinel-2 Level 2A)
scl_classes = {
    0: "No Data",
    1: "Saturated or defective",
    2: "Dark area pixels",
    3: "Cloud shadows",
    4: "Vegetation",
    5: "Not vegetated",
    6: "Water",
    7: "Unclassified",
    8: "Cloud medium probability",
    9: "Cloud high probability",
    10: "Thin cirrus",
    11: "Snow"
}

# Define what we consider "good" pixels for analysis
good_pixel_classes = [4, 5, 6]  # Vegetation, not vegetated, water
cloud_classes = [3, 8, 9, 10]   # Cloud shadows, clouds, cirrus

print("üå•Ô∏è Scene Classification Layer (SCL) Classes:")
for class_id, description in scl_classes.items():
    marker = "‚úì" if class_id in good_pixel_classes else "‚ùå" if class_id in cloud_classes else "‚ö†Ô∏è"
    print(f"   {marker} {class_id}: {description}")

print(f"\n‚úÖ Good pixels for analysis: {good_pixel_classes}")
print(f"‚òÅÔ∏è Cloud/shadow pixels to mask: {cloud_classes}")
```

## Week 2 Function Library

Before we begin the hands-on workflow, let's define all the core functions we'll use throughout this chapter. These functions build on the Week 1 foundations and will be exported to our `geogfm.c02` module:

```{python}
#| filename: geogfm/c02.py
# Tangled from c02-spatial-temporal-attention-mechanisms.qmd

"""Week 2: Advanced preprocessing functions for Sentinel-2 data."""

import numpy as np
import pandas as pd
import xarray as xr
from typing import Dict, List, Tuple, Optional, Union
from pathlib import Path
from functools import partial
from concurrent.futures import ThreadPoolExecutor
from geogfm.c01 import load_sentinel2_bands, setup_planetary_computer_auth, search_sentinel2_scenes

def create_cloud_mask(scl_data, good_classes: List[int]) -> np.ndarray:
    """
    Create binary cloud mask from Scene Classification Layer.

    Educational note: np.isin checks if each pixel value is in our 'good' list.
    Returns True for clear pixels, False for clouds/shadows.

    Args:
        scl_data: Scene Classification Layer data (numpy array or xarray DataArray)
        good_classes: List of SCL values considered valid pixels

    Returns:
        Binary mask array (True for valid pixels)
    """
    # Handle both numpy arrays and xarray DataArrays
    if hasattr(scl_data, 'values'):
        scl_values = scl_data.values
    else:
        scl_values = scl_data

    return np.isin(scl_values, good_classes)

def apply_cloud_mask(band_data: Dict[str, Union[np.ndarray, xr.DataArray]],
                    scl_data: Union[np.ndarray, xr.DataArray],
                    good_pixel_classes: List[int],
                    target_resolution: int = 20) -> Tuple[Dict[str, xr.DataArray], float]:
    """
    Apply SCL-based cloud masking to spectral bands.

    Args:
        band_data: Dictionary of band DataArrays
        scl_data: Scene Classification Layer DataArray
        good_pixel_classes: List of SCL values considered valid
        target_resolution: Target resolution for resampling bands

    Returns:
        masked_data: Dictionary with masked bands
        valid_pixel_fraction: Fraction of valid pixels
    """
    import rioxarray

    # Get SCL data and ensure it's at target resolution
    scl_array = scl_data
    if hasattr(scl_data, 'values'):
        scl_values = scl_data.values
    else:
        scl_values = scl_data

    # Create cloud mask from SCL
    good_pixels = create_cloud_mask(scl_data, good_pixel_classes)

    # Get target shape from SCL (typically 20m resolution)
    target_shape = scl_values.shape

    # Apply mask to spectral bands
    masked_data = {}
    # Map Sentinel-2 bands to readable names
    band_mapping = {'B04': 'red', 'B03': 'green', 'B02': 'blue', 'B08': 'nir'}

    for band_name in ['B04', 'B03', 'B02', 'B08']:
        if band_name in band_data:
            band_array = band_data[band_name]

            # Get band values (handle both numpy arrays and xarray DataArrays)
            if hasattr(band_array, 'values'):
                band_values = band_array.values
            else:
                band_values = band_array

            # Resample band to match SCL resolution if needed
            if band_values.shape != target_shape:
                print(f"Resampling {band_name} from {band_values.shape} to {target_shape}")

                # Try rioxarray resampling if CRS is available
                resampled_successfully = False
                if hasattr(band_array, 'rio'):
                    try:
                        # Check if CRS is available
                        if band_array.rio.crs is not None:
                            resampled = band_array.rio.reproject(
                                band_array.rio.crs,
                                resolution=target_resolution
                            )
                            band_values = resampled.values
                            resampled_successfully = True
                        else:
                            print(f"No CRS found for {band_name}, using fallback resampling")
                    except Exception as e:
                        print(f"rioxarray resampling failed for {band_name}: {e}")

                # Fallback: simple decimation for 2x downsampling (10m -> 20m)
                if not resampled_successfully:
                    if band_values.shape[0] == target_shape[0] * 2 and band_values.shape[1] == target_shape[1] * 2:
                        # Perfect 2x downsampling case (e.g., 10m -> 20m)
                        band_values = band_values[::2, ::2]
                        print(f"Used 2x decimation for {band_name}")
                    else:
                        print(f"Warning: Cannot resample {band_name} - incompatible shapes")
                        continue

            # Ensure shapes match after resampling
            if band_values.shape != target_shape:
                print(f"Warning: Shape mismatch for {band_name}: {band_values.shape} vs {target_shape}")
                continue

            # Mask invalid pixels with NaN
            masked_values = np.where(good_pixels, band_values, np.nan)

            # Use meaningful band names (red, green, blue, nir)
            readable_name = band_mapping[band_name]

            # Create DataArray with coordinates if available
            if hasattr(scl_array, 'coords') and hasattr(scl_array, 'dims'):
                masked_data[readable_name] = xr.DataArray(
                    masked_values,
                    coords=scl_array.coords,
                    dims=scl_array.dims
                )
            else:
                # Create with named dimensions for better compatibility
                dims = ['y', 'x'] if len(masked_values.shape) == 2 else ['dim_0', 'dim_1']
                masked_data[readable_name] = xr.DataArray(
                    masked_values,
                    dims=dims
                )

    # Calculate valid pixel fraction
    valid_pixel_fraction = np.sum(good_pixels) / good_pixels.size

    # Store SCL and mask for reference
    if hasattr(scl_data, 'coords') and hasattr(scl_data, 'dims'):
        masked_data['scl'] = scl_data
        masked_data['cloud_mask'] = xr.DataArray(
            good_pixels,
            coords=scl_data.coords,
            dims=scl_data.dims
        )
    else:
        # Create with named dimensions for consistency
        dims = ['y', 'x'] if len(good_pixels.shape) == 2 else ['dim_0', 'dim_1']
        masked_data['scl'] = xr.DataArray(scl_data, dims=dims)
        masked_data['cloud_mask'] = xr.DataArray(good_pixels, dims=dims)

    return masked_data, valid_pixel_fraction

def load_scene_with_cloudmask(item, target_crs: str = 'EPSG:32610',
                              target_resolution: int = 20,
                              good_pixel_classes: List[int] = [4, 5, 6],
                              subset_bbox: Optional[List[float]] = None) -> Tuple[Optional[Dict[str, xr.DataArray]], float]:
    """
    Load a Sentinel-2 scene with cloud masking applied using geogfm functions.

    Args:
        item: STAC item
        target_crs: Target coordinate reference system
        target_resolution: Target pixel size in meters
        good_pixel_classes: List of SCL values considered valid
        subset_bbox: Optional spatial subset as [west, south, east, north] in WGS84

    Returns:
        masked_data: dict with masked bands
        valid_pixel_fraction: fraction of valid pixels
    """
    try:
        # Use the tested function from geogfm.c01
        band_data = load_sentinel2_bands(
            item,
            bands=['B04', 'B03', 'B02', 'B08', 'SCL'],
            subset_bbox=subset_bbox,  # Enable spatial subsetting
            max_retries=3
        )

        if not band_data or 'SCL' not in band_data:
            print(f"‚ö†Ô∏è No data or missing SCL for scene {item.id}")
            return None, 0

        # Apply cloud masking using SCL with target resolution
        masked_data, valid_fraction = apply_cloud_mask(
            band_data, band_data['SCL'], good_pixel_classes, target_resolution
        )

        return masked_data, valid_fraction

    except Exception as e:
        print(f"‚ùå Error loading scene {item.id}: {str(e)}")
        return None, 0

def process_single_scene(item, target_crs: str = 'EPSG:32610',
                        target_resolution: int = 20,
                        min_valid_fraction: float = 0.1,  # Lowered threshold for demonstration
                        good_pixel_classes: List[int] = [4, 5, 6],
                        subset_bbox: Optional[List[float]] = None) -> Optional[Dict]:
    """
    Process a single scene with validation.

    Args:
        item: STAC item
        target_crs: Target coordinate reference system
        target_resolution: Target pixel size in meters
        min_valid_fraction: Minimum fraction of valid pixels required
        good_pixel_classes: List of SCL values considered valid
        subset_bbox: Optional spatial subset as [west, south, east, north] in WGS84

    Returns:
        Scene data dictionary or None if invalid
    """
    print(f"Processing {item.id[:50]}...")
    data, valid_frac = load_scene_with_cloudmask(
        item, target_crs=target_crs, target_resolution=target_resolution,
        good_pixel_classes=good_pixel_classes, subset_bbox=subset_bbox
    )

    if data and valid_frac > min_valid_fraction:
        return {
            'id': item.id,
            'date': item.properties['datetime'].split('T')[0],
            'data': data,
            'valid_fraction': valid_frac,
            'item': item
        }
    else:
        print(f"‚ö†Ô∏è Skipped {item.id[:30]} (valid fraction: {valid_frac:.1%})")
        return None

def process_scene_batch(scene_items: List, max_workers: int = 4,
                       target_crs: str = 'EPSG:32610',
                       target_resolution: int = 20,
                       min_valid_fraction: float = 0.1,  # Lowered threshold for demonstration
                       good_pixel_classes: List[int] = [4, 5, 6],
                       subset_bbox: Optional[List[float]] = None) -> List[Dict]:
    """
    Process multiple scenes in parallel with cloud masking and reprojection.

    Args:
        scene_items: List of STAC items
        max_workers: Number of parallel workers
        target_crs: Target coordinate reference system
        min_valid_fraction: Minimum valid pixel fraction
        good_pixel_classes: List of SCL values considered valid

    Returns:
        processed_scenes: List of processed scene data
    """
    print(f"üîÑ Processing {len(scene_items)} scenes with {max_workers} workers...")

    # Use partial to pass additional parameters
    process_func = partial(
        process_single_scene,
        target_crs=target_crs,
        target_resolution=target_resolution,
        min_valid_fraction=min_valid_fraction,
        good_pixel_classes=good_pixel_classes
    )

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(process_func, scene_items))

    # Filter successful results
    processed_scenes = [result for result in results if result is not None]

    print(f"‚úÖ Successfully processed {len(processed_scenes)} scenes")
    return processed_scenes

def create_temporal_mosaic(processed_scenes, method: str = 'median'):
    """
    Create a temporal mosaic from multiple processed scenes.

    Args:
        processed_scenes: List of processed scene dictionaries
        method: Compositing method ('median', 'mean', 'max')

    Returns:
        mosaic_data: Temporal composite as xarray Dataset
    """
    if not processed_scenes:
        print("‚ùå No scenes to mosaic")
        return None

    print(f"üß© Creating temporal mosaic using {method} method...")

    # Group data by band
    bands = ['red', 'green', 'blue', 'nir']
    band_stacks = {}
    dates = []

    for band in bands:
        band_data = []
        for scene in processed_scenes:
            band_data.append(scene['data'][band])
            if band == 'red':  # Only collect dates once
                dates.append(scene['date'])

        # Stack along time dimension
        band_stack = xr.concat(band_data, dim='time')
        band_stack = band_stack.assign_coords(time=dates)

        # Apply temporal compositing
        if method == 'median':
            band_stacks[band] = band_stack.median(dim='time', skipna=True)
        elif method == 'mean':
            band_stacks[band] = band_stack.mean(dim='time', skipna=True)
        elif method == 'max':
            band_stacks[band] = band_stack.max(dim='time', skipna=True)

    # Create mosaic dataset
    mosaic_data = xr.Dataset(band_stacks)

    # Add metadata
    mosaic_data.attrs['method'] = method
    mosaic_data.attrs['n_scenes'] = len(processed_scenes)
    mosaic_data.attrs['date_range'] = f"{min(dates)} to {max(dates)}"

    print(f"‚úÖ Mosaic created from {len(processed_scenes)} scenes")
    print(f"üìè Mosaic shape: {mosaic_data['red'].shape}")
    print(f"üìÖ Date range: {mosaic_data.attrs['date_range']}")

    return mosaic_data

def build_temporal_datacube(processed_scenes, chunk_size='auto'):
    """
    Build an analysis-ready temporal data cube.

    Args:
        processed_scenes: List of processed scenes
        chunk_size: Dask chunk size for memory management

    Returns:
        datacube: xarray Dataset with time dimension
    """
    if not processed_scenes:
        return None

    print("üìä Building temporal data cube...")

    # Sort scenes by date
    processed_scenes.sort(key=lambda x: x['date'])

    # Extract dates and data
    dates = [pd.to_datetime(scene['date']) for scene in processed_scenes]
    bands = ['red', 'green', 'blue', 'nir']

    # Build data arrays for each band
    band_cubes = {}

    for band in bands:
        # Stack all scenes for this band
        band_data = []
        for scene in processed_scenes:
            band_data.append(scene['data'][band])

        # Create temporal stack
        band_cube = xr.concat(band_data, dim='time')
        band_cube = band_cube.assign_coords(time=dates)

        # Add chunking for large datasets
        if chunk_size == 'auto':
            # Get actual dimension names from the data
            dims = band_cube.dims
            if len(dims) == 3:  # time, dim_0, dim_1 or time, y, x
                chunks = {dims[0]: 1, dims[1]: 512, dims[2]: 512}
            else:
                chunks = {}
        else:
            chunks = chunk_size

        # Only apply chunking if chunks are specified
        if chunks:
            band_cubes[band] = band_cube.chunk(chunks)
        else:
            band_cubes[band] = band_cube

    # Create dataset
    datacube = xr.Dataset(band_cubes)

    # Add derived indices
    print("üßÆ Computing vegetation indices...")
    datacube['ndvi'] = ((datacube['nir'] - datacube['red']) /
                        (datacube['nir'] + datacube['red'] + 1e-8))

    # Enhanced Vegetation Index (EVI)
    datacube['evi'] = (2.5 * (datacube['nir'] - datacube['red']) /
                       (datacube['nir'] + 6 * datacube['red'] - 7.5 * datacube['blue'] + 1))

    # Add metadata
    datacube.attrs.update({
        'title': 'Sentinel-2 Analysis-Ready Data Cube',
        'description': 'Cloud-masked, reprojected temporal stack',
        'n_scenes': len(processed_scenes),
        'time_range': f"{dates[0].strftime('%Y-%m-%d')} to {dates[-1].strftime('%Y-%m-%d')}",
        'crs': str(datacube['red'].rio.crs) if hasattr(datacube['red'], 'rio') and datacube['red'].rio.crs else 'Unknown',
        'resolution': 'Variable (depends on original scene resolution)'
    })

    print(f"‚úÖ Data cube created:")
    print(f"   Shape: {datacube['red'].shape}")
    print(f"   Time steps: {len(dates)}")
    print(f"   Variables: {list(datacube.data_vars)}")

    return datacube

class Sentinel2Preprocessor:
    """
    Scalable Sentinel-2 preprocessing pipeline using geogfm functions.
    """

    def __init__(self, output_dir: str = "preprocessed_data", target_crs: str = 'EPSG:32610',
                 target_resolution: int = 20, max_cloud_cover: float = 15,
                 good_pixel_classes: List[int] = [4, 5, 6]):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.target_crs = target_crs
        self.target_resolution = target_resolution
        self.max_cloud_cover = max_cloud_cover
        self.good_pixel_classes = good_pixel_classes

        # Set up authentication once during initialization
        setup_planetary_computer_auth()

        print(f"üîß Preprocessing pipeline initialized")
        print(f"   Output directory: {self.output_dir}")
        print(f"   Target CRS: {self.target_crs}")
        print(f"   Target resolution: {self.target_resolution}m")
        print(f"   Max cloud cover: {self.max_cloud_cover}%")

    def search_scenes(self, bbox: List[float], start_date: str, end_date: str,
                     limit: int = 100) -> List:
        """Search for Sentinel-2 scenes using geogfm standardized function."""
        # Ensure authentication is set up
        setup_planetary_computer_auth()

        # Use our standardized search function
        date_range = f"{start_date}/{end_date}"
        items = search_sentinel2_scenes(
            bbox=bbox,
            date_range=date_range,
            cloud_cover_max=self.max_cloud_cover,
            limit=limit
        )

        print(f"üîç Found {len(items)} scenes")
        return items

    def process_scene(self, item, save_individual: bool = True) -> Optional[Dict]:
        """Process a single scene with cloud masking using geogfm functions."""
        scene_id = item.id
        output_path = self.output_dir / f"{scene_id}_processed.nc"

        # Skip if already processed
        if output_path.exists():
            print(f"‚è≠Ô∏è Skipping {scene_id} (already processed)")
            if save_individual:
                return str(output_path)
            else:
                # Load existing data for in-memory processing
                return xr.open_dataset(output_path)

        # Process scene using our enhanced function
        data, valid_frac = load_scene_with_cloudmask(
            item, self.target_crs, self.target_resolution, self.good_pixel_classes
        )

        # Reduce minimum valid fraction threshold for demonstration
        if data and valid_frac > 0.1:  # Accept scenes with >10% valid pixels
            if save_individual:
                try:
                    # Convert to xarray Dataset
                    scene_ds = xr.Dataset(data)
                    scene_ds.attrs.update({
                        'scene_id': scene_id,
                        'date': item.properties['datetime'].split('T')[0],
                        'cloud_cover': item.properties.get('eo:cloud_cover', 0),
                        'valid_pixel_fraction': valid_frac,
                        'processing_crs': self.target_crs,
                        'processing_resolution': self.target_resolution
                    })

                    # Save to NetCDF with compression and engine fallback
                    try:
                        encoding = {var: {'zlib': True, 'complevel': 4} for var in scene_ds.data_vars}
                        scene_ds.to_netcdf(output_path, engine='netcdf4', encoding=encoding)
                        print(f"üíæ Saved: {output_path.name} (netCDF4)")
                    except ImportError:
                        print(f"‚ö†Ô∏è netCDF4 not available, using scipy for {scene_id}...")
                        scene_ds.to_netcdf(output_path, engine='scipy')
                        print(f"üíæ Saved: {output_path.name} (scipy)")
                except Exception as e:
                    print(f"‚ö†Ô∏è Save error for {scene_id}: {str(e)[:50]}")

            return data
        else:
            print(f"‚ùå Skipped {scene_id} (valid fraction: {valid_frac:.1%})")
            return None

    def create_time_series_cube(self, processed_data_list, cube_name: str = "datacube"):
        """Create and save temporal data cube."""
        if not processed_data_list:
            print("‚ùå No data to create cube")
            return None

        cube_path = self.output_dir / f"{cube_name}.nc"

        # Build temporal stack
        dates = []
        band_stacks = {band: [] for band in ['red', 'green', 'blue', 'nir']}

        for data in processed_data_list:
            if data:
                # Handle both dictionary format and xarray Dataset format
                if isinstance(data, dict):
                    # Dictionary format from fresh processing
                    for band in band_stacks.keys():
                        if band in data:
                            band_stacks[band].append(data[band])
                else:
                    # xarray Dataset from loaded file - extract individual bands
                    for band in band_stacks.keys():
                        if band in data.data_vars:
                            # If the loaded data has a time dimension, select the first time slice
                            band_data = data[band]
                            if 'time' in band_data.dims and band_data.dims['time'] > 1:
                                # Multiple time slices in saved file - take first one
                                band_data = band_data.isel(time=0)
                            elif 'time' in band_data.dims:
                                # Single time slice - remove time dimension
                                band_data = band_data.squeeze('time')

                            band_stacks[band].append(band_data)

        # Create dataset
        cube_data = {}
        print(f"üìä Processing bands: {list(band_stacks.keys())}")

        for band, stack in band_stacks.items():
            if stack:
                print(f"   {band}: {len(stack)} scenes")
                # Check that all scenes have this band
                if len(stack) == len(processed_data_list):
                    try:
                        cube_data[band] = xr.concat(stack, dim='time')
                    except Exception as e:
                        print(f"‚ö†Ô∏è Failed to concatenate {band}: {e}")
                else:
                    print(f"‚ö†Ô∏è {band} missing from some scenes ({len(stack)}/{len(processed_data_list)})")

        if cube_data:
            try:
                datacube = xr.Dataset(cube_data)
            except Exception as e:
                print(f"‚ùå Failed to create dataset: {e}")
                print(f"Available bands: {list(cube_data.keys())}")
                return None

            # Add vegetation indices
            datacube['ndvi'] = ((datacube['nir'] - datacube['red']) /
                               (datacube['nir'] + datacube['red'] + 1e-8))

            # Save cube with fallback engines
            try:
                datacube.to_netcdf(cube_path, engine='netcdf4')
                print(f"üì¶ Data cube saved: {cube_path} (netCDF4)")
            except ImportError:
                print("‚ö†Ô∏è netCDF4 not available, using scipy engine...")
                try:
                    datacube.to_netcdf(cube_path, engine='scipy')
                    print(f"üì¶ Data cube saved: {cube_path} (scipy)")
                except Exception:
                    print("‚ö†Ô∏è NetCDF save failed, saving as Zarr...")
                    zarr_path = cube_path.with_suffix('.zarr')
                    datacube.to_zarr(zarr_path)
                    print(f"üì¶ Data cube saved: {zarr_path} (zarr)")

            return datacube

        return None
```

### Test Cloud Masking Functions

Now let's test our cloud masking functions with a real scene. We'll use spatial subsetting to make processing faster and more educational.

:::{.callout-tip}
## Spatial Subsetting for Faster Processing

Processing full Sentinel-2 scenes can be slow and memory-intensive. Each full scene:
- **Size**: ~100MB+ per scene when loaded
- **Dimensions**: ~10,000 √ó 10,000 pixels at 10m resolution
- **Processing time**: Several minutes per scene

Using spatial subsets:
- **Size**: ~1-5MB per subset
- **Dimensions**: ~500 √ó 500 to 2,000 √ó 2,000 pixels
- **Processing time**: Seconds per subset

**Perfect for**: Learning, development, testing, and focused analysis
:::

```{python}
# Define some useful preset subsets for different use cases

# Central Valley subsets (agriculture focus)
small_farm_area = [-121.0, 37.0, -120.8, 37.2]     # ~20km √ó 20km
medium_valley = [-121.2, 36.8, -120.6, 37.4]       # ~40km √ó 40km
large_valley = [-121.5, 36.5, -120.0, 38.0]        # Full study area

# Urban area subsets
sacramento_metro = [-121.6, 38.4, -121.3, 38.7]    # Sacramento urban area
fresno_area = [-119.9, 36.6, -119.6, 36.9]         # Fresno urban/ag mix

print("üìç Available subset presets:")
print(f"Small farm area: {small_farm_area} (~400MB data)")
print(f"Medium valley: {medium_valley} (~1.6GB data)")
print(f"Large valley: {large_valley} (full study area)")
print(f"Sacramento metro: {sacramento_metro} (~urban focus)")
print(f"Fresno area: {fresno_area} (~urban/ag mix)")
```

```{python}
# Test with one scene
test_item = scenes_df.iloc[0]['item']
print(f"üß™ Testing cloud masking with scene: {test_item.id}")

# Define good pixel classes for this demonstration
good_pixel_classes = [4, 5, 6]  # Vegetation, not vegetated, water

# Define a smaller subset for faster processing (optional)
# This is a small area within Central Valley for demonstration
fast_subset = [-121.0, 37.0, -120.8, 37.2]  # Small 20km x 20km area

print(f"\nüéØ Processing options:")
print(f"1. Full scene: ~100MB+ download, slow processing")
print(f"2. Subset area: ~1-5MB download, fast processing")
print(f"\nüöÄ Using fast subset for demonstration...")

# Test our enhanced cloud masking function with spatial subset
masked_data, valid_fraction = load_scene_with_cloudmask(
    test_item,
    target_crs='EPSG:32610',
    target_resolution=20,  # Resample to 20m to match SCL
    good_pixel_classes=good_pixel_classes,
    subset_bbox=fast_subset  # Use subset for faster processing
)

if masked_data:
    print(f"‚úÖ Scene loaded successfully")
    print(f"üìè Data shape: {masked_data['red'].shape}")
    print(f"üìä Valid pixels: {valid_fraction:.1%}")
    print(f"‚òÅÔ∏è Cloudy pixels: {1-valid_fraction:.1%}")
else:
    print("‚ùå Failed to load scene")
```

### Visualize Cloud Masking Results

```{python}
if masked_data:
    # Create visualization of cloud masking
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))

    # Original RGB (before masking)
    red_orig = masked_data['red'].fillna(0)  # Fill NaN for display
    green_orig = masked_data['green'].fillna(0)
    blue_orig = masked_data['blue'].fillna(0)

    # Normalize for RGB display
    def normalize_for_display(band, percentiles=(2, 98)):
        valid_data = band[~np.isnan(band)]
        if len(valid_data) > 0:
            p_low, p_high = np.percentile(valid_data, percentiles)
            return np.clip((band - p_low) / (p_high - p_low), 0, 1)
        return band

    red_norm = normalize_for_display(red_orig.values)
    green_norm = normalize_for_display(green_orig.values)
    blue_norm = normalize_for_display(blue_orig.values)

    rgb_composite = np.dstack([red_norm, green_norm, blue_norm])

    # Plot results
    axes[0,0].imshow(rgb_composite)
    axes[0,0].set_title('RGB Composite')
    axes[0,0].axis('off')

    # Scene Classification Layer
    scl_plot = axes[0,1].imshow(masked_data['scl'].values, cmap='tab20', vmin=0, vmax=11)
    axes[0,1].set_title('Scene Classification Layer')
    axes[0,1].axis('off')

    # Cloud mask
    axes[0,2].imshow(masked_data['cloud_mask'].values, cmap='RdYlGn', vmin=0, vmax=1)
    axes[0,2].set_title('Valid Pixels Mask')
    axes[0,2].axis('off')

    # Masked RGB
    masked_rgb = rgb_composite.copy()
    masked_rgb[~masked_data['cloud_mask'].values] = [1, 0, 0]  # Red for masked areas
    axes[1,0].imshow(masked_rgb)
    axes[1,0].set_title('Masked RGB (Red = Clouds)')
    axes[1,0].axis('off')

    # NDVI calculation on masked data
    # The Normalized Difference Vegetation Index (NDVI) is calculated as:
    # NDVI = (NIR - Red) / (NIR + Red)
    nir_masked = masked_data['nir'].values
    red_masked = masked_data['red'].values
    ndvi = (nir_masked - red_masked) / (nir_masked + red_masked + 1e-8)

    ndvi_plot = axes[1,1].imshow(ndvi, cmap='RdYlGn', vmin=-0.5, vmax=1.0)
    axes[1,1].set_title('NDVI (Clouds Excluded)')
    axes[1,1].axis('off')
    plt.colorbar(ndvi_plot, ax=axes[1,1], shrink=0.6)

    # Statistics
    axes[1,2].text(0.1, 0.8, f"Valid Pixels: {valid_fraction:.1%}", transform=axes[1,2].transAxes, fontsize=12)
    axes[1,2].text(0.1, 0.6, f"Cloudy Pixels: {1-valid_fraction:.1%}", transform=axes[1,2].transAxes, fontsize=12)
    axes[1,2].text(0.1, 0.4, f"NDVI Range: {np.nanmin(ndvi):.2f} to {np.nanmax(ndvi):.2f}", transform=axes[1,2].transAxes, fontsize=12)
    axes[1,2].text(0.1, 0.2, f"Mean NDVI: {np.nanmean(ndvi):.2f}", transform=axes[1,2].transAxes, fontsize=12)
    axes[1,2].set_title('Statistics')
    axes[1,2].axis('off')

    plt.tight_layout()
    plt.show()

    print("üé® Cloud masking visualization complete")
```

:::{.callout-note}
## Scene Classification Layer (SCL) Benefits

The SCL is automatically generated during Sentinel-2 Level 2A processing using machine learning algorithms trained on expert-labeled data.

**Key Advantages**:
- **Automated cloud detection**: No manual threshold setting needed
- **Multiple cloud types**: Distinguishes dense clouds, thin cirrus, and shadows
- **Consistent classification**: Same algorithm across all Sentinel-2 scenes globally
- **Analysis-ready**: Level 2A processing includes atmospheric correction
- **Production quality**: Used by ESA and major data providers

**Best Practice**: Always use SCL for cloud masking rather than simple band thresholds, as it accounts for seasonal and geographic variations in cloud appearance.
:::

---

## Step 3: Reprojection and Mosaicking

When working with multiple scenes, we need to ensure they're all in the same coordinate system and can be combined seamlessly.

### Batch Process Multiple Scenes

```{python}
# Now let's test the batch processing functions we defined earlier

# Select subset of scenes for processing (to manage computational load)
selected_scenes = scenes_df.head(5)['item'].tolist()  # Process first 5 scenes

# Define processing options
print("\nüìé Processing Options:")
print("Option A: Full scenes (slower, ~100MB+ per scene)")
print("Option B: Spatial subset (faster, ~1-5MB per scene)")
print("\nüöÄ Using spatial subset for faster demonstration...")

# Use the same fast subset as before
fast_subset = [-121.0, 37.0, -120.8, 37.2]  # Small area for fast processing

processed_scenes = process_scene_batch(
    selected_scenes,
    max_workers=2,
    min_valid_fraction=0.1,  # Lower threshold to include more scenes
    subset_bbox=fast_subset  # Enable fast processing with subset
)

# Show processing results
if processed_scenes:
    print(f"\nüìä Processing Summary:")
    for scene in processed_scenes:
        print(f"   {scene['date']}: {scene['valid_fraction']:.1%} valid pixels")
```

### Create Temporal Mosaic

```{python}
# Create temporal mosaic using the function we defined earlier

# Create median composite
mosaic = create_temporal_mosaic(processed_scenes, method='median')

if mosaic:
    # Visualize the mosaic
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # RGB composite of mosaic
    red_norm = normalize_for_display(mosaic['red'].values)
    green_norm = normalize_for_display(mosaic['green'].values)
    blue_norm = normalize_for_display(mosaic['blue'].values)
    rgb_mosaic = np.dstack([red_norm, green_norm, blue_norm])

    axes[0].imshow(rgb_mosaic)
    axes[0].set_title(f'RGB Mosaic ({mosaic.attrs["method"]})')
    axes[0].axis('off')

    # NDVI mosaic
    nir_vals = mosaic['nir'].values
    red_vals = mosaic['red'].values
    ndvi_mosaic = (nir_vals - red_vals) / (nir_vals + red_vals + 1e-8)

    ndvi_plot = axes[1].imshow(ndvi_mosaic, cmap='RdYlGn', vmin=-0.2, vmax=0.8)
    axes[1].set_title('NDVI Mosaic')
    axes[1].axis('off')
    plt.colorbar(ndvi_plot, ax=axes[1], shrink=0.8)

    # Data availability (how many scenes contributed to each pixel)
    # This would require tracking per-pixel contributions
    axes[2].text(0.1, 0.5, f"Scenes used: {mosaic.attrs['n_scenes']}\n"
                           f"Method: {mosaic.attrs['method']}\n"
                           f"Date range: {mosaic.attrs['date_range']}\n"
                           f"Coverage: Central Valley, CA",
                transform=axes[2].transAxes, fontsize=12, verticalalignment='center')
    axes[2].set_title('Mosaic Info')
    axes[2].axis('off')

    plt.tight_layout()
    plt.show()

    print("üé® Temporal mosaic visualization complete")
```

---

## Step 4: Analysis-Ready Data Cubes

Now let's create analysis-ready data cubes that can be used for time series analysis and machine learning.

### Build Temporal Data Cube

```{python}
# Build temporal data cube using the function we defined earlier

# Build the data cube
datacube = build_temporal_datacube(processed_scenes)

if datacube:
    print(f"\nüì¶ Data Cube Summary:")
    print(datacube)
```

### Time Series Analysis Example

```{python}
if datacube:
    # Extract time series for a sample location
    # Use more robust center selection - assume the spatial dims are the last two
    spatial_dims = [dim for dim in datacube['red'].dims if dim != 'time']
    if len(spatial_dims) >= 2:
        y_dim, x_dim = spatial_dims[0], spatial_dims[1]
        center_y_idx = datacube.dims[y_dim] // 2
        center_x_idx = datacube.dims[x_dim] // 2
        # Extract time series at center point using integer indexing
        point_ts = datacube.isel({y_dim: center_y_idx, x_dim: center_x_idx})
        print(f"üìç Using spatial dimensions: {y_dim}={center_y_idx}, {x_dim}={center_x_idx}")
    else:
        print("‚ö†Ô∏è Cannot determine spatial dimensions for time series analysis")
        point_ts = None

    # Create time series plots only if we have valid point data
    if point_ts is not None:
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))

        # NDVI time series
        axes[0,0].plot(point_ts.time, point_ts['ndvi'], 'g-o', markersize=4)
        axes[0,0].set_title('NDVI Time Series')
        axes[0,0].set_ylabel('NDVI')
        axes[0,0].grid(True, alpha=0.3)

        # EVI time series
        axes[0,1].plot(point_ts.time, point_ts['evi'], 'b-o', markersize=4)
        axes[0,1].set_title('EVI Time Series')
        axes[0,1].set_ylabel('EVI')
        axes[0,1].grid(True, alpha=0.3)

        # RGB bands time series
        axes[1,0].plot(point_ts.time, point_ts['red'], 'r-', label='Red', alpha=0.7)
        axes[1,0].plot(point_ts.time, point_ts['green'], 'g-', label='Green', alpha=0.7)
        axes[1,0].plot(point_ts.time, point_ts['blue'], 'b-', label='Blue', alpha=0.7)
        axes[1,0].set_title('RGB Bands Time Series')
        axes[1,0].set_ylabel('Reflectance')
        axes[1,0].legend()
        axes[1,0].grid(True, alpha=0.3)

        # NIR time series
        axes[1,1].plot(point_ts.time, point_ts['nir'], 'darkred', marker='o', markersize=4)
        axes[1,1].set_title('NIR Band Time Series')
        axes[1,1].set_ylabel('NIR Reflectance')
        axes[1,1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

        print("üìà Time series analysis complete")
        print(f"Sample location indices: y={center_y_idx}, x={center_x_idx}")
    else:
        print("‚ö†Ô∏è Skipping time series plots due to dimension issues")
```

---

## Step 5: Scalable Batch Processing Workflow

Finally, let's create a reproducible workflow that can handle larger datasets efficiently.

### Preprocessing Pipeline Class

Now let's use the preprocessing pipeline class we defined earlier.

### Initialize and Test the Preprocessing Pipeline

Now let's create an instance of our preprocessing pipeline:

```{python}
# Initialize preprocessor
preprocessor = Sentinel2Preprocessor(
    output_dir="week2_preprocessed",
    target_crs='EPSG:32610',  # UTM Zone 10N for California
    target_resolution=20
)

print("‚úÖ Preprocessing pipeline ready")
```

### Run Complete Preprocessing Workflow

```{python}
# Define workflow parameters with subset options
workflow_params = {
    'bbox': central_valley_bbox,
    'start_date': "2024-07-01",
    'end_date': "2024-08-15",
    'max_scenes': 5,  # Limit for demonstration
    'subset_bbox': small_farm_area  # Use fast subset for demo
}

print(f"üöÄ Starting complete preprocessing workflow...")
print(f"   Area: Central Valley, CA")
print(f"   Period: {workflow_params['start_date']} to {workflow_params['end_date']}")
print(f"   Subset: {workflow_params['subset_bbox']} (for faster processing)")

# Step 1: Search for scenes
workflow_items = preprocessor.search_scenes(
    workflow_params['bbox'],
    workflow_params['start_date'],
    workflow_params['end_date'],
    limit=workflow_params['max_scenes']
)

# Clean up any existing files for fresh processing
import glob
existing_files = glob.glob(str(preprocessor.output_dir / "*.nc"))
if existing_files:
    print(f"üóëÔ∏è Cleaning up {len(existing_files)} existing processed files for fresh processing...")
    for file_path in existing_files:
        try:
            Path(file_path).unlink()
        except:
            pass

# Step 2: Process scenes with spatial subset (demonstration with simulated data)
print("üìù For demonstration purposes, we'll create a simplified data cube")
print("   In practice, you would process real Sentinel-2 scenes as shown above")
print("   Real processing may encounter network issues or incomplete band availability")
print("   This simulation ensures consistent results for educational purposes")

# Create a simple demonstration data cube with consistent dimensions
import numpy as np
import pandas as pd

# Simulate 3 time steps of a small area (20x20 pixels)
n_time = 3
height, width = 20, 20
dates = pd.date_range('2024-07-01', periods=n_time, freq='10D')

# Create simulated spectral data
np.random.seed(42)  # For reproducible demonstration
demo_data = {}

for i, date in enumerate(dates):
    # Simulate realistic spectral values (scaled 0-1)
    red = np.random.uniform(0.1, 0.3, (height, width))
    green = np.random.uniform(0.1, 0.4, (height, width))
    blue = np.random.uniform(0.1, 0.5, (height, width))
    nir = np.random.uniform(0.3, 0.8, (height, width))

    # Add some spatial pattern (vegetation gradient)
    y, x = np.ogrid[:height, :width]
    vegetation_pattern = np.exp(-((y-height//2)**2 + (x-width//2)**2) / (height*width/4))

    # Enhance NIR in vegetated areas
    nir = nir + 0.3 * vegetation_pattern

    # Create xarray DataArrays
    coords = {'y': range(height), 'x': range(width)}
    scene_data = {
        'red': xr.DataArray(red, coords=coords, dims=['y', 'x']),
        'green': xr.DataArray(green, coords=coords, dims=['y', 'x']),
        'blue': xr.DataArray(blue, coords=coords, dims=['y', 'x']),
        'nir': xr.DataArray(nir, coords=coords, dims=['y', 'x'])
    }

    demo_data[date.strftime('%Y-%m-%d')] = scene_data

print(f"üìä Created demonstration data cube with {len(demo_data)} time steps")
print(f"   Spatial dimensions: {height} √ó {width} pixels")
print(f"   Spectral bands: red, green, blue, nir")

# Step 3: Create temporal data cube from demonstration data
print("üß© Building temporal data cube...")
band_stacks = {band: [] for band in ['red', 'green', 'blue', 'nir']}

for date_str, scene_data in demo_data.items():
    for band in band_stacks.keys():
        band_stacks[band].append(scene_data[band])

# Stack along time dimension
cube_data = {}
for band, stack in band_stacks.items():
    cube_data[band] = xr.concat(stack, dim='time')
    cube_data[band] = cube_data[band].assign_coords(time=dates)

# Create final datacube
final_cube = xr.Dataset(cube_data)

# Add vegetation indices
final_cube['ndvi'] = ((final_cube['nir'] - final_cube['red']) /
                      (final_cube['nir'] + final_cube['red'] + 1e-8))

final_cube['evi'] = (2.5 * (final_cube['nir'] - final_cube['red']) /
                     (final_cube['nir'] + 6 * final_cube['red'] - 7.5 * final_cube['blue'] + 1))

# Add metadata
final_cube.attrs.update({
    'title': 'Demonstration Sentinel-2 Data Cube',
    'description': 'Simulated cloud-masked, reprojected temporal stack',
    'n_scenes': len(demo_data),
    'time_range': f"{dates[0].strftime('%Y-%m-%d')} to {dates[-1].strftime('%Y-%m-%d')}",
    'demo': True
})

print(f"\nüéâ Demonstration workflow completed successfully!")
print(f"   Time steps: {len(dates)}")
print(f"   Data cube shape: {final_cube['red'].shape}")
print(f"   Variables: {list(final_cube.data_vars)}")
```

### Create Processing Summary Report

```{python}
# Generate processing summary
output_files = list(preprocessor.output_dir.glob("*.nc"))

print(f"\nüìã Processing Summary Report")
print(f"=" * 50)
print(f"Output Directory: {preprocessor.output_dir}")
print(f"Total Files Created: {len(output_files)}")
print(f"Processing Parameters:")
print(f"  - Target CRS: {preprocessor.target_crs}")
print(f"  - Target Resolution: {preprocessor.target_resolution}m")
print(f"  - Max Cloud Cover: {preprocessor.max_cloud_cover}%")

print(f"\nüìÅ Output Files:")
for file_path in sorted(output_files):
    file_size = file_path.stat().st_size / (1024*1024)  # MB
    print(f"  {file_path.name} ({file_size:.1f} MB)")

# Check if final_cube was created successfully
try:
    if final_cube:
        print(f"\nüìä Final Data Cube Statistics:")
        print(f"  Shape: {final_cube.dims}")
        print(f"  Variables: {list(final_cube.data_vars)}")
        print(f"  Memory usage: ~{final_cube.nbytes / (1024**2):.1f} MB")
except NameError:
    print(f"\nüìä Final Data Cube: Not created (no valid data processed)")

print(f"\nüöÄ Ready for Week 3: Machine Learning on Remote Sensing!")
```

---

## Conclusion

üéâ **Excellent work!** You've built a production-ready preprocessing pipeline for Sentinel-2 imagery.

### What You Accomplished:

1. **Multi-scene Data Discovery**: Searched and organized multiple satellite scenes
2. **Automated Cloud Masking**: Used Scene Classification Layer for quality filtering
3. **Spatial Harmonization**: Reprojected and aligned multiple scenes
4. **Temporal Compositing**: Created cloud-free mosaics using median compositing
5. **Analysis-Ready Data Cubes**: Built time series datasets for analysis
6. **Scalable Workflows**: Implemented batch processing with parallel execution

### Key Takeaways:

- **Scene Classification Layer is powerful** - automates cloud/shadow detection
- **Reprojection is essential** - ensures scenes can be combined seamlessly
- **Temporal compositing reduces clouds** - median filtering creates cleaner datasets
- **Data cubes enable time series analysis** - organize data for trend detection
- **Batch processing scales** - handle large datasets efficiently
- **Spatial subsetting accelerates development** - process small areas quickly for testing and learning

:::{.callout-important}
## Performance Benefits of Spatial Subsetting

**Without subsetting (full scenes)**:
- Download: ~100MB+ per scene
- Processing: 2-5 minutes per scene
- Memory: 1-2GB RAM required
- Storage: 500MB+ per processed scene

**With spatial subsetting (20km √ó 20km)**:
- Download: ~1-5MB per subset
- Processing: 10-30 seconds per subset
- Memory: 100-200MB RAM required
- Storage: 10-50MB per processed subset

**Perfect for**: Learning, prototyping, testing algorithms, focused analysis
**Scale up to**: Full scenes when ready for production analysis
:::

:::{.callout-tip}
## Troubleshooting Common Issues

**Low valid pixel fractions**: If scenes have <30% valid pixels due to clouds:
- Lower the `min_valid_fraction` threshold (e.g., 0.1 instead of 0.3)
- Try different time periods with less cloud cover
- Use larger spatial subsets to increase the chance of finding clear pixels

**Missing netCDF4 errors**: If you see "No module named 'netCDF4'":
- Install with: `conda install netcdf4` or `mamba install netcdf4`
- The code will automatically fallback to scipy or zarr formats
- This doesn't affect functionality, just file format

**Memory issues**: If processing fails due to memory:
- Use smaller spatial subsets
- Process fewer scenes at once
- Reduce the number of parallel workers (`max_workers=1`)
:::

### Course Integration

Building on Week 1's single-scene analysis, this week scales to production workflows essential for geospatial AI applications. Your preprocessing pipeline outputs will be the foundation for machine learning workflows.

### Next Week Preview:

In **Week 3: Fine-tuning Foundation Models**, we'll use your preprocessed data to **train specialized models on land cover patches**:
- Extract training patches from your data cubes
- Create labeled datasets for supervised learning
- Build and train convolutional neural networks
- Compare different CNN architectures
- Evaluate model performance on real satellite imagery

Your preprocessing pipeline outputs will be the foundation for machine learning workflows!

## Resources

- [Sentinel-2 Scene Classification Layer](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm)
- [Rasterio Reprojection Guide](https://rasterio.readthedocs.io/en/latest/topics/reproject.html)
- [Xarray User Guide for Geosciences](https://docs.xarray.dev/en/stable/user-guide/index.html)
- [Dask for Geospatial Data](https://docs.dask.org/en/latest/array.html)