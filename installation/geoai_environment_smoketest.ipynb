{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GeoAI Environment Smoke Test\n",
        "\n",
        "This notebook provides a comprehensive test of your GeoAI course environment. Run all cells to verify that:\n",
        "\n",
        "- ‚úÖ Python environment and packages are correctly installed\n",
        "- ‚úÖ GPU/MPS acceleration is working (if available)\n",
        "- ‚úÖ Jupyter kernel is properly configured\n",
        "- ‚úÖ Course data and models are accessible\n",
        "- ‚úÖ Foundation models can be loaded\n",
        "- ‚úÖ Basic ML workflows function correctly\n",
        "\n",
        "**Instructions:** \n",
        "1. Make sure you're running this notebook with the **GeoAI Course** kernel\n",
        "2. Run all cells in order\n",
        "3. Check that all tests pass (‚úÖ) - any failures (‚ùå) indicate setup issues\n",
        "4. If you encounter issues, refer to the GRIT_SETUP.md troubleshooting section\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment and System Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import platform\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üîç Environment Information\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìÖ Test run: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"üêç Python version: {sys.version}\")\n",
        "print(f\"üíª Platform: {platform.platform()}\")\n",
        "print(f\"üè† Home directory: {os.path.expanduser('~')}\")\n",
        "print(f\"üìÅ Current working directory: {os.getcwd()}\")\n",
        "print(f\"üîß Conda environment: {os.environ.get('CONDA_DEFAULT_ENV', 'unknown')}\")\n",
        "print(f\"üì¶ Python executable: {sys.executable}\")\n",
        "\n",
        "# Check if we're in the right environment\n",
        "expected_env = \"geoAI\"\n",
        "current_env = os.environ.get('CONDA_DEFAULT_ENV', 'unknown')\n",
        "if current_env == expected_env:\n",
        "    print(f\"‚úÖ Running in correct environment: {current_env}\")\n",
        "else:\n",
        "    print(f\"‚ùå Wrong environment! Expected: {expected_env}, Found: {current_env}\")\n",
        "    print(\"   ‚Üí Activate the geoAI environment: conda activate geoAI\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment Variables and Path Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîç Course Environment Variables\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check critical environment variables for the course\n",
        "critical_env_vars = {\n",
        "    'GEO_BENCH_DIR': 'GEO-Bench datasets directory',\n",
        "    'GEOAI_MODELS_DIR': 'Foundation models directory', \n",
        "    'GEOAI_DATA_DIR': 'Course data directory',\n",
        "    'HUGGINGFACE_HUB_CACHE': 'HuggingFace models cache',\n",
        "    'HF_HOME': 'HuggingFace home directory'\n",
        "}\n",
        "\n",
        "all_vars_ok = True\n",
        "for var, description in critical_env_vars.items():\n",
        "    value = os.environ.get(var)\n",
        "    if value:\n",
        "        if os.path.exists(value):\n",
        "            print(f\"‚úÖ {var}: {value}\")\n",
        "            print(f\"   üìÅ {description} - Path exists\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  {var}: {value}\")\n",
        "            print(f\"   üìÅ {description} - Path does not exist\")\n",
        "            all_vars_ok = False\n",
        "    else:\n",
        "        print(f\"‚ùå {var}: NOT SET\")\n",
        "        print(f\"   üìÅ {description} - Variable not configured\")\n",
        "        all_vars_ok = False\n",
        "\n",
        "# Check Python path\n",
        "pythonpath = os.environ.get('PYTHONPATH', '')\n",
        "if pythonpath:\n",
        "    print(f\"\\nüìö PYTHONPATH: {pythonpath}\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  PYTHONPATH: Not set\")\n",
        "\n",
        "print(f\"\\n{'‚úÖ All environment variables configured correctly' if all_vars_ok else '‚ùå Some environment variables need attention'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Core Package Imports and Versions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "print(\"üîç Package Import Test\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Core scientific packages\n",
        "core_packages = [\n",
        "    ('numpy', 'NumPy'),\n",
        "    ('pandas', 'Pandas'), \n",
        "    ('matplotlib', 'Matplotlib'),\n",
        "    ('seaborn', 'Seaborn'),\n",
        "    ('scipy', 'SciPy'),\n",
        "    ('sklearn', 'Scikit-learn')\n",
        "]\n",
        "\n",
        "# AI/ML packages  \n",
        "ml_packages = [\n",
        "    ('torch', 'PyTorch'),\n",
        "    ('torchvision', 'TorchVision'),\n",
        "    ('transformers', 'HuggingFace Transformers'),\n",
        "    ('datasets', 'HuggingFace Datasets'),\n",
        "    ('pytorch_lightning', 'PyTorch Lightning'),\n",
        "    ('timm', 'TIMM')\n",
        "]\n",
        "\n",
        "# Geospatial packages\n",
        "geo_packages = [\n",
        "    ('rasterio', 'Rasterio'),\n",
        "    ('geopandas', 'GeoPandas'),\n",
        "    ('xarray', 'XArray'),\n",
        "    ('folium', 'Folium'),\n",
        "    ('torchgeo', 'TorchGeo'),\n",
        "    ('ee', 'Earth Engine API')\n",
        "]\n",
        "\n",
        "# Computer vision packages\n",
        "cv_packages = [\n",
        "    ('cv2', 'OpenCV'),\n",
        "    ('kornia', 'Kornia'), \n",
        "    ('einops', 'Einops'),\n",
        "    ('PIL', 'Pillow')\n",
        "]\n",
        "\n",
        "# Jupyter packages\n",
        "jupyter_packages = [\n",
        "    ('jupyter', 'Jupyter'),\n",
        "    ('jupyterlab', 'JupyterLab'),\n",
        "    ('ipykernel', 'IPython Kernel'),\n",
        "    ('notebook', 'Notebook')\n",
        "]\n",
        "\n",
        "def test_package_group(packages, group_name):\n",
        "    print(f\"\\nüì¶ {group_name}\")\n",
        "    print(\"-\" * 30)\n",
        "    failed_imports = []\n",
        "    \n",
        "    for package, display_name in packages:\n",
        "        try:\n",
        "            module = __import__(package)\n",
        "            version = getattr(module, '__version__', 'unknown')\n",
        "            print(f\"‚úÖ {display_name}: {version}\")\n",
        "        except ImportError as e:\n",
        "            print(f\"‚ùå {display_name}: Failed to import - {e}\")\n",
        "            failed_imports.append(display_name)\n",
        "    \n",
        "    return failed_imports\n",
        "\n",
        "all_failed = []\n",
        "all_failed.extend(test_package_group(core_packages, \"Core Scientific Packages\"))\n",
        "all_failed.extend(test_package_group(ml_packages, \"AI/ML Packages\"))\n",
        "all_failed.extend(test_package_group(geo_packages, \"Geospatial Packages\"))\n",
        "all_failed.extend(test_package_group(cv_packages, \"Computer Vision Packages\"))\n",
        "all_failed.extend(test_package_group(jupyter_packages, \"Jupyter Packages\"))\n",
        "\n",
        "print(f\"\\n{'=' * 50}\")\n",
        "if not all_failed:\n",
        "    print(\"‚úÖ All core packages imported successfully!\")\n",
        "else:\n",
        "    print(f\"‚ùå {len(all_failed)} packages failed to import:\")\n",
        "    for pkg in all_failed:\n",
        "        print(f\"   ‚Ä¢ {pkg}\")\n",
        "    print(\"\\nRefer to installation guide for troubleshooting.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. GPU/Acceleration Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "print(\"üîç GPU/Acceleration Testing\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# Check available devices\n",
        "gpu_available = False\n",
        "device_name = \"cpu\"\n",
        "\n",
        "# Check CUDA (NVIDIA GPU)\n",
        "if torch.cuda.is_available():\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    primary_gpu = torch.cuda.get_device_name(0)\n",
        "    print(f\"‚úÖ CUDA available: {gpu_count} device(s)\")\n",
        "    print(f\"   üéØ Primary GPU: {primary_gpu}\")\n",
        "    device_name = \"cuda\"\n",
        "    gpu_available = True\n",
        "    \n",
        "    # Test CUDA operations\n",
        "    try:\n",
        "        device = torch.device('cuda')\n",
        "        x = torch.randn(100, 100, device=device)\n",
        "        y = torch.randn(100, 100, device=device)\n",
        "        z = torch.mm(x, y)\n",
        "        print(f\"   ‚úÖ CUDA tensor operations successful on {z.device}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå CUDA tensor operations failed: {e}\")\n",
        "        gpu_available = False\n",
        "\n",
        "# Check MPS (Apple Silicon)\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    print(\"‚úÖ Apple Metal Performance Shaders (MPS) available\")\n",
        "    device_name = \"mps\"\n",
        "    gpu_available = True\n",
        "    \n",
        "    # Test MPS operations  \n",
        "    try:\n",
        "        device = torch.device('mps')\n",
        "        x = torch.randn(100, 100, device=device)\n",
        "        y = torch.randn(100, 100, device=device)\n",
        "        z = torch.mm(x, y)\n",
        "        print(f\"   ‚úÖ MPS tensor operations successful on {z.device}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå MPS tensor operations failed: {e}\")\n",
        "        gpu_available = False\n",
        "        device_name = \"cpu\"\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU acceleration available - using CPU only\")\n",
        "    print(\"   üí° This is normal for CPU-only systems\")\n",
        "\n",
        "# Performance benchmark\n",
        "print(f\"\\nüèÉ Performance benchmark on {device_name.upper()}:\")\n",
        "try:\n",
        "    if gpu_available:\n",
        "        device = torch.device(device_name)\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    \n",
        "    # Warm up\n",
        "    a = torch.randn(1000, 1000, device=device)\n",
        "    b = torch.randn(1000, 1000, device=device)\n",
        "    _ = torch.mm(a, b)\n",
        "    \n",
        "    # Benchmark\n",
        "    start_time = time.time()\n",
        "    for _ in range(10):\n",
        "        c = torch.mm(a, b)\n",
        "    if device_name in ['cuda']:\n",
        "        torch.cuda.synchronize()\n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    print(f\"   üéØ 10x (1000x1000) matrix multiplications: {elapsed:.3f}s\")\n",
        "    print(f\"   üìä Average per operation: {elapsed/10:.3f}s\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå Benchmark failed: {e}\")\n",
        "\n",
        "# Recommended device selection code\n",
        "print(f\"\\nüí° Recommended device selection for notebooks:\")\n",
        "print(\"   device = torch.device('cuda' if torch.cuda.is_available() else\")\n",
        "print(\"                        ('mps' if torch.backends.mps.is_available() else 'cpu'))\")\n",
        "print(f\"   Current best device: {device}\")\n",
        "\n",
        "print(f\"\\n{'‚úÖ GPU acceleration ready!' if gpu_available else '‚ö†Ô∏è  CPU-only mode (still functional)'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Foundation Models and Data Access\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"üîç Foundation Models and Data Access\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check for foundation model registry\n",
        "models_dir = Path.home() / 'geoAI' / 'models'\n",
        "registry_path = models_dir / 'model_registry.json'\n",
        "\n",
        "print(f\"üìÅ Models directory: {models_dir}\")\n",
        "print(f\"üìÑ Registry path: {registry_path}\")\n",
        "\n",
        "if registry_path.exists():\n",
        "    try:\n",
        "        with open(registry_path, 'r') as f:\n",
        "            registry = json.load(f)\n",
        "        \n",
        "        print(\"‚úÖ Model registry found\")\n",
        "        print(f\"   üìÖ Created: {registry.get('created', 'unknown')}\")\n",
        "        \n",
        "        models = registry.get('models', {})\n",
        "        if models:\n",
        "            print(f\"   üì¶ Available models ({len(models)}):\")\n",
        "            for model_name, model_info in models.items():\n",
        "                model_path = Path(model_info['path'])\n",
        "                if model_path.exists():\n",
        "                    print(f\"      ‚úÖ {model_name}: {model_path}\")\n",
        "                else:\n",
        "                    print(f\"      ‚ùå {model_name}: {model_path} (not found)\")\n",
        "        else:\n",
        "            print(\"   ‚ö†Ô∏è  No models registered\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to read model registry: {e}\")\n",
        "else:\n",
        "    print(\"‚ùå Model registry not found\")\n",
        "    print(\"   üí° Run: bash installation/scripts/install_foundation_models.sh\")\n",
        "\n",
        "# Check GEO-Bench data\n",
        "geobench_dir = os.environ.get('GEO_BENCH_DIR')\n",
        "if geobench_dir:\n",
        "    geobench_path = Path(geobench_dir)\n",
        "    if geobench_path.exists():\n",
        "        print(f\"\\n‚úÖ GEO-Bench directory: {geobench_path}\")\n",
        "        # List available datasets\n",
        "        try:\n",
        "            datasets = [d for d in geobench_path.iterdir() if d.is_dir()]\n",
        "            if datasets:\n",
        "                print(f\"   üìä Available datasets ({len(datasets)}):\")\n",
        "                for dataset in sorted(datasets)[:10]:  # Show first 10\n",
        "                    print(f\"      ‚Ä¢ {dataset.name}\")\n",
        "                if len(datasets) > 10:\n",
        "                    print(f\"      ... and {len(datasets)-10} more\")\n",
        "            else:\n",
        "                print(\"   ‚ö†Ô∏è  No datasets found\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è  Could not list datasets: {e}\")\n",
        "    else:\n",
        "        print(f\"‚ùå GEO-Bench directory not found: {geobench_path}\")\n",
        "else:\n",
        "    print(\"‚ùå GEO_BENCH_DIR environment variable not set\")\n",
        "\n",
        "# Check course data directory\n",
        "data_dir = os.environ.get('GEOAI_DATA_DIR')\n",
        "if data_dir:\n",
        "    data_path = Path(data_dir)\n",
        "    if data_path.exists():\n",
        "        print(f\"\\n‚úÖ Course data directory: {data_path}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Course data directory not found: {data_path}\")\n",
        "else:\n",
        "    print(\"‚ùå GEOAI_DATA_DIR environment variable not set\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Loading and Basic ML Workflow Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîç Model Loading and ML Workflow Test\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Test HuggingFace model loading\n",
        "print(\"üì¶ Testing HuggingFace model loading...\")\n",
        "try:\n",
        "    from transformers import AutoModel, AutoTokenizer\n",
        "    \n",
        "    # Load a small test model\n",
        "    model_name = \"distilbert-base-uncased\"\n",
        "    print(f\"   Loading {model_name}...\")\n",
        "    \n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "    \n",
        "    # Move to available device\n",
        "    if gpu_available:\n",
        "        model = model.to(device)\n",
        "        print(f\"   ‚úÖ Model loaded on {device}\")\n",
        "    else:\n",
        "        print(\"   ‚úÖ Model loaded on CPU\")\n",
        "    \n",
        "    # Test tokenization and inference\n",
        "    test_text = \"This is a test sentence for the GeoAI course.\"\n",
        "    inputs = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    \n",
        "    if gpu_available:\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    \n",
        "    print(f\"   ‚úÖ Model inference successful\")\n",
        "    print(f\"   üìä Output shape: {outputs.last_hidden_state.shape}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå HuggingFace model loading failed: {e}\")\n",
        "\n",
        "# Test PyTorch model creation with TIMM\n",
        "print(f\"\\nüèóÔ∏è  Testing TIMM model creation...\")\n",
        "try:\n",
        "    import timm\n",
        "    \n",
        "    # Create a vision transformer model\n",
        "    model_name = \"vit_tiny_patch16_224\"\n",
        "    print(f\"   Creating {model_name}...\")\n",
        "    \n",
        "    model = timm.create_model(model_name, pretrained=False, num_classes=10)\n",
        "    \n",
        "    if gpu_available:\n",
        "        model = model.to(device)\n",
        "        \n",
        "    # Test forward pass\n",
        "    batch_size = 2\n",
        "    test_input = torch.randn(batch_size, 3, 224, 224)\n",
        "    \n",
        "    if gpu_available:\n",
        "        test_input = test_input.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(test_input)\n",
        "    \n",
        "    print(f\"   ‚úÖ TIMM model creation and inference successful\")\n",
        "    print(f\"   üìä Input shape: {test_input.shape}\")\n",
        "    print(f\"   üìä Output shape: {output.shape}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå TIMM model creation failed: {e}\")\n",
        "\n",
        "# Test basic tensor operations with geospatial dimensions\n",
        "print(f\"\\nüåç Testing geospatial tensor operations...\")\n",
        "try:\n",
        "    # Simulate satellite image data (batch, channels, height, width)\n",
        "    batch_size = 4\n",
        "    channels = 6  # Typical for HLS (6-band)\n",
        "    height, width = 256, 256\n",
        "    \n",
        "    print(f\"   Creating mock satellite data: ({batch_size}, {channels}, {height}, {width})\")\n",
        "    satellite_data = torch.randn(batch_size, channels, height, width)\n",
        "    \n",
        "    if gpu_available:\n",
        "        satellite_data = satellite_data.to(device)\n",
        "    \n",
        "    # Test common operations\n",
        "    mean_channels = torch.mean(satellite_data, dim=(2, 3))  # Spatial mean\n",
        "    normalized = (satellite_data - satellite_data.mean()) / satellite_data.std()\n",
        "    patches = satellite_data.unfold(2, 64, 64).unfold(3, 64, 64)  # 64x64 patches\n",
        "    \n",
        "    print(f\"   ‚úÖ Geospatial tensor operations successful\")\n",
        "    print(f\"   üìä Channel means shape: {mean_channels.shape}\")\n",
        "    print(f\"   üìä Patches shape: {patches.shape}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå Geospatial tensor operations failed: {e}\")\n",
        "\n",
        "print(f\"\\n{'‚úÖ ML workflow tests completed successfully!' if True else '‚ùå Some ML workflow tests failed'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Final Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üéØ Environment Smoke Test Summary\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Collect overall status\n",
        "print(f\"‚úÖ Test completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
        "print(f\"üîß Environment: {os.environ.get('CONDA_DEFAULT_ENV', 'unknown')}\")\n",
        "print(f\"üéÆ Acceleration: {device_name.upper() if gpu_available else 'CPU-only'}\")\n",
        "\n",
        "print(f\"\\nüìã Quick checklist for students:\")\n",
        "print(\"   ‚úÖ Run `conda activate geoAI` before starting Jupyter\")\n",
        "print(\"   ‚úÖ Use the 'GeoAI Course' kernel in your notebooks\")\n",
        "print(\"   ‚úÖ Import torch and set device for your computations\")\n",
        "print(\"   ‚úÖ Check environment variables are set correctly\")\n",
        "\n",
        "print(f\"\\nüí° Recommended code snippet for your notebooks:\")\n",
        "print(\"```python\")\n",
        "print(\"import torch\")\n",
        "print(\"import os\")\n",
        "print(\"\")\n",
        "print(\"# Set device for computations\")\n",
        "print(\"device = torch.device('cuda' if torch.cuda.is_available() else\")\n",
        "print(\"                     ('mps' if torch.backends.mps.is_available() else 'cpu'))\")\n",
        "print(\"print(f'Using device: {device}')\")\n",
        "print(\"\")\n",
        "print(\"# Check environment variables\")\n",
        "print(\"for var in ['GEO_BENCH_DIR', 'GEOAI_MODELS_DIR', 'GEOAI_DATA_DIR']:\")\n",
        "print(\"    print(f'{var}: {os.environ.get(var, \\\"NOT SET\\\")}')\")\n",
        "print(\"```\")\n",
        "\n",
        "print(f\"\\nüö® If you encountered any ‚ùå errors:\")\n",
        "print(\"   1. Check the GRIT_SETUP.md file for troubleshooting\")\n",
        "print(\"   2. Ensure you're in the correct conda environment\") \n",
        "print(\"   3. Verify environment variables are set correctly\")\n",
        "print(\"   4. Contact course staff if issues persist\")\n",
        "\n",
        "print(f\"\\nüéâ Your GeoAI environment appears to be ready for the course!\")\n",
        "print(\"   You can now proceed with the course materials and assignments.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
